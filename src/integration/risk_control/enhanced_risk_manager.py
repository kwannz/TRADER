"""
Enhanced Risk Manager with CTBench Integration
å¢å¼ºé£é™©ç®¡ç†å™¨ï¼Œé›†æˆCTBenchåˆæˆæ•°æ®ç”Ÿæˆèƒ½åŠ›
"""

import asyncio
import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime, timedelta
from dataclasses import dataclass
import logging
from enum import Enum

from ..model_service import get_ctbench_service, DataGenerationRequest

class RiskLevel(Enum):
    """é£é™©ç­‰çº§"""
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    CRITICAL = 4
    EXTREME = 5

@dataclass
class RiskAssessment:
    """é£é™©è¯„ä¼°ç»“æœ"""
    overall_risk: RiskLevel
    portfolio_value: float
    var_1d: float  # 1æ—¥é£é™©ä»·å€¼
    var_5d: float  # 5æ—¥é£é™©ä»·å€¼
    max_drawdown: float
    sharpe_ratio: float
    volatility: float
    black_swan_probability: float
    stress_test_results: Dict[str, float]
    recommendations: List[str]
    timestamp: datetime

@dataclass
class PositionRisk:
    """ä»“ä½é£é™©"""
    symbol: str
    position_size: float
    market_value: float
    risk_contribution: float
    beta: float
    correlation_risk: float
    liquidity_risk: float

class EnhancedRiskManager:
    """å¢å¼ºé£é™©ç®¡ç†å™¨"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.logger = logging.getLogger(__name__)
        self.config = config or self._default_config()
        self.ctbench_service = None
        self.risk_history = []
        
        # é£é™©é˜ˆå€¼
        self.risk_thresholds = {
            RiskLevel.LOW: 0.02,      # 2% VaR
            RiskLevel.MEDIUM: 0.05,   # 5% VaR
            RiskLevel.HIGH: 0.10,     # 10% VaR
            RiskLevel.CRITICAL: 0.20, # 20% VaR
            RiskLevel.EXTREME: 0.50   # 50% VaR
        }
        
    def _default_config(self) -> Dict[str, Any]:
        """é»˜è®¤é…ç½®"""
        return {
            'var_confidence_level': 0.05,  # 95% VaR
            'stress_test_scenarios': 1000,
            'max_position_weight': 0.1,
            'correlation_threshold': 0.8,
            'liquidity_threshold': 0.05,
            'black_swan_threshold': 0.01,
            'rebalance_threshold': 0.05
        }
        
    async def initialize(self):
        """åˆå§‹åŒ–é£é™©ç®¡ç†å™¨"""
        self.ctbench_service = await get_ctbench_service()
        self.logger.info("å¢å¼ºé£é™©ç®¡ç†å™¨å·²åˆå§‹åŒ–")
        
    async def comprehensive_risk_assessment(self, 
                                          portfolio_data: Dict[str, Any],
                                          market_data: pd.DataFrame) -> RiskAssessment:
        """ç»¼åˆé£é™©è¯„ä¼°"""
        try:
            # åŸºç¡€é£é™©æŒ‡æ ‡è®¡ç®—
            basic_metrics = self._calculate_basic_metrics(portfolio_data, market_data)
            
            # CTBenchå¢å¼ºåˆ†æ
            enhanced_metrics = await self._ctbench_enhanced_analysis(market_data)
            
            # å‹åŠ›æµ‹è¯•
            stress_results = await self._comprehensive_stress_testing(portfolio_data, market_data)
            
            # é»‘å¤©é¹…äº‹ä»¶æ¦‚ç‡ä¼°è®¡
            black_swan_prob = await self._estimate_black_swan_probability(market_data)
            
            # ç»¼åˆé£é™©ç­‰çº§è¯„ä¼°
            overall_risk = self._assess_overall_risk_level(
                basic_metrics, enhanced_metrics, stress_results, black_swan_prob
            )
            
            # ç”Ÿæˆé£é™©å»ºè®®
            recommendations = self._generate_risk_recommendations(
                overall_risk, basic_metrics, enhanced_metrics, stress_results
            )
            
            risk_assessment = RiskAssessment(
                overall_risk=overall_risk,
                portfolio_value=portfolio_data.get('total_value', 0),
                var_1d=basic_metrics['var_1d'],
                var_5d=basic_metrics['var_5d'],
                max_drawdown=basic_metrics['max_drawdown'],
                sharpe_ratio=basic_metrics['sharpe_ratio'],
                volatility=basic_metrics['volatility'],
                black_swan_probability=black_swan_prob,
                stress_test_results=stress_results,
                recommendations=recommendations,
                timestamp=datetime.now()
            )
            
            # è®°å½•é£é™©è¯„ä¼°å†å²
            self.risk_history.append(risk_assessment)
            
            return risk_assessment
            
        except Exception as e:
            self.logger.error(f"ç»¼åˆé£é™©è¯„ä¼°å¤±è´¥: {e}")
            raise
            
    def _calculate_basic_metrics(self, portfolio_data: Dict[str, Any],
                               market_data: pd.DataFrame) -> Dict[str, float]:
        """è®¡ç®—åŸºç¡€é£é™©æŒ‡æ ‡"""
        metrics = {}
        
        try:
            # å‡è®¾market_dataåŒ…å«ä»·æ ¼æ•°æ®
            prices = market_data.iloc[:, 0].values  # å‡è®¾ç¬¬ä¸€åˆ—æ˜¯ä»·æ ¼
            returns = np.diff(np.log(prices))
            
            # VaRè®¡ç®—
            var_percentile = self.config['var_confidence_level']
            metrics['var_1d'] = np.percentile(returns, var_percentile * 100)
            metrics['var_5d'] = metrics['var_1d'] * np.sqrt(5)  # ç®€åŒ–çš„5æ—¥VaR
            
            # æœ€å¤§å›æ’¤
            cumulative_returns = np.cumprod(1 + returns)
            running_max = np.maximum.accumulate(cumulative_returns)
            drawdowns = (cumulative_returns - running_max) / running_max
            metrics['max_drawdown'] = np.min(drawdowns)
            
            # æ³¢åŠ¨ç‡
            metrics['volatility'] = np.std(returns) * np.sqrt(252)  # å¹´åŒ–æ³¢åŠ¨ç‡
            
            # å¤æ™®æ¯”ç‡ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå‡è®¾æ— é£é™©åˆ©ç‡ä¸º0ï¼‰
            mean_return = np.mean(returns) * 252
            metrics['sharpe_ratio'] = mean_return / metrics['volatility'] if metrics['volatility'] > 0 else 0
            
        except Exception as e:
            self.logger.error(f"è®¡ç®—åŸºç¡€æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
            # è¿”å›é»˜è®¤å€¼
            metrics = {
                'var_1d': 0.0, 'var_5d': 0.0, 'max_drawdown': 0.0,
                'volatility': 0.0, 'sharpe_ratio': 0.0
            }
            
        return metrics
        
    async def _ctbench_enhanced_analysis(self, market_data: pd.DataFrame) -> Dict[str, Any]:
        """CTBenchå¢å¼ºåˆ†æ"""
        if self.ctbench_service is None:
            return {}
            
        try:
            # å°†å¸‚åœºæ•°æ®è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼ˆå‡è®¾æ˜¯OHLCVæ ¼å¼ï¼‰
            data_array = market_data.values
            if data_array.shape[1] < 6:
                # å¦‚æœåˆ—æ•°ä¸è¶³ï¼Œç”¨ä»·æ ¼æ•°æ®å¡«å……
                price_col = data_array[:, [0]]
                data_array = np.hstack([
                    price_col, price_col, price_col, price_col, 
                    price_col, price_col
                ])[:, :6]
                
            # é‡å¡‘ä¸ºCTBenchæœŸæœ›çš„æ ¼å¼ (batch, sequence, features)
            sequence_length = min(60, data_array.shape[0])
            data_reshaped = data_array[-sequence_length:].reshape(1, sequence_length, -1)
            
            # ä½¿ç”¨CTBenchç”Ÿæˆå¢å¼ºæ•°æ®è¿›è¡Œåˆ†æ
            augmentation_result = await self.ctbench_service.get_real_time_market_data_augmentation(
                data_reshaped, augmentation_factor=100
            )
            
            if augmentation_result['success']:
                augmented_data = augmentation_result['augmented_data']
                
                # åˆ†æå¢å¼ºæ•°æ®çš„ç»Ÿè®¡ç‰¹æ€§
                enhanced_metrics = {
                    'scenario_volatility_range': self._analyze_scenario_volatility(augmented_data),
                    'extreme_event_frequency': self._count_extreme_events(augmented_data),
                    'tail_risk_metrics': self._calculate_tail_risks(augmented_data),
                    'scenario_correlation': self._analyze_scenario_correlations(augmented_data)
                }
                
                return enhanced_metrics
            else:
                self.logger.warning("CTBenchæ•°æ®å¢å¼ºå¤±è´¥")
                return {}
                
        except Exception as e:
            self.logger.error(f"CTBenchå¢å¼ºåˆ†æå¤±è´¥: {e}")
            return {}
            
    def _analyze_scenario_volatility(self, augmented_data: np.ndarray) -> Dict[str, float]:
        """åˆ†æåœºæ™¯æ³¢åŠ¨ç‡åˆ†å¸ƒ"""
        volatilities = []
        
        for scenario in augmented_data:
            returns = np.diff(np.log(scenario[:, 0] + 1e-8))  # é¿å…log(0)
            vol = np.std(returns)
            volatilities.append(vol)
            
        return {
            'min_volatility': float(np.min(volatilities)),
            'max_volatility': float(np.max(volatilities)),
            'median_volatility': float(np.median(volatilities)),
            'volatility_95th': float(np.percentile(volatilities, 95))
        }
        
    def _count_extreme_events(self, augmented_data: np.ndarray) -> float:
        """ç»Ÿè®¡æç«¯äº‹ä»¶é¢‘ç‡"""
        extreme_threshold = 0.05  # 5%çš„ä»·æ ¼å˜åŠ¨è§†ä¸ºæç«¯äº‹ä»¶
        total_events = 0
        total_observations = 0
        
        for scenario in augmented_data:
            returns = np.diff(scenario[:, 0]) / (scenario[:-1, 0] + 1e-8)
            extreme_events = np.sum(np.abs(returns) > extreme_threshold)
            total_events += extreme_events
            total_observations += len(returns)
            
        return total_events / total_observations if total_observations > 0 else 0
        
    def _calculate_tail_risks(self, augmented_data: np.ndarray) -> Dict[str, float]:
        """è®¡ç®—å°¾éƒ¨é£é™©æŒ‡æ ‡"""
        all_returns = []
        
        for scenario in augmented_data:
            returns = np.diff(scenario[:, 0]) / (scenario[:-1, 0] + 1e-8)
            all_returns.extend(returns)
            
        all_returns = np.array(all_returns)
        
        return {
            'var_1pct': float(np.percentile(all_returns, 1)),
            'var_5pct': float(np.percentile(all_returns, 5)),
            'cvar_5pct': float(np.mean(all_returns[all_returns <= np.percentile(all_returns, 5)])),
            'skewness': float(self._calculate_skewness(all_returns)),
            'kurtosis': float(self._calculate_kurtosis(all_returns))
        }
        
    def _analyze_scenario_correlations(self, augmented_data: np.ndarray) -> Dict[str, float]:
        """åˆ†æåœºæ™¯é—´ç›¸å…³æ€§"""
        if augmented_data.shape[2] < 2:
            return {'avg_correlation': 0.0}
            
        correlations = []
        for scenario in augmented_data:
            if scenario.shape[1] >= 2:
                corr_matrix = np.corrcoef(scenario[:, 0], scenario[:, 1])
                if not np.isnan(corr_matrix[0, 1]):
                    correlations.append(corr_matrix[0, 1])
                    
        return {
            'avg_correlation': float(np.mean(correlations)) if correlations else 0.0,
            'max_correlation': float(np.max(correlations)) if correlations else 0.0,
            'min_correlation': float(np.min(correlations)) if correlations else 0.0
        }
        
    async def _comprehensive_stress_testing(self, portfolio_data: Dict[str, Any],
                                          market_data: pd.DataFrame) -> Dict[str, float]:
        """ç»¼åˆå‹åŠ›æµ‹è¯•"""
        if self.ctbench_service is None:
            return {}
            
        try:
            # å‡†å¤‡åŸºç¡€æ•°æ®
            data_array = market_data.values
            if data_array.shape[1] < 6:
                price_col = data_array[:, [0]]
                data_array = np.hstack([price_col] * 6)[:, :6]
                
            sequence_length = min(60, data_array.shape[0])
            data_reshaped = data_array[-sequence_length:].reshape(1, sequence_length, -1)
            
            # ç”Ÿæˆå‹åŠ›æµ‹è¯•åœºæ™¯
            stress_result = await self.ctbench_service.generate_stress_test_scenarios(
                data_reshaped, ['black_swan', 'high_volatility', 'bear_market']
            )
            
            if not stress_result['success']:
                return {}
                
            stress_scenarios = stress_result['stress_scenarios']
            portfolio_value = portfolio_data.get('total_value', 1000000)
            
            # è¯„ä¼°æ¯ç§å‹åŠ›åœºæ™¯ä¸‹çš„æŸå¤±
            stress_results = {}
            
            for scenario_type, scenarios in stress_scenarios.items():
                losses = []
                for scenario in scenarios:
                    # è®¡ç®—è¯¥åœºæ™¯ä¸‹çš„ç»„åˆæŸå¤±ï¼ˆç®€åŒ–è®¡ç®—ï¼‰
                    scenario_returns = np.diff(scenario[:, 0]) / (scenario[:-1, 0] + 1e-8)
                    scenario_loss = -np.sum(scenario_returns) * portfolio_value
                    losses.append(scenario_loss)
                    
                stress_results[f'{scenario_type}_worst_loss'] = float(np.max(losses))
                stress_results[f'{scenario_type}_avg_loss'] = float(np.mean(losses))
                stress_results[f'{scenario_type}_var_95'] = float(np.percentile(losses, 95))
                
            return stress_results
            
        except Exception as e:
            self.logger.error(f"ç»¼åˆå‹åŠ›æµ‹è¯•å¤±è´¥: {e}")
            return {}
            
    async def _estimate_black_swan_probability(self, market_data: pd.DataFrame) -> float:
        """ä¼°è®¡é»‘å¤©é¹…äº‹ä»¶æ¦‚ç‡"""
        try:
            prices = market_data.iloc[:, 0].values
            returns = np.diff(np.log(prices))
            
            # ä½¿ç”¨æå€¼ç†è®ºä¼°è®¡å°¾éƒ¨æ¦‚ç‡
            threshold = np.percentile(np.abs(returns), 95)  # 95%åˆ†ä½æ•°ä½œä¸ºé˜ˆå€¼
            extreme_returns = returns[np.abs(returns) > threshold]
            
            if len(extreme_returns) == 0:
                return 0.0
                
            # ç®€åŒ–çš„é»‘å¤©é¹…æ¦‚ç‡ä¼°è®¡ï¼ˆåŸºäºå†å²æå€¼é¢‘ç‡ï¼‰
            extreme_frequency = len(extreme_returns) / len(returns)
            
            # è°ƒæ•´ç³»æ•°ï¼ˆè€ƒè™‘å°¾éƒ¨åšåº¦ï¼‰
            kurtosis = self._calculate_kurtosis(returns)
            tail_adjustment = max(1.0, kurtosis / 3.0)  # æ­£æ€åˆ†å¸ƒå³°åº¦ä¸º3
            
            black_swan_prob = extreme_frequency * tail_adjustment
            
            return min(black_swan_prob, 0.1)  # æœ€å¤§æ¦‚ç‡é™åˆ¶ä¸º10%
            
        except Exception as e:
            self.logger.error(f"ä¼°è®¡é»‘å¤©é¹…æ¦‚ç‡å¤±è´¥: {e}")
            return 0.0
            
    def _assess_overall_risk_level(self, basic_metrics: Dict[str, float],
                                 enhanced_metrics: Dict[str, Any],
                                 stress_results: Dict[str, float],
                                 black_swan_prob: float) -> RiskLevel:
        """è¯„ä¼°æ€»ä½“é£é™©ç­‰çº§"""
        risk_scores = []
        
        # åŸºäºVaRçš„é£é™©è¯„åˆ†
        var_1d = abs(basic_metrics.get('var_1d', 0))
        for level, threshold in self.risk_thresholds.items():
            if var_1d >= threshold:
                risk_scores.append(level.value)
                
        # åŸºäºæœ€å¤§å›æ’¤çš„é£é™©è¯„åˆ†
        max_dd = abs(basic_metrics.get('max_drawdown', 0))
        if max_dd > 0.3:
            risk_scores.append(RiskLevel.EXTREME.value)
        elif max_dd > 0.2:
            risk_scores.append(RiskLevel.CRITICAL.value)
        elif max_dd > 0.1:
            risk_scores.append(RiskLevel.HIGH.value)
            
        # åŸºäºé»‘å¤©é¹…æ¦‚ç‡çš„é£é™©è¯„åˆ†
        if black_swan_prob > 0.05:
            risk_scores.append(RiskLevel.EXTREME.value)
        elif black_swan_prob > 0.02:
            risk_scores.append(RiskLevel.CRITICAL.value)
            
        # åŸºäºå‹åŠ›æµ‹è¯•ç»“æœçš„é£é™©è¯„åˆ†
        if stress_results:
            max_stress_loss = max([v for k, v in stress_results.items() if 'worst_loss' in k], default=0)
            portfolio_value = 1000000  # å‡è®¾ç»„åˆä»·å€¼
            stress_loss_ratio = max_stress_loss / portfolio_value
            
            if stress_loss_ratio > 0.5:
                risk_scores.append(RiskLevel.EXTREME.value)
            elif stress_loss_ratio > 0.3:
                risk_scores.append(RiskLevel.CRITICAL.value)
                
        # å–æœ€é«˜é£é™©ç­‰çº§
        if risk_scores:
            max_risk_score = max(risk_scores)
            return RiskLevel(max_risk_score)
        else:
            return RiskLevel.LOW
            
    def _generate_risk_recommendations(self, overall_risk: RiskLevel,
                                     basic_metrics: Dict[str, float],
                                     enhanced_metrics: Dict[str, Any],
                                     stress_results: Dict[str, float]) -> List[str]:
        """ç”Ÿæˆé£é™©ç®¡ç†å»ºè®®"""
        recommendations = []
        
        if overall_risk == RiskLevel.EXTREME:
            recommendations.extend([
                "âš ï¸ æç«¯é£é™©è­¦å‘Šï¼šå»ºè®®ç«‹å³å‡ä»“è‡³æœ€ä½æ°´å¹³",
                "ğŸ”´ å¯åŠ¨ç´§æ€¥é£é™©ç®¡ç†ç¨‹åº",
                "ğŸ“Š æš‚åœè‡ªåŠ¨äº¤æ˜“ï¼Œå¯ç”¨äººå·¥å®¡æ ¸",
                "ğŸ’° è€ƒè™‘å¯¹å†²æ“ä½œä»¥é™ä½ç³»ç»Ÿæ€§é£é™©"
            ])
        elif overall_risk == RiskLevel.CRITICAL:
            recommendations.extend([
                "ğŸš¨ é«˜é£é™©è­¦å‘Šï¼šå»ºè®®å¤§å¹…å‡å°‘ä»“ä½",
                "ğŸ“‰ å¢åŠ ç°é‡‘æ¯”ä¾‹è‡³50%ä»¥ä¸Š",
                "ğŸ›¡ï¸ å¯ç”¨ä¸¥æ ¼çš„æ­¢æŸæœºåˆ¶",
                "ğŸ“ˆ è€ƒè™‘åå‘ETFå¯¹å†²"
            ])
        elif overall_risk == RiskLevel.HIGH:
            recommendations.extend([
                "âš¡ é£é™©åé«˜ï¼šå»ºè®®é€‚åº¦å‡ä»“",
                "ğŸ¯ å°†å•ä¸€ä»“ä½é™åˆ¶åœ¨5%ä»¥ä¸‹",
                "ğŸ“Š å¢åŠ é£é™©ç›‘æ§é¢‘ç‡",
                "ğŸ’¼ è€ƒè™‘åˆ†æ•£æŠ•èµ„ç­–ç•¥"
            ])
        elif overall_risk == RiskLevel.MEDIUM:
            recommendations.extend([
                "âš–ï¸ é£é™©é€‚ä¸­ï¼šä¿æŒå½“å‰é£é™©ç®¡ç†ç­–ç•¥",
                "ğŸ”„ å®šæœŸé‡æ–°å¹³è¡¡æŠ•èµ„ç»„åˆ",
                "ğŸ“‹ ç›‘æ§å…³é”®é£é™©æŒ‡æ ‡å˜åŒ–"
            ])
        else:
            recommendations.extend([
                "âœ… é£é™©è¾ƒä½ï¼šå¯é€‚åº¦å¢åŠ ä»“ä½",
                "ğŸ“ˆ è€ƒè™‘å¢åŠ æˆé•¿æ€§èµ„äº§é…ç½®"
            ])
            
        # åŸºäºå…·ä½“æŒ‡æ ‡çš„å»ºè®®
        if basic_metrics.get('sharpe_ratio', 0) < 0.5:
            recommendations.append("ğŸ“Š å¤æ™®æ¯”ç‡åä½ï¼Œå»ºè®®ä¼˜åŒ–æ”¶ç›Šé£é™©æ¯”")
            
        if abs(basic_metrics.get('max_drawdown', 0)) > 0.15:
            recommendations.append("ğŸ“‰ æœ€å¤§å›æ’¤è¿‡å¤§ï¼Œå»ºè®®åŠ å¼ºæ­¢æŸç®¡ç†")
            
        if enhanced_metrics.get('extreme_event_frequency', 0) > 0.1:
            recommendations.append("âš¡ æç«¯äº‹ä»¶é¢‘ç‡è¾ƒé«˜ï¼Œå»ºè®®å¢åŠ é˜²å¾¡æ€§é…ç½®")
            
        return recommendations
        
    def _calculate_skewness(self, data: np.ndarray) -> float:
        """è®¡ç®—ååº¦"""
        mean = np.mean(data)
        std = np.std(data)
        if std == 0:
            return 0
        n = len(data)
        skewness = (n / ((n - 1) * (n - 2))) * np.sum(((data - mean) / std) ** 3)
        return skewness
        
    def _calculate_kurtosis(self, data: np.ndarray) -> float:
        """è®¡ç®—å³°åº¦"""
        mean = np.mean(data)
        std = np.std(data)
        if std == 0:
            return 0
        n = len(data)
        kurtosis = (n * (n + 1) / ((n - 1) * (n - 2) * (n - 3))) * np.sum(((data - mean) / std) ** 4) - 3 * (n - 1) ** 2 / ((n - 2) * (n - 3))
        return kurtosis + 3  # è¿”å›è¶…é¢å³°åº¦ + 3
        
    async def real_time_risk_monitoring(self, portfolio_data: Dict[str, Any],
                                      market_data: pd.DataFrame) -> Dict[str, Any]:
        """å®æ—¶é£é™©ç›‘æ§"""
        try:
            # å¿«é€Ÿé£é™©è¯„ä¼°
            basic_metrics = self._calculate_basic_metrics(portfolio_data, market_data)
            
            # æ£€æŸ¥é£é™©é˜ˆå€¼è§¦å‘
            alerts = []
            current_var = abs(basic_metrics.get('var_1d', 0))
            
            for level, threshold in self.risk_thresholds.items():
                if current_var >= threshold:
                    alerts.append({
                        'level': level.name,
                        'message': f'VaRè¶…è¿‡{level.name}çº§åˆ«é˜ˆå€¼: {current_var:.4f} >= {threshold:.4f}',
                        'timestamp': datetime.now()
                    })
                    break
                    
            # æ£€æŸ¥æœ€å¤§å›æ’¤
            max_dd = abs(basic_metrics.get('max_drawdown', 0))
            if max_dd > 0.1:
                alerts.append({
                    'level': 'HIGH',
                    'message': f'æœ€å¤§å›æ’¤è¿‡å¤§: {max_dd:.4f}',
                    'timestamp': datetime.now()
                })
                
            return {
                'timestamp': datetime.now(),
                'basic_metrics': basic_metrics,
                'alerts': alerts,
                'risk_status': 'NORMAL' if not alerts else 'ALERT'
            }
            
        except Exception as e:
            self.logger.error(f"å®æ—¶é£é™©ç›‘æ§å¤±è´¥: {e}")
            return {'error': str(e), 'timestamp': datetime.now()}