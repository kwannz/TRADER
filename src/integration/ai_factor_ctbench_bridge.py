"""
AI Factor Discovery & CTBench Integration Bridge
AIå› å­å‘ç°ä¸CTBenchç³»ç»Ÿé›†æˆæ¡¥æ¥å™¨
"""

import asyncio
import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timedelta
import json
import logging
from dataclasses import dataclass

from .model_service import CTBenchModelService, get_ctbench_service
from .risk_control.enhanced_risk_manager import EnhancedRiskManager

@dataclass
class FactorEnhancementRequest:
    """å› å­å¢å¼ºè¯·æ±‚"""
    factor_name: str
    factor_formula: str
    factor_type: str
    base_data: np.ndarray
    enhancement_scenarios: List[str]
    validation_period: int = 252

@dataclass
class FactorValidationResult:
    """å› å­éªŒè¯ç»“æœ"""
    factor_name: str
    ctbench_ic: float
    synthetic_data_ic: float
    stress_test_results: Dict[str, float]
    robustness_score: float
    enhancement_recommendations: List[str]

class AIFactorCTBenchBridge:
    """AIå› å­å‘ç°ä¸CTBenché›†æˆæ¡¥æ¥å™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.ctbench_service: Optional[CTBenchModelService] = None
        self.risk_manager: Optional[EnhancedRiskManager] = None
        
        # é›†æˆé…ç½®
        self.config = {
            'data_augmentation_factor': 10,
            'stress_test_scenarios': ['black_swan', 'high_volatility', 'bear_market'],
            'validation_thresholds': {
                'min_ic': 0.02,
                'min_robustness': 0.6,
                'max_drawdown': 0.15
            }
        }
        
    async def initialize(self):
        """åˆå§‹åŒ–é›†æˆæœåŠ¡"""
        try:
            self.ctbench_service = await get_ctbench_service()
            self.risk_manager = EnhancedRiskManager()
            await self.risk_manager.initialize()
            
            self.logger.info("AIå› å­å‘ç°ä¸CTBenché›†æˆæ¡¥æ¥å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"é›†æˆæ¡¥æ¥å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
            
    async def enhance_factor_with_synthetic_data(self, 
                                               factor_request: FactorEnhancementRequest) -> Dict[str, Any]:
        """ä½¿ç”¨åˆæˆæ•°æ®å¢å¼ºå› å­éªŒè¯"""
        try:
            self.logger.info(f"å¼€å§‹å¢å¼ºå› å­: {factor_request.factor_name}")
            
            # 1. ç”ŸæˆåŸºç¡€åˆæˆæ•°æ®è¿›è¡Œå› å­è®¡ç®—
            synthetic_data_result = await self._generate_synthetic_data_for_factor(
                factor_request.base_data,
                factor_request.enhancement_scenarios
            )
            
            # 2. åœ¨åˆæˆæ•°æ®ä¸Šè®¡ç®—å› å­å€¼
            synthetic_factor_values = self._calculate_factor_on_synthetic_data(
                factor_request.factor_formula,
                synthetic_data_result['augmented_data']
            )
            
            # 3. è¿›è¡Œå‹åŠ›æµ‹è¯•
            stress_test_results = await self._stress_test_factor(
                factor_request,
                synthetic_factor_values
            )
            
            # 4. è®¡ç®—å› å­ç¨³å¥æ€§è¯„åˆ†
            robustness_score = self._calculate_factor_robustness(
                synthetic_factor_values,
                stress_test_results
            )
            
            # 5. ç”Ÿæˆå¢å¼ºå»ºè®®
            enhancement_recommendations = await self._generate_enhancement_recommendations(
                factor_request,
                synthetic_factor_values,
                stress_test_results
            )
            
            return {
                'success': True,
                'factor_name': factor_request.factor_name,
                'synthetic_data_stats': {
                    'original_samples': factor_request.base_data.shape[0],
                    'augmented_samples': synthetic_data_result['augmentation_factor'],
                    'scenarios_tested': len(factor_request.enhancement_scenarios)
                },
                'factor_performance': {
                    'synthetic_ic_mean': np.mean([v['ic'] for v in synthetic_factor_values.values()]),
                    'robustness_score': robustness_score,
                    'stress_test_survival_rate': self._calculate_survival_rate(stress_test_results)
                },
                'stress_test_results': stress_test_results,
                'enhancement_recommendations': enhancement_recommendations,
                'ctbench_integration_metrics': {
                    'data_augmentation_quality': synthetic_data_result.get('quality_score', 0.0),
                    'scenario_coverage': len(factor_request.enhancement_scenarios) / 5.0,
                    'validation_confidence': robustness_score
                }
            }
            
        except Exception as e:
            self.logger.error(f"å› å­å¢å¼ºå¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}
            
    async def _generate_synthetic_data_for_factor(self, 
                                                base_data: np.ndarray,
                                                scenarios: List[str]) -> Dict[str, Any]:
        """ä¸ºå› å­éªŒè¯ç”Ÿæˆåˆæˆæ•°æ®"""
        # ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®
        if len(base_data.shape) == 2:
            base_data = base_data.reshape(1, base_data.shape[0], base_data.shape[1])
            
        # ç”Ÿæˆå¤šåœºæ™¯å¢å¼ºæ•°æ®
        augmented_results = {}
        total_augmented_samples = 0
        
        for scenario in scenarios:
            try:
                scenario_result = self.ctbench_service.synthetic_manager.generate_market_scenarios(
                    scenario, base_data, 50  # æ¯ä¸ªåœºæ™¯ç”Ÿæˆ50ä¸ªæ ·æœ¬
                )
                
                if scenario_result['success']:
                    augmented_results[scenario] = scenario_result['data']
                    total_augmented_samples += scenario_result['num_scenarios']
                    
            except Exception as e:
                self.logger.warning(f"åœºæ™¯ {scenario} æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
                
        # åˆå¹¶æ‰€æœ‰å¢å¼ºæ•°æ®
        all_augmented_data = []
        for scenario_data in augmented_results.values():
            all_augmented_data.extend(scenario_data)
            
        return {
            'success': True,
            'augmented_data': np.array(all_augmented_data) if all_augmented_data else base_data,
            'augmentation_factor': total_augmented_samples,
            'scenarios': augmented_results,
            'quality_score': self._assess_synthetic_data_quality(all_augmented_data, base_data)
        }
        
    def _calculate_factor_on_synthetic_data(self, 
                                          factor_formula: str,
                                          synthetic_data: np.ndarray) -> Dict[str, Any]:
        """åœ¨åˆæˆæ•°æ®ä¸Šè®¡ç®—å› å­å€¼"""
        factor_results = {}
        
        try:
            # ä¸ºæ¯ä¸ªåˆæˆæ ·æœ¬è®¡ç®—å› å­å€¼
            for i, sample in enumerate(synthetic_data):
                # è½¬æ¢ä¸ºDataFrameæ ¼å¼ä¾¿äºè®¡ç®—
                sample_df = pd.DataFrame(sample, columns=['open', 'high', 'low', 'close', 'volume', 'adj_close'])
                
                # è®¡ç®—å› å­å€¼ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…éœ€è¦è§£æfactor_formulaï¼‰
                factor_value = self._evaluate_factor_formula(factor_formula, sample_df)
                
                # è®¡ç®—å‰ç»æ”¶ç›Šç‡
                forward_returns = self._calculate_forward_returns(sample_df['close'], periods=5)
                
                # è®¡ç®—IC
                if len(factor_value) > 0 and len(forward_returns) > 0:
                    ic = np.corrcoef(factor_value, forward_returns)[0, 1] if not np.isnan(np.corrcoef(factor_value, forward_returns)[0, 1]) else 0
                    factor_results[f'sample_{i}'] = {
                        'factor_values': factor_value,
                        'forward_returns': forward_returns,
                        'ic': ic
                    }
                    
        except Exception as e:
            self.logger.error(f"åˆæˆæ•°æ®å› å­è®¡ç®—å¤±è´¥: {e}")
            
        return factor_results
        
    def _evaluate_factor_formula(self, formula: str, data: pd.DataFrame) -> np.ndarray:
        """è¯„ä¼°å› å­å…¬å¼ï¼ˆç®€åŒ–å®ç°ï¼‰"""
        try:
            # æ·»åŠ å¸¸ç”¨çš„æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
            data['returns'] = data['close'].pct_change()
            data['sma_20'] = data['close'].rolling(20).mean()
            data['std_20'] = data['close'].rolling(20).std()
            data['rsi'] = self._calculate_rsi(data['close'])
            
            # ç®€åŒ–çš„å…¬å¼è¯„ä¼°ï¼ˆå®é™…åº”è¯¥ä½¿ç”¨æ›´å®‰å…¨çš„è¡¨è¾¾å¼è§£æï¼‰
            # è¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼Œç”Ÿäº§ç¯å¢ƒéœ€è¦æ›´ä¸¥æ ¼çš„å…¬å¼è§£æ
            if 'sma' in formula.lower():
                return data['sma_20'].values
            elif 'rsi' in formula.lower():
                return data['rsi'].values
            elif 'returns' in formula.lower():
                return data['returns'].values
            else:
                # é»˜è®¤è¿”å›ä»·æ ¼åŠ¨é‡
                return data['close'].pct_change(5).values
                
        except Exception as e:
            self.logger.warning(f"å› å­å…¬å¼è¯„ä¼°å¤±è´¥: {e}")
            return np.zeros(len(data))
            
    def _calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """è®¡ç®—RSIæŒ‡æ ‡"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs))
        
    def _calculate_forward_returns(self, prices: pd.Series, periods: int = 5) -> np.ndarray:
        """è®¡ç®—å‰ç»æ”¶ç›Šç‡"""
        return prices.pct_change(periods).shift(-periods).fillna(0).values
        
    async def _stress_test_factor(self, 
                                factor_request: FactorEnhancementRequest,
                                synthetic_factor_values: Dict[str, Any]) -> Dict[str, float]:
        """å¯¹å› å­è¿›è¡Œå‹åŠ›æµ‹è¯•"""
        stress_results = {}
        
        try:
            # ä½¿ç”¨CTBenchçš„å‹åŠ›æµ‹è¯•åŠŸèƒ½
            base_data_reshaped = factor_request.base_data.reshape(1, factor_request.base_data.shape[0], -1)
            
            stress_test_result = await self.ctbench_service.generate_stress_test_scenarios(
                base_data_reshaped,
                ['black_swan', 'high_volatility', 'bear_market']
            )
            
            if stress_test_result['success']:
                stress_scenarios = stress_test_result['stress_scenarios']
                
                for scenario_type, scenarios in stress_scenarios.items():
                    # åœ¨æ¯ä¸ªå‹åŠ›åœºæ™¯ä¸‹æµ‹è¯•å› å­è¡¨ç°
                    scenario_ics = []
                    
                    for scenario in scenarios[:10]:  # æµ‹è¯•å‰10ä¸ªåœºæ™¯
                        scenario_df = pd.DataFrame(scenario, columns=['open', 'high', 'low', 'close', 'volume', 'adj_close'])
                        
                        # è®¡ç®—å› å­å€¼
                        factor_values = self._evaluate_factor_formula(factor_request.factor_formula, scenario_df)
                        forward_returns = self._calculate_forward_returns(scenario_df['close'])
                        
                        # è®¡ç®—IC
                        if len(factor_values) > 5 and len(forward_returns) > 5:
                            ic = np.corrcoef(factor_values[5:], forward_returns[5:])[0, 1]
                            if not np.isnan(ic):
                                scenario_ics.append(ic)
                                
                    if scenario_ics:
                        stress_results[f'{scenario_type}_mean_ic'] = np.mean(scenario_ics)
                        stress_results[f'{scenario_type}_std_ic'] = np.std(scenario_ics)
                        stress_results[f'{scenario_type}_min_ic'] = np.min(scenario_ics)
                        
        except Exception as e:
            self.logger.error(f"å› å­å‹åŠ›æµ‹è¯•å¤±è´¥: {e}")
            
        return stress_results
        
    def _calculate_factor_robustness(self, 
                                   synthetic_factor_values: Dict[str, Any],
                                   stress_test_results: Dict[str, float]) -> float:
        """è®¡ç®—å› å­ç¨³å¥æ€§è¯„åˆ†"""
        try:
            # 1. åˆæˆæ•°æ®ICç¨³å®šæ€§è¯„åˆ†
            ics = [result['ic'] for result in synthetic_factor_values.values() if not np.isnan(result['ic'])]
            
            if not ics:
                return 0.0
                
            ic_stability = 1.0 - (np.std(ics) / (np.abs(np.mean(ics)) + 1e-8))
            ic_strength = min(abs(np.mean(ics)) / 0.05, 1.0)  # æ ‡å‡†åŒ–åˆ°0.05ä¸ºæ»¡åˆ†
            
            # 2. å‹åŠ›æµ‹è¯•ç¨³å®šæ€§è¯„åˆ†
            stress_stability = 0.0
            if stress_test_results:
                min_ics = [v for k, v in stress_test_results.items() if 'min_ic' in k]
                if min_ics:
                    stress_stability = min(1.0, (np.mean(min_ics) + 0.02) / 0.02)  # -0.02ä»¥ä¸Šä¸ºåŠæ ¼
                    
            # 3. ç»¼åˆç¨³å¥æ€§è¯„åˆ†
            robustness_score = 0.4 * ic_stability + 0.4 * ic_strength + 0.2 * stress_stability
            
            return max(0.0, min(1.0, robustness_score))
            
        except Exception as e:
            self.logger.error(f"ç¨³å¥æ€§è¯„åˆ†è®¡ç®—å¤±è´¥: {e}")
            return 0.0
            
    def _calculate_survival_rate(self, stress_test_results: Dict[str, float]) -> float:
        """è®¡ç®—å‹åŠ›æµ‹è¯•ç”Ÿå­˜ç‡"""
        if not stress_test_results:
            return 0.0
            
        min_ic_threshold = -0.05  # ICä½äº-0.05è§†ä¸ºå¤±æ•ˆ
        survival_count = 0
        total_tests = 0
        
        for key, value in stress_test_results.items():
            if 'min_ic' in key:
                total_tests += 1
                if value > min_ic_threshold:
                    survival_count += 1
                    
        return survival_count / total_tests if total_tests > 0 else 0.0
        
    async def _generate_enhancement_recommendations(self,
                                                  factor_request: FactorEnhancementRequest,
                                                  synthetic_factor_values: Dict[str, Any],
                                                  stress_test_results: Dict[str, float]) -> List[str]:
        """ç”Ÿæˆå› å­å¢å¼ºå»ºè®®"""
        recommendations = []
        
        try:
            # åˆ†æå› å­è¡¨ç°
            ics = [result['ic'] for result in synthetic_factor_values.values() if not np.isnan(result['ic'])]
            avg_ic = np.mean(ics) if ics else 0
            
            # åŸºäºè¡¨ç°ç”Ÿæˆå»ºè®®
            if abs(avg_ic) < 0.02:
                recommendations.append("ğŸ” å› å­ä¿¡å·è¾ƒå¼±ï¼Œå»ºè®®ç»“åˆå…¶ä»–æŒ‡æ ‡æˆ–è°ƒæ•´å‚æ•°")
                
            if len(ics) > 0 and np.std(ics) > 0.05:
                recommendations.append("âš¡ å› å­ç¨³å®šæ€§è¾ƒå·®ï¼Œå»ºè®®å¢åŠ å¹³æ»‘å¤„ç†æˆ–é£æ§æœºåˆ¶")
                
            # åŸºäºå‹åŠ›æµ‹è¯•ç»“æœçš„å»ºè®®
            survival_rate = self._calculate_survival_rate(stress_test_results)
            if survival_rate < 0.7:
                recommendations.append("ğŸ›¡ï¸ æç«¯å¸‚åœºä¸‹è¡¨ç°ä¸ä½³ï¼Œå»ºè®®å¢åŠ é˜²å¾¡æ€§è°ƒæ•´")
                
            # CTBenchç‰¹å®šå»ºè®®
            recommendations.extend([
                "ğŸ“Š å»ºè®®ä½¿ç”¨CTBenchç”Ÿæˆæ›´å¤šæ ·åŒ–çš„æµ‹è¯•åœºæ™¯",
                "ğŸ”„ å¯é€šè¿‡CTBenchçš„æ•°æ®å¢å¼ºåŠŸèƒ½æ‰©å¤§å› å­éªŒè¯æ ·æœ¬",
                "âš ï¸ å»ºè®®é›†æˆå®æ—¶é£é™©ç›‘æ§ç³»ç»Ÿç›‘æ§å› å­è¡¨ç°"
            ])
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆå¢å¼ºå»ºè®®å¤±è´¥: {e}")
            recommendations.append("âŒ å»ºè®®ç”Ÿæˆè¿‡ç¨‹å‡ºé”™ï¼Œéœ€è¦äººå·¥æ£€æŸ¥")
            
        return recommendations
        
    def _assess_synthetic_data_quality(self, 
                                     synthetic_data: List[np.ndarray],
                                     original_data: np.ndarray) -> float:
        """è¯„ä¼°åˆæˆæ•°æ®è´¨é‡"""
        try:
            if not synthetic_data:
                return 0.0
                
            # è®¡ç®—ç»Ÿè®¡ç›¸ä¼¼æ€§
            orig_stats = {
                'mean': np.mean(original_data[:, :, 0]),  # ä»·æ ¼å‡å€¼
                'std': np.std(original_data[:, :, 0]),    # ä»·æ ¼æ ‡å‡†å·®
                'vol': np.std(np.diff(original_data[0, :, 0]) / original_data[0, :-1, 0])  # æ”¶ç›Šç‡æ³¢åŠ¨ç‡
            }
            
            synthetic_stats = []
            for sample in synthetic_data:
                sample_stats = {
                    'mean': np.mean(sample[:, 0]),
                    'std': np.std(sample[:, 0]),
                    'vol': np.std(np.diff(sample[:, 0]) / sample[:-1, 0])
                }
                synthetic_stats.append(sample_stats)
                
            # è®¡ç®—ç›¸ä¼¼æ€§è¯„åˆ†
            similarity_scores = []
            for stat_key in orig_stats.keys():
                orig_val = orig_stats[stat_key]
                synth_vals = [s[stat_key] for s in synthetic_stats]
                
                if orig_val != 0:
                    relative_errors = [abs(s - orig_val) / abs(orig_val) for s in synth_vals]
                    similarity_score = 1.0 - min(1.0, np.mean(relative_errors))
                    similarity_scores.append(similarity_score)
                    
            return np.mean(similarity_scores) if similarity_scores else 0.0
            
        except Exception as e:
            self.logger.error(f"åˆæˆæ•°æ®è´¨é‡è¯„ä¼°å¤±è´¥: {e}")
            return 0.0
            
    async def batch_factor_validation(self, 
                                    factor_requests: List[FactorEnhancementRequest]) -> List[Dict[str, Any]]:
        """æ‰¹é‡å› å­éªŒè¯"""
        validation_results = []
        
        self.logger.info(f"å¼€å§‹æ‰¹é‡éªŒè¯ {len(factor_requests)} ä¸ªå› å­")
        
        # å¹¶è¡Œå¤„ç†å¤šä¸ªå› å­
        tasks = []
        for factor_request in factor_requests:
            task = asyncio.create_task(
                self.enhance_factor_with_synthetic_data(factor_request)
            )
            tasks.append(task)
            
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                self.logger.error(f"å› å­ {factor_requests[i].factor_name} éªŒè¯å¤±è´¥: {result}")
                validation_results.append({
                    'success': False,
                    'factor_name': factor_requests[i].factor_name,
                    'error': str(result)
                })
            else:
                validation_results.append(result)
                
        return validation_results
        
    async def real_time_factor_monitoring(self, factor_names: List[str]):
        """å®æ—¶å› å­ç›‘æ§"""
        self.logger.info(f"å¼€å§‹å®æ—¶ç›‘æ§ {len(factor_names)} ä¸ªå› å­")
        
        while True:
            try:
                for factor_name in factor_names:
                    # è·å–æœ€æ–°å¸‚åœºæ•°æ®
                    # latest_data = await self.get_latest_market_data()
                    
                    # ä½¿ç”¨CTBenchç”Ÿæˆæµ‹è¯•åœºæ™¯
                    # test_scenarios = await self.generate_test_scenarios(latest_data)
                    
                    # ç›‘æ§å› å­åœ¨æ–°åœºæ™¯ä¸‹çš„è¡¨ç°
                    # performance = await self.monitor_factor_performance(factor_name, test_scenarios)
                    
                    # å‘é€ç›‘æ§æŠ¥å‘Š
                    # await self.send_monitoring_report(factor_name, performance)
                    pass
                    
                await asyncio.sleep(300)  # 5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                self.logger.error(f"å®æ—¶å› å­ç›‘æ§å‡ºé”™: {e}")
                await asyncio.sleep(60)
                
    def generate_integration_report(self, validation_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”Ÿæˆé›†æˆæŠ¥å‘Š"""
        successful_validations = [r for r in validation_results if r.get('success', False)]
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'total_factors': len(validation_results),
            'successful_validations': len(successful_validations),
            'success_rate': len(successful_validations) / len(validation_results) if validation_results else 0,
            'ctbench_integration_stats': {
                'total_synthetic_samples_generated': sum(
                    r.get('synthetic_data_stats', {}).get('augmented_samples', 0) 
                    for r in successful_validations
                ),
                'scenarios_tested': sum(
                    r.get('synthetic_data_stats', {}).get('scenarios_tested', 0)
                    for r in successful_validations
                ),
                'average_robustness_score': np.mean([
                    r.get('factor_performance', {}).get('robustness_score', 0)
                    for r in successful_validations
                ]) if successful_validations else 0
            },
            'top_performing_factors': sorted(
                successful_validations,
                key=lambda x: x.get('factor_performance', {}).get('robustness_score', 0),
                reverse=True
            )[:5],
            'common_recommendations': self._extract_common_recommendations(successful_validations)
        }
        
        return report
        
    def _extract_common_recommendations(self, validation_results: List[Dict[str, Any]]) -> List[str]:
        """æå–é€šç”¨å»ºè®®"""
        all_recommendations = []
        for result in validation_results:
            all_recommendations.extend(result.get('enhancement_recommendations', []))
            
        # ç»Ÿè®¡æœ€å¸¸è§çš„å»ºè®®
        recommendation_counts = {}
        for rec in all_recommendations:
            recommendation_counts[rec] = recommendation_counts.get(rec, 0) + 1
            
        # è¿”å›å‡ºç°é¢‘ç‡æœ€é«˜çš„å»ºè®®
        common_recommendations = sorted(
            recommendation_counts.items(),
            key=lambda x: x[1],
            reverse=True
        )[:5]
        
        return [rec[0] for rec in common_recommendations]

# å•ä¾‹æ¨¡å¼çš„é›†æˆæ¡¥æ¥å™¨
ai_factor_ctbench_bridge = None

async def get_ai_factor_bridge() -> AIFactorCTBenchBridge:
    """è·å–AIå› å­CTBenché›†æˆæ¡¥æ¥å™¨å•ä¾‹"""
    global ai_factor_ctbench_bridge
    if ai_factor_ctbench_bridge is None:
        ai_factor_ctbench_bridge = AIFactorCTBenchBridge()
        await ai_factor_ctbench_bridge.initialize()
    return ai_factor_ctbench_bridge