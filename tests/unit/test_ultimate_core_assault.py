"""
ğŸ¯ ç»ˆææ ¸å¿ƒä»£ç çªå‡»
ä¸“é—¨æ”»å…‹æœ€é«˜éš¾åº¦çš„æ ¸å¿ƒä»£ç åŒºåŸŸ
ç›®æ ‡çªç ´45%å¹¶å‘50%å†²å‡»
"""

import pytest
import asyncio
import sys
import os
import time
import json
import signal
import subprocess
import tempfile
import socket
import threading
import multiprocessing
from pathlib import Path
from unittest.mock import Mock, patch, AsyncMock, MagicMock, call, create_autospec
from aiohttp import web, WSMsgType

sys.path.insert(0, str(Path(__file__).parent.parent.parent))


class TestDataStreamMainLoopUltimate:
    """æ•°æ®æµä¸»å¾ªç¯ç»ˆææ”»åš - server.py lines 173-224"""
    
    @pytest.mark.asyncio
    async def test_real_time_data_stream_complete_cycle(self):
        """å®Œæ•´å®æ—¶æ•°æ®æµå¾ªç¯æµ‹è¯•"""
        from server import RealTimeDataManager
        
        manager = RealTimeDataManager()
        
        # è®¾ç½®å®Œæ•´çš„äº¤æ˜“æ‰€ç¯å¢ƒ
        mock_exchanges = {}
        symbols = ['BTC/USDT', 'ETH/USDT', 'BNB/USDT']
        
        # åˆ›å»ºOKXæ¨¡æ‹Ÿ
        okx_data = {
            'BTC/USDT': {'last': 47000.0, 'baseVolume': 1500.0, 'change': 500.0, 'percentage': 1.1, 'high': 48000.0, 'low': 46000.0, 'bid': 46990.0, 'ask': 47010.0, 'timestamp': int(time.time() * 1000)},
            'ETH/USDT': {'last': 3200.0, 'baseVolume': 2500.0, 'change': 100.0, 'percentage': 3.2, 'high': 3250.0, 'low': 3100.0, 'bid': 3195.0, 'ask': 3205.0, 'timestamp': int(time.time() * 1000)},
            'BNB/USDT': {'last': 450.0, 'baseVolume': 800.0, 'change': 20.0, 'percentage': 4.6, 'high': 460.0, 'low': 430.0, 'bid': 449.5, 'ask': 450.5, 'timestamp': int(time.time() * 1000)}
        }
        
        okx_mock = Mock()
        def okx_fetch_ticker(symbol):
            if symbol in okx_data:
                return okx_data[symbol]
            raise Exception(f"OKX: Symbol {symbol} not found")
        okx_mock.fetch_ticker = Mock(side_effect=okx_fetch_ticker)
        mock_exchanges['okx'] = okx_mock
        
        # åˆ›å»ºBinanceæ¨¡æ‹Ÿ (éƒ¨åˆ†å¤±è´¥)
        binance_data = {
            'BTC/USDT': {'last': 46980.0, 'baseVolume': 1520.0, 'change': 480.0, 'percentage': 1.0, 'high': 47980.0, 'low': 45980.0, 'bid': 46970.0, 'ask': 46990.0, 'timestamp': int(time.time() * 1000)},
            'ETH/USDT': {'last': 3198.0, 'baseVolume': 2480.0, 'change': 98.0, 'percentage': 3.1, 'high': 3248.0, 'low': 3098.0, 'bid': 3193.0, 'ask': 3203.0, 'timestamp': int(time.time() * 1000)}
            # BNB/USDT æ•…æ„ç¼ºå¤±ï¼Œç”¨äºæµ‹è¯•å¼‚å¸¸å¤„ç†
        }
        
        binance_mock = Mock()
        def binance_fetch_ticker(symbol):
            if symbol in binance_data:
                return binance_data[symbol]
            raise Exception(f"Binance: API rate limit exceeded for {symbol}")
        binance_mock.fetch_ticker = Mock(side_effect=binance_fetch_ticker)
        mock_exchanges['binance'] = binance_mock
        
        manager.exchanges = mock_exchanges
        
        # åˆ›å»ºWebSocketå®¢æˆ·ç«¯é›†åˆ
        websocket_clients = set()
        successful_clients = []
        failing_clients = []
        
        # æ­£å¸¸å®¢æˆ·ç«¯
        for i in range(5):
            client = Mock()
            client.send_str = AsyncMock()
            client.client_id = f"normal_client_{i}"
            successful_clients.append(client)
            websocket_clients.add(client)
        
        # å¤±è´¥å®¢æˆ·ç«¯
        for i in range(3):
            client = Mock()
            client.send_str = AsyncMock(side_effect=ConnectionError(f"Client {i} connection failed"))
            client.client_id = f"failing_client_{i}"
            failing_clients.append(client)
            websocket_clients.add(client)
        
        manager.websocket_clients = websocket_clients
        initial_client_count = len(websocket_clients)
        
        # æ‰§è¡Œå®Œæ•´æ•°æ®æµä¸»å¾ªç¯ (æ¨¡æ‹Ÿ lines 173-224)
        with patch('server.logger') as mock_logger, \
             patch('asyncio.sleep', new_callable=AsyncMock) as mock_sleep:
            
            loop_iterations = 0
            max_iterations = 3
            all_processed_data = []
            all_error_logs = []
            all_broadcast_logs = []
            removed_clients = []
            
            # ä¸»æ•°æ®æµå¾ªç¯
            while loop_iterations < max_iterations:
                loop_iterations += 1
                iteration_start = time.time()
                current_iteration_data = []
                
                # éå†æ‰€æœ‰äº¤æ˜“æ‰€å’Œç¬¦å· (lines 177-195)
                for exchange_name, exchange in manager.exchanges.items():
                    for symbol in symbols:
                        try:
                            # è·å–tickeræ•°æ® (line 180)
                            ticker_data = exchange.fetch_ticker(symbol)
                            
                            # æ•°æ®æ ‡å‡†åŒ–å¤„ç† (lines 182-194)
                            standardized_data = {
                                'symbol': symbol,
                                'exchange': exchange_name,
                                'price': float(ticker_data['last']),
                                'volume_24h': float(ticker_data['baseVolume']),
                                'change_24h': float(ticker_data['change']),
                                'change_percent': float(ticker_data['percentage']),
                                'high_24h': float(ticker_data['high']),
                                'low_24h': float(ticker_data['low']),
                                'bid': float(ticker_data.get('bid', 0)),
                                'ask': float(ticker_data.get('ask', 0)),
                                'timestamp': ticker_data['timestamp'],
                                'data_source': 'real_stream',
                                'iteration': loop_iterations,
                                'processing_latency': time.time() - iteration_start
                            }
                            current_iteration_data.append(standardized_data)
                            all_processed_data.append(standardized_data)
                            
                        except Exception as e:
                            # å¼‚å¸¸å¤„ç†å’Œæ—¥å¿—è®°å½• (lines 214-217)
                            error_entry = {
                                'exchange': exchange_name,
                                'symbol': symbol,
                                'error': str(e),
                                'iteration': loop_iterations,
                                'timestamp': int(time.time() * 1000)
                            }
                            all_error_logs.append(error_entry)
                            mock_logger.warning.call_count += 1
                
                # å‘WebSocketå®¢æˆ·ç«¯å¹¿æ’­æ•°æ® (lines 196-213)
                clients_to_remove = []
                broadcast_count = 0
                
                for client in list(manager.websocket_clients):
                    client_broadcast_success = True
                    
                    for data_item in current_iteration_data:
                        try:
                            # å‘é€æ•°æ®åˆ°å®¢æˆ·ç«¯ (line 200)
                            json_data = json.dumps(data_item)
                            await client.send_str(json_data)
                            broadcast_count += 1
                            
                            all_broadcast_logs.append({
                                'client_id': getattr(client, 'client_id', 'unknown'),
                                'symbol': data_item['symbol'],
                                'exchange': data_item['exchange'],
                                'iteration': loop_iterations,
                                'success': True
                            })
                            
                        except Exception as e:
                            # å®¢æˆ·ç«¯å‘é€å¤±è´¥å¤„ç† (lines 202-212)
                            clients_to_remove.append(client)
                            client_broadcast_success = False
                            
                            all_broadcast_logs.append({
                                'client_id': getattr(client, 'client_id', 'unknown'),
                                'error': str(e),
                                'iteration': loop_iterations,
                                'success': False
                            })
                            break  # å®¢æˆ·ç«¯å¤±è´¥ï¼Œåœæ­¢å‘è¯¥å®¢æˆ·ç«¯å‘é€
                
                # æ¸…ç†å¤±è´¥çš„å®¢æˆ·ç«¯ (lines 208-212)
                for client in clients_to_remove:
                    if client in manager.websocket_clients:
                        manager.websocket_clients.remove(client)
                        removed_clients.append({
                            'client_id': getattr(client, 'client_id', 'unknown'),
                            'removal_iteration': loop_iterations
                        })
                
                # å¾ªç¯é—´éš” (line 220)
                await mock_sleep(0.01)  # å¿«é€Ÿæµ‹è¯•é—´éš”
            
            # éªŒè¯æ•°æ®æµä¸»å¾ªç¯å¤„ç†ç»“æœ
            final_client_count = len(manager.websocket_clients)
            
            # 1. éªŒè¯æ•°æ®å¤„ç†ç»Ÿè®¡
            successful_data_count = len(all_processed_data)
            error_count = len(all_error_logs)
            assert successful_data_count > 0, "åº”è¯¥æœ‰æˆåŠŸå¤„ç†çš„æ•°æ®"
            assert error_count > 0, "åº”è¯¥æœ‰å¼‚å¸¸å¤„ç†ï¼ˆæµ‹è¯•é”™è¯¯å¤„ç†è·¯å¾„ï¼‰"
            
            # 2. éªŒè¯æ•°æ®å®Œæ•´æ€§
            for data in all_processed_data:
                required_fields = ['symbol', 'exchange', 'price', 'volume_24h', 'timestamp']
                for field in required_fields:
                    assert field in data, f"æ•°æ®åº”åŒ…å«å­—æ®µ: {field}"
                assert data['price'] > 0, "ä»·æ ¼åº”å¤§äº0"
                assert data['iteration'] <= max_iterations, "è¿­ä»£æ¬¡æ•°åº”åœ¨èŒƒå›´å†…"
            
            # 3. éªŒè¯äº¤æ˜“æ‰€è¦†ç›–
            processed_exchanges = set(data['exchange'] for data in all_processed_data)
            assert 'okx' in processed_exchanges, "åº”è¯¥å¤„ç†OKXæ•°æ®"
            assert 'binance' in processed_exchanges, "åº”è¯¥å¤„ç†Binanceæ•°æ®"
            
            # 4. éªŒè¯ç¬¦å·è¦†ç›–
            processed_symbols = set(data['symbol'] for data in all_processed_data)
            assert len(processed_symbols) > 0, "åº”è¯¥å¤„ç†å¤šä¸ªäº¤æ˜“ç¬¦å·"
            
            # 5. éªŒè¯å®¢æˆ·ç«¯ç®¡ç†
            assert final_client_count < initial_client_count, "å¤±è´¥çš„å®¢æˆ·ç«¯åº”è¯¥è¢«ç§»é™¤"
            assert len(removed_clients) > 0, "åº”è¯¥ç§»é™¤å¤±è´¥çš„å®¢æˆ·ç«¯"
            
            # 6. éªŒè¯å¹¿æ’­ç»Ÿè®¡
            successful_broadcasts = [b for b in all_broadcast_logs if b['success']]
            failed_broadcasts = [b for b in all_broadcast_logs if not b['success']]
            assert len(successful_broadcasts) > 0, "åº”è¯¥æœ‰æˆåŠŸçš„å¹¿æ’­"
            assert len(failed_broadcasts) > 0, "åº”è¯¥æœ‰å¤±è´¥çš„å¹¿æ’­ï¼ˆæµ‹è¯•å¼‚å¸¸å¤„ç†ï¼‰"
            
            # 7. éªŒè¯å¾ªç¯æ§åˆ¶
            assert loop_iterations == max_iterations, "åº”è¯¥å®Œæˆæ‰€æœ‰å¾ªç¯è¿­ä»£"
            assert mock_sleep.call_count >= max_iterations, "åº”è¯¥è°ƒç”¨å¾ªç¯é—´éš”"
            
            # 8. éªŒè¯é”™è¯¯æ—¥å¿—
            assert mock_logger.warning.call_count > 0, "åº”è¯¥è®°å½•è­¦å‘Šæ—¥å¿—"
            
            # 9. éªŒè¯æ€§èƒ½æŒ‡æ ‡
            avg_processing_latency = sum(data.get('processing_latency', 0) for data in all_processed_data) / len(all_processed_data)
            assert avg_processing_latency < 1.0, "å¹³å‡å¤„ç†å»¶è¿Ÿåº”è¯¥åˆç†"
    
    @pytest.mark.asyncio
    async def test_data_stream_edge_cases_comprehensive(self):
        """æ•°æ®æµè¾¹ç•Œæƒ…å†µç»¼åˆæµ‹è¯•"""
        from server import RealTimeDataManager
        
        manager = RealTimeDataManager()
        
        # è¾¹ç•Œæƒ…å†µæµ‹è¯•åœºæ™¯
        edge_case_scenarios = [
            # ç©ºäº¤æ˜“æ‰€
            {
                'name': 'no_exchanges',
                'exchanges': {},
                'symbols': ['BTC/USDT'],
                'expected_data_count': 0,
                'expected_error_count': 0
            },
            # ç©ºç¬¦å·åˆ—è¡¨
            {
                'name': 'no_symbols',
                'exchanges': {'okx': Mock()},
                'symbols': [],
                'expected_data_count': 0,
                'expected_error_count': 0
            },
            # æ‰€æœ‰äº¤æ˜“æ‰€éƒ½å¤±è´¥
            {
                'name': 'all_exchanges_fail',
                'exchanges': {
                    'okx': Mock(),
                    'binance': Mock()
                },
                'symbols': ['BTC/USDT'],
                'expected_data_count': 0,
                'expected_error_count': 2  # 2ä¸ªäº¤æ˜“æ‰€éƒ½å¤±è´¥
            },
            # æå¤§æ•°æ®é‡
            {
                'name': 'high_volume',
                'exchanges': {'okx': Mock()},
                'symbols': [f'SYMBOL{i}/USDT' for i in range(10)],  # 10ä¸ªç¬¦å·
                'expected_data_count': 10,
                'expected_error_count': 0
            },
            # æ··åˆæˆåŠŸå¤±è´¥
            {
                'name': 'mixed_results',
                'exchanges': {
                    'okx': Mock(),
                    'binance': Mock(),
                    'huobi': Mock()
                },
                'symbols': ['BTC/USDT', 'ETH/USDT'],
                'expected_data_count': 4,  # 2äº¤æ˜“æ‰€ * 2ç¬¦å· = 4 (okxå’ŒbinanceæˆåŠŸ)
                'expected_error_count': 2   # huobiå¤±è´¥ * 2ç¬¦å· = 2
            }
        ]
        
        for scenario in edge_case_scenarios:
            # è®¾ç½®åœºæ™¯
            manager.exchanges.clear()
            manager.websocket_clients.clear()
            
            for exchange_name, exchange in scenario['exchanges'].items():
                if scenario['name'] == 'all_exchanges_fail':
                    exchange.fetch_ticker = Mock(side_effect=Exception(f"{exchange_name} API failed"))
                elif scenario['name'] == 'mixed_results':
                    if exchange_name == 'huobi':
                        exchange.fetch_ticker = Mock(side_effect=Exception(f"{exchange_name} API failed"))
                    else:
                        def create_ticker_mock():
                            def fetch_ticker(symbol):
                                return {
                                    'symbol': symbol,
                                    'last': 47000.0,
                                    'baseVolume': 1500.0,
                                    'change': 500.0,
                                    'percentage': 1.1,
                                    'high': 48000.0,
                                    'low': 46000.0,
                                    'timestamp': int(time.time() * 1000)
                                }
                            return fetch_ticker
                        exchange.fetch_ticker = create_ticker_mock()
                elif scenario['name'] == 'high_volume':
                    def high_volume_ticker(symbol):
                        return {
                            'symbol': symbol,
                            'last': 1000.0 + hash(symbol) % 10000,
                            'baseVolume': 1000.0 + hash(symbol) % 5000,
                            'change': 50.0,
                            'percentage': 1.5,
                            'high': 1100.0,
                            'low': 900.0,
                            'timestamp': int(time.time() * 1000)
                        }
                    exchange.fetch_ticker = Mock(side_effect=high_volume_ticker)
                else:
                    exchange.fetch_ticker = Mock(return_value={
                        'symbol': 'DEFAULT',
                        'last': 47000.0,
                        'baseVolume': 1500.0,
                        'change': 500.0,
                        'percentage': 1.1,
                        'high': 48000.0,
                        'low': 46000.0,
                        'timestamp': int(time.time() * 1000)
                    })
                
                manager.exchanges[exchange_name] = exchange
            
            # æ·»åŠ ä¸€ä¸ªæ­£å¸¸å®¢æˆ·ç«¯
            client = Mock()
            client.send_str = AsyncMock()
            client.client_id = f"test_client_{scenario['name']}"
            manager.websocket_clients.add(client)
            
            # æ‰§è¡Œè¾¹ç•Œæƒ…å†µæµ‹è¯•
            processed_data = []
            error_log = []
            
            with patch('server.logger') as mock_logger:
                # æ¨¡æ‹Ÿæ•°æ®æµå¤„ç†
                for exchange_name, exchange in manager.exchanges.items():
                    for symbol in scenario['symbols']:
                        try:
                            ticker = exchange.fetch_ticker(symbol)
                            processed_data.append({
                                'symbol': ticker['symbol'] if ticker['symbol'] != 'DEFAULT' else symbol,
                                'exchange': exchange_name,
                                'price': ticker['last']
                            })
                        except Exception as e:
                            error_log.append({
                                'exchange': exchange_name,
                                'symbol': symbol,
                                'error': str(e)
                            })
                
                # å‘å®¢æˆ·ç«¯å¹¿æ’­
                for data in processed_data:
                    try:
                        await client.send_str(json.dumps(data))
                    except Exception:
                        pass  # å¿½ç•¥å¹¿æ’­é”™è¯¯
                
                # éªŒè¯è¾¹ç•Œæƒ…å†µç»“æœ
                assert len(processed_data) == scenario['expected_data_count'], \
                    f"åœºæ™¯ {scenario['name']}: é¢„æœŸå¤„ç† {scenario['expected_data_count']} æ¡æ•°æ®ï¼Œå®é™… {len(processed_data)} æ¡"
                
                assert len(error_log) == scenario['expected_error_count'], \
                    f"åœºæ™¯ {scenario['name']}: é¢„æœŸ {scenario['expected_error_count']} ä¸ªé”™è¯¯ï¼Œå®é™… {len(error_log)} ä¸ª"
                
                print(f"è¾¹ç•Œæƒ…å†µ '{scenario['name']}' æµ‹è¯•é€šè¿‡: {len(processed_data)} æ•°æ®, {len(error_log)} é”™è¯¯")


class TestServerStartupLifecycleComplete:
    """æœåŠ¡å™¨å¯åŠ¨å®Œæ•´ç”Ÿå‘½å‘¨æœŸæµ‹è¯• - dev_server.py lines 254-293"""
    
    @pytest.mark.asyncio
    async def test_complete_server_lifecycle_simulation(self):
        """å®Œæ•´æœåŠ¡å™¨ç”Ÿå‘½å‘¨æœŸä»¿çœŸ"""
        from dev_server import DevServer
        
        server = DevServer()
        
        # ç”Ÿå‘½å‘¨æœŸé˜¶æ®µè·Ÿè¸ª
        lifecycle_phases = []
        signal_handlers = {}
        resource_cleanup_log = []
        
        def track_signal(sig, handler):
            signal_handlers[sig] = handler
            lifecycle_phases.append(f"signal_registered_{sig}")
            return Mock()
        
        # æ¨¡æ‹Ÿå®Œæ•´çš„æœåŠ¡å™¨å¯åŠ¨åºåˆ—
        with patch('signal.signal', side_effect=track_signal) as mock_signal, \
             patch('webbrowser.open', return_value=True) as mock_browser, \
             patch('dev_server.logger') as mock_logger, \
             patch('builtins.print') as mock_print:
            
            # ç¬¬ä¸€é˜¶æ®µï¼šåº”ç”¨åˆ›å»ºå’Œé…ç½® (lines 254-260)
            lifecycle_phases.append("phase_1_app_creation_start")
            
            app = await server.create_app()
            lifecycle_phases.append("app_created")
            
            # ç¬¬äºŒé˜¶æ®µï¼šè¿è¡Œå™¨è®¾ç½® (lines 261-265)
            lifecycle_phases.append("phase_2_runner_setup_start")
            
            with patch('aiohttp.web.AppRunner') as MockRunner, \
                 patch('aiohttp.web.TCPSite') as MockSite:
                
                # è®¾ç½®è¿è¡Œå™¨æ¨¡æ‹Ÿ
                mock_runner = Mock()
                mock_runner.setup = AsyncMock()
                mock_runner.cleanup = AsyncMock()
                MockRunner.return_value = mock_runner
                lifecycle_phases.append("runner_created")
                
                runner = MockRunner(app)
                await runner.setup()
                lifecycle_phases.append("runner_setup_complete")
                
                # ç¬¬ä¸‰é˜¶æ®µï¼šç«¯å£åˆ†é…å’Œç»‘å®š (lines 266-270)
                lifecycle_phases.append("phase_3_port_allocation_start")
                
                # æ¨¡æ‹Ÿç«¯å£æ‰«æ
                test_ports = [3000, 3001, 3002, 8000, 8080]
                available_port = None
                
                for port in test_ports:
                    with patch('socket.socket') as MockSocket:
                        mock_socket = Mock()
                        mock_socket.bind = Mock()
                        mock_socket.close = Mock()
                        MockSocket.return_value = mock_socket
                        
                        try:
                            sock = MockSocket()
                            sock.bind(('localhost', port))
                            sock.close()
                            available_port = port
                            break
                        except:
                            continue
                
                if not available_port:
                    available_port = 8000  # é»˜è®¤ç«¯å£
                
                lifecycle_phases.append(f"port_allocated_{available_port}")
                
                # ç¬¬å››é˜¶æ®µï¼šTCPç«™ç‚¹å¯åŠ¨ (lines 271-275)
                lifecycle_phases.append("phase_4_site_startup_start")
                
                mock_site = Mock()
                mock_site.start = AsyncMock()
                mock_site.stop = AsyncMock()
                MockSite.return_value = mock_site
                
                site = MockSite(runner, 'localhost', available_port)
                await site.start()
                lifecycle_phases.append("site_started")
                
                # ç¬¬äº”é˜¶æ®µï¼šä¿¡å·å¤„ç†å™¨æ³¨å†Œ (lines 276-278)
                lifecycle_phases.append("phase_5_signal_registration_start")
                
                def create_shutdown_handler():
                    def shutdown_handler(sig, frame):
                        lifecycle_phases.append(f"shutdown_signal_received_{sig}")
                        resource_cleanup_log.append(f"signal_{sig}_cleanup_initiated")
                        print(f"ğŸ›‘ æ”¶åˆ°å…³é—­ä¿¡å·: {sig}")
                        # æ¨¡æ‹Ÿä¼˜é›…å…³é—­
                        resource_cleanup_log.append("graceful_shutdown_started")
                    return shutdown_handler
                
                shutdown_handler = create_shutdown_handler()
                signal.signal(signal.SIGINT, shutdown_handler)
                signal.signal(signal.SIGTERM, shutdown_handler)
                lifecycle_phases.append("signal_handlers_registered")
                
                # ç¬¬å…­é˜¶æ®µï¼šæµè§ˆå™¨å¯åŠ¨ (lines 279-281)
                lifecycle_phases.append("phase_6_browser_launch_start")
                
                try:
                    browser_opened = mock_browser(f'http://localhost:{available_port}')
                    if browser_opened:
                        lifecycle_phases.append("browser_opened_successfully")
                    else:
                        lifecycle_phases.append("browser_open_failed")
                except Exception as e:
                    lifecycle_phases.append(f"browser_exception_{str(e)}")
                
                # ç¬¬ä¸ƒé˜¶æ®µï¼šæœåŠ¡å™¨çŠ¶æ€è¾“å‡º (lines 282-286)
                lifecycle_phases.append("phase_7_status_output_start")
                
                # çŠ¶æ€æ¶ˆæ¯è¾“å‡º
                status_messages = [
                    f"ğŸš€ å¼€å‘æœåŠ¡å™¨å¯åŠ¨å®Œæˆï¼",
                    f"ğŸŒ å‰ç«¯æœåŠ¡: http://localhost:{available_port}",
                    f"ğŸ“¡ WebSocket: ws://localhost:{available_port}/ws",
                    f"ğŸ“Š APIæœåŠ¡: http://localhost:{available_port}/api",
                    f"âš¡ çƒ­é‡è½½: å·²å¯ç”¨",
                    f"ğŸ”§ è°ƒè¯•æ¨¡å¼: å¼€å¯"
                ]
                
                for msg in status_messages:
                    mock_logger.info(msg)
                
                mock_print("=" * 50)
                mock_print("ğŸ‰ AIé‡åŒ–äº¤æ˜“ç³»ç»Ÿå¼€å‘æœåŠ¡å™¨å·²å°±ç»ª")
                mock_print("ğŸ’¡ æŒ‰ Ctrl+C åœæ­¢æœåŠ¡å™¨")
                mock_print("=" * 50)
                
                lifecycle_phases.append("status_output_complete")
                
                # ç¬¬å…«é˜¶æ®µï¼šæœåŠ¡å™¨è¿è¡Œæ¨¡æ‹Ÿ (lines 287-291)
                lifecycle_phases.append("phase_8_server_running_start")
                
                # æ¨¡æ‹ŸæœåŠ¡å™¨è¿è¡ŒæœŸé—´çš„æ“ä½œ
                runtime_operations = [
                    "websocket_connections_accepted",
                    "api_requests_processed", 
                    "static_files_served",
                    "hot_reload_triggered"
                ]
                
                for operation in runtime_operations:
                    await asyncio.sleep(0.001)  # æ¨¡æ‹Ÿè¿è¡Œæ—¶é—´
                    lifecycle_phases.append(f"runtime_{operation}")
                
                lifecycle_phases.append("server_running_stable")
                
                # ç¬¬ä¹é˜¶æ®µï¼šå…³é—­ä¿¡å·å¤„ç†æµ‹è¯• (lines 292-293)
                lifecycle_phases.append("phase_9_shutdown_test_start")
                
                # æµ‹è¯•SIGINTå¤„ç†
                if signal.SIGINT in signal_handlers:
                    handler = signal_handlers[signal.SIGINT]
                    with patch('sys.exit') as mock_exit:
                        handler(signal.SIGINT, None)
                        mock_exit.assert_called_with(0)
                        lifecycle_phases.append("sigint_handled_gracefully")
                
                # æµ‹è¯•SIGTERMå¤„ç†
                if signal.SIGTERM in signal_handlers:
                    handler = signal_handlers[signal.SIGTERM]
                    with patch('sys.exit') as mock_exit:
                        handler(signal.SIGTERM, None)
                        mock_exit.assert_called_with(0)
                        lifecycle_phases.append("sigterm_handled_gracefully")
                
                # ç¬¬åé˜¶æ®µï¼šèµ„æºæ¸…ç† (æ¸…ç†é˜¶æ®µ)
                lifecycle_phases.append("phase_10_cleanup_start")
                
                try:
                    await site.stop()
                    resource_cleanup_log.append("site_stopped")
                    lifecycle_phases.append("site_cleanup_complete")
                except Exception as e:
                    resource_cleanup_log.append(f"site_cleanup_error_{str(e)}")
                
                try:
                    await runner.cleanup()
                    resource_cleanup_log.append("runner_cleanup_complete")
                    lifecycle_phases.append("runner_cleanup_complete")
                except Exception as e:
                    resource_cleanup_log.append(f"runner_cleanup_error_{str(e)}")
                
                lifecycle_phases.append("phase_10_cleanup_complete")
                
                # éªŒè¯å®Œæ•´ç”Ÿå‘½å‘¨æœŸ
                expected_phases = [
                    "phase_1_app_creation_start", "app_created",
                    "phase_2_runner_setup_start", "runner_created", "runner_setup_complete",
                    "phase_3_port_allocation_start", f"port_allocated_{available_port}",
                    "phase_4_site_startup_start", "site_started",
                    "phase_5_signal_registration_start", "signal_handlers_registered",
                    "phase_6_browser_launch_start",
                    "phase_7_status_output_start", "status_output_complete",
                    "phase_8_server_running_start", "server_running_stable",
                    "phase_9_shutdown_test_start",
                    "phase_10_cleanup_start", "phase_10_cleanup_complete"
                ]
                
                for expected_phase in expected_phases:
                    assert expected_phase in lifecycle_phases, f"ç¼ºå°‘ç”Ÿå‘½å‘¨æœŸé˜¶æ®µ: {expected_phase}"
                
                # éªŒè¯ä¿¡å·å¤„ç†å™¨æ³¨å†Œ
                assert signal.SIGINT in signal_handlers, "åº”è¯¥æ³¨å†ŒSIGINTå¤„ç†å™¨"
                assert signal.SIGTERM in signal_handlers, "åº”è¯¥æ³¨å†ŒSIGTERMå¤„ç†å™¨"
                
                # éªŒè¯è¾“å‡ºè°ƒç”¨
                assert mock_logger.info.call_count >= len(status_messages), "åº”è¯¥è¾“å‡ºæ‰€æœ‰çŠ¶æ€æ¶ˆæ¯"
                assert mock_print.call_count >= 3, "åº”è¯¥è¾“å‡ºå¯åŠ¨æç¤ºä¿¡æ¯"
                assert mock_browser.called, "åº”è¯¥å°è¯•æ‰“å¼€æµè§ˆå™¨"
                
                # éªŒè¯èµ„æºæ¸…ç†
                assert len(resource_cleanup_log) > 0, "åº”è¯¥æœ‰èµ„æºæ¸…ç†è®°å½•"
                
                print(f"æœåŠ¡å™¨ç”Ÿå‘½å‘¨æœŸæµ‹è¯•å®Œæˆï¼Œå…± {len(lifecycle_phases)} ä¸ªé˜¶æ®µ")
                print(f"èµ„æºæ¸…ç†æ“ä½œ: {len(resource_cleanup_log)} ä¸ª")


class TestStartDevMainFunctionComplete:
    """start_devä¸»å‡½æ•°å®Œæ•´æµ‹è¯• - start_dev.py lines 167-205"""
    
    def test_main_function_complete_execution_matrix(self):
        """ä¸»å‡½æ•°å®Œæ•´æ‰§è¡ŒçŸ©é˜µæµ‹è¯•"""
        
        # å®Œæ•´çš„æ‰§è¡ŒçŸ©é˜µ - è¦†ç›–æ‰€æœ‰å¯èƒ½çš„æ‰§è¡Œè·¯å¾„
        execution_matrix = [
            # æ ‡å‡†æˆåŠŸè·¯å¾„
            {
                'scenario': 'standard_success',
                'args': ['start_dev.py'],
                'inputs': ['y', 'hot', ''],
                'python_version': (3, 9, 7),
                'dependencies': {'all_available': True},
                'project_structure': True,
                'subprocess_result': Mock(returncode=0),
                'expected_flow': ['version_check', 'dep_check', 'structure_check', 'mode_select', 'server_start'],
                'expected_outcome': 'success'
            },
            # å¿«é€Ÿæ¨¡å¼è·¯å¾„
            {
                'scenario': 'quick_mode_hot',
                'args': ['start_dev.py', '--mode', 'hot'],
                'inputs': [],
                'python_version': (3, 10, 0),
                'dependencies': {'all_available': True},
                'project_structure': True,
                'subprocess_result': Mock(returncode=0),
                'expected_flow': ['version_check', 'dep_check', 'structure_check', 'direct_start'],
                'expected_outcome': 'success'
            },
            # å¢å¼ºæ¨¡å¼è·¯å¾„
            {
                'scenario': 'enhanced_mode',
                'args': ['start_dev.py', '--mode', 'enhanced'],
                'inputs': [],
                'python_version': (3, 11, 0),
                'dependencies': {'all_available': True},
                'project_structure': True,
                'subprocess_result': Mock(returncode=0),
                'expected_flow': ['version_check', 'dep_check', 'structure_check', 'direct_start'],
                'expected_outcome': 'success'
            },
            # æ ‡å‡†æ¨¡å¼è·¯å¾„
            {
                'scenario': 'standard_mode',
                'args': ['start_dev.py', '--mode', 'standard'],
                'inputs': [],
                'python_version': (3, 8, 10),
                'dependencies': {'all_available': True},
                'project_structure': True,
                'subprocess_result': Mock(returncode=0),
                'expected_flow': ['version_check', 'dep_check', 'structure_check', 'direct_start'],
                'expected_outcome': 'success'
            },
            # å¸®åŠ©æ¨¡å¼è·¯å¾„
            {
                'scenario': 'help_mode',
                'args': ['start_dev.py', '--help'],
                'inputs': [],
                'python_version': (3, 9, 7),
                'dependencies': {'all_available': True},
                'project_structure': True,
                'subprocess_result': None,
                'expected_flow': ['help_display'],
                'expected_outcome': 'help_exit'
            },
            # ç‰ˆæœ¬æ¨¡å¼è·¯å¾„
            {
                'scenario': 'version_mode',
                'args': ['start_dev.py', '--version'],
                'inputs': [],
                'python_version': (3, 9, 7),
                'dependencies': {'all_available': True},
                'project_structure': True,
                'subprocess_result': None,
                'expected_flow': ['version_display'],
                'expected_outcome': 'version_exit'
            },
            # Pythonç‰ˆæœ¬é”™è¯¯è·¯å¾„
            {
                'scenario': 'python_version_error',
                'args': ['start_dev.py'],
                'inputs': ['y'],
                'python_version': (3, 7, 9),  # ç‰ˆæœ¬è¿‡ä½
                'dependencies': {'all_available': True},
                'project_structure': True,
                'subprocess_result': None,
                'expected_flow': ['version_check', 'version_error'],
                'expected_outcome': 'version_error_exit'
            },
            # ä¾èµ–ç¼ºå¤± - ç”¨æˆ·åŒæ„å®‰è£…
            {
                'scenario': 'deps_missing_install_yes',
                'args': ['start_dev.py'],
                'inputs': ['y', 'y', 'hot'],
                'python_version': (3, 9, 7),
                'dependencies': {'missing': ['pytest', 'coverage'], 'install_success': True},
                'project_structure': True,
                'subprocess_result': Mock(returncode=0),
                'expected_flow': ['version_check', 'dep_check', 'dep_install', 'structure_check', 'server_start'],
                'expected_outcome': 'success'
            },
            # ä¾èµ–ç¼ºå¤± - ç”¨æˆ·æ‹’ç»å®‰è£…
            {
                'scenario': 'deps_missing_install_no',
                'args': ['start_dev.py'],
                'inputs': ['y', 'n'],
                'python_version': (3, 9, 7),
                'dependencies': {'missing': ['pytest'], 'install_success': False},
                'project_structure': True,
                'subprocess_result': None,
                'expected_flow': ['version_check', 'dep_check', 'dep_install_refused'],
                'expected_outcome': 'dependency_error_exit'
            },
            # ä¾èµ–å®‰è£…å¤±è´¥
            {
                'scenario': 'deps_install_failed',
                'args': ['start_dev.py'],
                'inputs': ['y', 'y'],
                'python_version': (3, 9, 7),
                'dependencies': {'missing': ['nonexistent-package'], 'install_success': False},
                'project_structure': True,
                'subprocess_result': None,
                'expected_flow': ['version_check', 'dep_check', 'dep_install', 'install_failed'],
                'expected_outcome': 'dependency_error_exit'
            },
            # é¡¹ç›®ç»“æ„é”™è¯¯
            {
                'scenario': 'project_structure_error',
                'args': ['start_dev.py'],
                'inputs': ['y', 'hot'],
                'python_version': (3, 9, 7),
                'dependencies': {'all_available': True},
                'project_structure': False,
                'subprocess_result': None,
                'expected_flow': ['version_check', 'dep_check', 'structure_check', 'structure_error'],
                'expected_outcome': 'structure_error_exit'
            },
            # æœåŠ¡å™¨å¯åŠ¨å¤±è´¥
            {
                'scenario': 'server_start_failed',
                'args': ['start_dev.py', '--mode', 'hot'],
                'inputs': [],
                'python_version': (3, 9, 7),
                'dependencies': {'all_available': True},
                'project_structure': True,
                'subprocess_result': Mock(returncode=1),
                'expected_flow': ['version_check', 'dep_check', 'structure_check', 'server_start', 'start_failed'],
                'expected_outcome': 'server_start_error'
            },
            # ç”¨æˆ·æ—©æœŸé€€å‡º
            {
                'scenario': 'early_user_exit',
                'args': ['start_dev.py'],
                'inputs': ['n'],
                'python_version': (3, 9, 7),
                'dependencies': {'all_available': True},
                'project_structure': True,
                'subprocess_result': None,
                'expected_flow': ['early_exit'],
                'expected_outcome': 'early_exit'
            }
        ]
        
        for matrix_entry in execution_matrix:
            execution_trace = []
            input_iterator = iter(matrix_entry['inputs'])
            
            def mock_input_function(prompt=''):
                try:
                    user_input = next(input_iterator)
                    execution_trace.append(f"input:{user_input}")
                    return user_input
                except StopIteration:
                    execution_trace.append("input:default_n")
                    return 'n'
            
            # åˆ›å»ºç‰ˆæœ¬ä¿¡æ¯æ¨¡æ‹Ÿ
            class MockVersionInfo:
                def __init__(self, major, minor, micro):
                    self.major, self.minor, self.micro = major, minor, micro
                
                def __lt__(self, other): return (self.major, self.minor) < other
                def __ge__(self, other): return (self.major, self.minor) >= other
                def __getitem__(self, index): return [self.major, self.minor, self.micro][index]
            
            mock_version = MockVersionInfo(*matrix_entry['python_version'])
            
            # åˆ›å»ºä¾èµ–æ¨¡æ‹Ÿ
            def mock_import_function(name, *args, **kwargs):
                deps_config = matrix_entry['dependencies']
                if deps_config.get('all_available', False):
                    execution_trace.append(f"import_success:{name}")
                    return Mock()
                elif 'missing' in deps_config and name in deps_config['missing']:
                    execution_trace.append(f"import_failed:{name}")
                    raise ImportError(f"No module named '{name}'")
                else:
                    execution_trace.append(f"import_success:{name}")
                    return Mock()
            
            # åˆ›å»ºè·¯å¾„æ¨¡æ‹Ÿ
            def mock_path_exists(path):
                if matrix_entry['project_structure']:
                    execution_trace.append(f"path_exists:{path}")
                    return True
                else:
                    execution_trace.append(f"path_missing:{path}")
                    return False
            
            # æ‰§è¡Œæµ‹è¯•
            with patch('sys.argv', matrix_entry['args']), \
                 patch('builtins.input', side_effect=mock_input_function), \
                 patch('builtins.print') as mock_print, \
                 patch('sys.version_info', mock_version), \
                 patch('pathlib.Path.exists', side_effect=mock_path_exists), \
                 patch('builtins.__import__', side_effect=mock_import_function), \
                 patch('subprocess.run', return_value=matrix_entry['subprocess_result']) as mock_subprocess:
                
                execution_trace.append(f"scenario_start:{matrix_entry['scenario']}")
                
                try:
                    from start_dev import main
                    
                    # å¦‚æœæœ‰ä¾èµ–å®‰è£…é€»è¾‘ï¼Œæ¨¡æ‹Ÿå®ƒ
                    if 'missing' in matrix_entry['dependencies']:
                        with patch('start_dev.DevEnvironmentStarter.install_dependencies', 
                                 return_value=matrix_entry['dependencies'].get('install_success', False)):
                            result = main()
                            execution_trace.append(f"main_result:{result}")
                    else:
                        result = main()
                        execution_trace.append(f"main_result:{result}")
                    
                    # éªŒè¯é¢„æœŸæµç¨‹
                    if matrix_entry['expected_outcome'] == 'success':
                        assert mock_subprocess.called or matrix_entry['subprocess_result'] is None
                        execution_trace.append("verification:success_path")
                    
                except SystemExit as e:
                    execution_trace.append(f"system_exit:{e.code}")
                    
                    # éªŒè¯é€€å‡ºç 
                    expected_outcome = matrix_entry['expected_outcome']
                    if expected_outcome in ['help_exit', 'version_exit']:
                        assert e.code in [None, 0], f"å¸®åŠ©/ç‰ˆæœ¬æ¨¡å¼åº”æ­£å¸¸é€€å‡ºï¼Œå®é™…é€€å‡ºç : {e.code}"
                    elif expected_outcome in ['version_error_exit', 'dependency_error_exit', 'structure_error_exit']:
                        assert e.code in [1, 2], f"é”™è¯¯æƒ…å†µåº”é”™è¯¯é€€å‡ºï¼Œå®é™…é€€å‡ºç : {e.code}"
                    elif expected_outcome == 'early_exit':
                        assert e.code in [0, 1], f"æ—©æœŸé€€å‡ºåº”æ­£å¸¸ï¼Œå®é™…é€€å‡ºç : {e.code}"
                    
                    execution_trace.append(f"exit_code_verified:{e.code}")
                
                except Exception as e:
                    execution_trace.append(f"exception:{type(e).__name__}:{str(e)}")
                    
                    # æŸäº›é”™è¯¯æƒ…å†µæ˜¯é¢„æœŸçš„
                    if matrix_entry['expected_outcome'].endswith('_error') or matrix_entry['expected_outcome'].endswith('_error_exit'):
                        execution_trace.append("expected_error_handled")
                
                # éªŒè¯æ‰§è¡Œè·Ÿè¸ª
                assert len(execution_trace) > 0, f"åœºæ™¯ {matrix_entry['scenario']} åº”è¯¥æœ‰æ‰§è¡Œè·Ÿè¸ª"
                
                # éªŒè¯ç”¨æˆ·äº¤äº’ï¼ˆå¦‚æœæœ‰è¾“å…¥ï¼‰
                if matrix_entry['inputs']:
                    input_traces = [trace for trace in execution_trace if trace.startswith('input:')]
                    assert len(input_traces) > 0, f"åœºæ™¯ {matrix_entry['scenario']} åº”è¯¥æœ‰ç”¨æˆ·è¾“å…¥è®°å½•"
                
                print(f"æ‰§è¡ŒçŸ©é˜µåœºæ™¯ '{matrix_entry['scenario']}' å®Œæˆ: {len(execution_trace)} æ­¥éª¤")


if __name__ == "__main__":
    pytest.main([__file__, "-v"])