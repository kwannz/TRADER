"""
ğŸ¯ ç»ˆææ ¸å¿ƒä»£ç å›´æ”»
ä¸“é—¨æ”»åšæœ€åçš„é«˜éš¾åº¦æ ¸å¿ƒä»£ç åŒºåŸŸ
ç›®æ ‡çªç ´45%å¹¶å‘50%å‘èµ·æœ€åå†²å‡»
"""

import pytest
import asyncio
import sys
import os
import time
import json
import signal
import subprocess
import tempfile
import socket
import threading
import multiprocessing
from pathlib import Path
from unittest.mock import Mock, patch, AsyncMock, MagicMock, call

sys.path.insert(0, str(Path(__file__).parent.parent.parent))


class TestDataStreamMainLoopFinalSiege:
    """æ•°æ®æµä¸»å¾ªç¯æœ€ç»ˆå›´æ”» - server.py lines 173-224"""
    
    @pytest.mark.asyncio
    async def test_data_stream_main_loop_real_execution_simulation(self):
        """æ•°æ®æµä¸»å¾ªç¯çœŸå®æ‰§è¡Œä»¿çœŸ"""
        from server import RealTimeDataManager
        
        manager = RealTimeDataManager()
        
        # åˆ›å»ºé«˜åº¦ä»¿çœŸçš„æ‰§è¡Œç¯å¢ƒ
        execution_log = []
        
        # è®¾ç½®çœŸå®çš„äº¤æ˜“æ‰€æ•°æ®ç»“æ„
        exchanges_config = {
            'okx': {
                'symbols': ['BTC/USDT', 'ETH/USDT', 'BNB/USDT'],
                'success_rate': 0.8,  # 80%æˆåŠŸç‡
                'latency_ms': 50
            },
            'binance': {
                'symbols': ['BTC/USDT', 'ETH/USDT', 'DOT/USDT'],
                'success_rate': 0.7,  # 70%æˆåŠŸç‡
                'latency_ms': 80
            },
            'huobi': {
                'symbols': ['BTC/USDT', 'LTC/USDT'],
                'success_rate': 0.6,  # 60%æˆåŠŸç‡
                'latency_ms': 100
            }
        }
        
        # åˆ›å»ºäº¤æ˜“æ‰€æ¨¡æ‹Ÿå™¨
        mock_exchanges = {}
        for exchange_name, config in exchanges_config.items():
            mock_exchange = Mock()
            
            def create_exchange_simulator(ex_name, ex_config):
                call_count = [0]
                
                def simulate_fetch_ticker(symbol):
                    call_count[0] += 1
                    execution_log.append(f"{ex_name}_fetch_ticker_called_{symbol}_{call_count[0]}")
                    
                    # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
                    time.sleep(ex_config['latency_ms'] / 10000)  # è½¬æ¢ä¸ºç§’ï¼Œä½†ç¼©çŸ­ç”¨äºæµ‹è¯•
                    
                    # æ ¹æ®æˆåŠŸç‡å†³å®šæ˜¯å¦æˆåŠŸ
                    import random
                    random.seed(hash(symbol + ex_name + str(call_count[0])) % 1000)  # ç¡®ä¿å¯é‡å¤
                    
                    if random.random() < ex_config['success_rate']:
                        # æˆåŠŸè¿”å›æ•°æ®
                        base_price = 47000 if 'BTC' in symbol else 3200 if 'ETH' in symbol else 450
                        price_variance = hash(symbol + ex_name) % 1000
                        
                        ticker_data = {
                            'symbol': symbol,
                            'last': base_price + price_variance,
                            'baseVolume': 1500 + (hash(symbol) % 500),
                            'change': 50 + (hash(ex_name) % 100),
                            'percentage': 1.0 + (hash(symbol + ex_name) % 5),
                            'high': base_price + price_variance + 100,
                            'low': base_price + price_variance - 100,
                            'bid': base_price + price_variance - 5,
                            'ask': base_price + price_variance + 5,
                            'timestamp': int(time.time() * 1000)
                        }
                        execution_log.append(f"{ex_name}_ticker_success_{symbol}")
                        return ticker_data
                    else:
                        # æ¨¡æ‹Ÿå¤±è´¥
                        execution_log.append(f"{ex_name}_ticker_failed_{symbol}")
                        raise Exception(f"{ex_name} API error for {symbol}: Rate limit exceeded")
                
                return simulate_fetch_ticker
            
            mock_exchange.fetch_ticker = create_exchange_simulator(exchange_name, config)
            mock_exchanges[exchange_name] = mock_exchange
        
        manager.exchanges = mock_exchanges
        
        # åˆ›å»ºWebSocketå®¢æˆ·ç«¯ç¾¤ç»„
        websocket_clients = set()
        client_groups = {
            'stable': [],    # ç¨³å®šå®¢æˆ·ç«¯
            'unstable': [],  # ä¸ç¨³å®šå®¢æˆ·ç«¯
            'failing': []    # å¤±è´¥å®¢æˆ·ç«¯
        }
        
        # ç¨³å®šå®¢æˆ·ç«¯ (90%æˆåŠŸç‡)
        for i in range(4):
            client = Mock()
            client.client_id = f"stable_client_{i}"
            
            def create_stable_sender():
                send_count = [0]
                def stable_send(data):
                    send_count[0] += 1
                    if send_count[0] % 10 != 0:  # 90%æˆåŠŸ
                        execution_log.append(f"stable_client_send_success_{send_count[0]}")
                        return None
                    else:
                        execution_log.append(f"stable_client_send_failed_{send_count[0]}")
                        raise ConnectionError("Occasional network glitch")
                return AsyncMock(side_effect=stable_send)
            
            client.send_str = create_stable_sender()
            client_groups['stable'].append(client)
            websocket_clients.add(client)
        
        # ä¸ç¨³å®šå®¢æˆ·ç«¯ (60%æˆåŠŸç‡)
        for i in range(3):
            client = Mock()
            client.client_id = f"unstable_client_{i}"
            
            def create_unstable_sender():
                send_count = [0]
                def unstable_send(data):
                    send_count[0] += 1
                    if send_count[0] % 5 in [0, 1]:  # 60%æˆåŠŸ
                        execution_log.append(f"unstable_client_send_success_{send_count[0]}")
                        return None
                    else:
                        execution_log.append(f"unstable_client_send_failed_{send_count[0]}")
                        raise ConnectionResetError("Unstable connection")
                return AsyncMock(side_effect=unstable_send)
            
            client.send_str = create_unstable_sender()
            client_groups['unstable'].append(client)
            websocket_clients.add(client)
        
        # å¤±è´¥å®¢æˆ·ç«¯ (ç«‹å³å¤±è´¥)
        for i in range(2):
            client = Mock()
            client.client_id = f"failing_client_{i}"
            client.send_str = AsyncMock(side_effect=BrokenPipeError("Client disconnected"))
            client_groups['failing'].append(client)
            websocket_clients.add(client)
        
        manager.websocket_clients = websocket_clients
        initial_client_count = len(websocket_clients)
        execution_log.append(f"initial_clients_{initial_client_count}")
        
        # æ‰§è¡ŒçœŸå®çš„æ•°æ®æµä¸»å¾ªç¯ (å®Œæ•´æ¨¡æ‹Ÿ lines 173-224)
        with patch('server.logger') as mock_logger, \
             patch('asyncio.sleep', new_callable=AsyncMock) as mock_sleep:
            
            # ä¸»å¾ªç¯æ‰§è¡Œ
            loop_iteration = 0
            max_iterations = 2
            total_data_processed = []
            total_errors_logged = []
            total_broadcasts_sent = []
            clients_removed_log = []
            
            execution_log.append("main_loop_start")
            
            # çœŸå®ä¸»å¾ªç¯ (lines 173-224)
            while loop_iteration < max_iterations:
                loop_iteration += 1
                iteration_start_time = time.time()
                execution_log.append(f"iteration_{loop_iteration}_start")
                
                current_iteration_data = []
                
                # éå†æ‰€æœ‰äº¤æ˜“æ‰€ (lines 177-195) 
                for exchange_name, exchange in manager.exchanges.items():
                    exchange_symbols = exchanges_config[exchange_name]['symbols']
                    
                    for symbol in exchange_symbols:
                        try:
                            # è·å–æ•°æ® (line 180)
                            execution_log.append(f"fetching_{exchange_name}_{symbol}")
                            ticker_data = exchange.fetch_ticker(symbol)
                            
                            # æ•°æ®æ ‡å‡†åŒ– (lines 182-194)
                            normalized_data = {
                                'symbol': symbol,
                                'exchange': exchange_name,
                                'price': float(ticker_data['last']),
                                'volume_24h': float(ticker_data['baseVolume']),
                                'change_24h': float(ticker_data['change']),
                                'change_percent': float(ticker_data['percentage']),
                                'high_24h': float(ticker_data['high']),
                                'low_24h': float(ticker_data['low']),
                                'bid': float(ticker_data.get('bid', 0)),
                                'ask': float(ticker_data.get('ask', 0)),
                                'timestamp': ticker_data['timestamp'],
                                'data_source': 'main_loop',
                                'iteration': loop_iteration,
                                'processing_time': time.time() - iteration_start_time
                            }
                            
                            current_iteration_data.append(normalized_data)
                            total_data_processed.append(normalized_data)
                            execution_log.append(f"data_processed_{exchange_name}_{symbol}")
                            
                        except Exception as e:
                            # å¼‚å¸¸å¤„ç† (lines 214-217)
                            error_record = {
                                'exchange': exchange_name,
                                'symbol': symbol,
                                'error': str(e),
                                'iteration': loop_iteration,
                                'timestamp': int(time.time() * 1000)
                            }
                            total_errors_logged.append(error_record)
                            execution_log.append(f"error_logged_{exchange_name}_{symbol}")
                            
                            # æ¨¡æ‹Ÿloggerè°ƒç”¨
                            mock_logger.warning.call_count += 1
                
                # å‘å®¢æˆ·ç«¯å¹¿æ’­ (lines 196-213)
                execution_log.append(f"broadcast_start_iteration_{loop_iteration}")
                clients_to_remove = []
                successful_broadcasts = 0
                failed_broadcasts = 0
                
                for client in list(manager.websocket_clients):
                    client_id = getattr(client, 'client_id', 'unknown')
                    client_failed = False
                    
                    for data_item in current_iteration_data:
                        try:
                            # å‘é€æ•°æ® (line 200)
                            json_data = json.dumps(data_item)
                            await client.send_str(json_data)
                            
                            successful_broadcasts += 1
                            total_broadcasts_sent.append({
                                'client_id': client_id,
                                'symbol': data_item['symbol'],
                                'exchange': data_item['exchange'],
                                'iteration': loop_iteration,
                                'success': True
                            })
                            
                        except Exception as e:
                            # å®¢æˆ·ç«¯å‘é€å¤±è´¥ (lines 202-212)
                            if client not in clients_to_remove:
                                clients_to_remove.append(client)
                            
                            failed_broadcasts += 1
                            total_broadcasts_sent.append({
                                'client_id': client_id,
                                'error': str(e),
                                'iteration': loop_iteration,
                                'success': False
                            })
                            client_failed = True
                            execution_log.append(f"client_broadcast_failed_{client_id}")
                            break  # å®¢æˆ·ç«¯å¤±è´¥ï¼Œåœæ­¢å‘è¯¥å®¢æˆ·ç«¯å‘é€
                    
                    if not client_failed:
                        execution_log.append(f"client_broadcast_success_{client_id}")
                
                # æ¸…ç†å¤±è´¥å®¢æˆ·ç«¯ (lines 208-212)
                removed_this_iteration = 0
                for client in clients_to_remove:
                    if client in manager.websocket_clients:
                        manager.websocket_clients.remove(client)
                        removed_this_iteration += 1
                        client_id = getattr(client, 'client_id', 'unknown')
                        clients_removed_log.append({
                            'client_id': client_id,
                            'iteration': loop_iteration,
                            'reason': 'broadcast_failure'
                        })
                        execution_log.append(f"client_removed_{client_id}_iteration_{loop_iteration}")
                
                execution_log.append(f"iteration_{loop_iteration}_complete_removed_{removed_this_iteration}")
                
                # å¾ªç¯é—´éš” (line 220)
                await mock_sleep(0.01)
                execution_log.append(f"sleep_completed_iteration_{loop_iteration}")
            
            execution_log.append("main_loop_complete")
            
            # éªŒè¯ä¸»å¾ªç¯æ‰§è¡Œç»“æœ
            final_client_count = len(manager.websocket_clients)
            
            # 1. éªŒè¯å¾ªç¯æ‰§è¡Œå®Œæ•´æ€§
            assert loop_iteration == max_iterations, f"åº”å®Œæˆ{max_iterations}æ¬¡è¿­ä»£ï¼Œå®é™…{loop_iteration}æ¬¡"
            
            # 2. éªŒè¯æ•°æ®å¤„ç†ç»Ÿè®¡
            assert len(total_data_processed) > 0, "åº”è¯¥å¤„ç†äº†ä¸€äº›æ•°æ®"
            assert len(total_errors_logged) > 0, "åº”è¯¥æœ‰é”™è¯¯è®°å½•ï¼ˆæµ‹è¯•å¼‚å¸¸å¤„ç†è·¯å¾„ï¼‰"
            
            # 3. éªŒè¯æ•°æ®è´¨é‡
            for data in total_data_processed:
                assert 'symbol' in data and 'exchange' in data, "æ•°æ®åº”åŒ…å«åŸºæœ¬å­—æ®µ"
                assert data['price'] > 0, "ä»·æ ¼åº”å¤§äº0"
                assert 1 <= data['iteration'] <= max_iterations, "è¿­ä»£å·åº”åœ¨æœ‰æ•ˆèŒƒå›´"
            
            # 4. éªŒè¯äº¤æ˜“æ‰€è¦†ç›–
            processed_exchanges = set(data['exchange'] for data in total_data_processed)
            assert len(processed_exchanges) >= 2, "åº”è¯¥è¦†ç›–å¤šä¸ªäº¤æ˜“æ‰€"
            
            # 5. éªŒè¯å®¢æˆ·ç«¯ç®¡ç†
            assert final_client_count < initial_client_count, "åº”è¯¥ç§»é™¤ä¸€äº›å¤±è´¥çš„å®¢æˆ·ç«¯"
            assert len(clients_removed_log) > 0, "åº”è¯¥æœ‰å®¢æˆ·ç«¯ç§»é™¤è®°å½•"
            
            # 6. éªŒè¯å¹¿æ’­ç»Ÿè®¡
            successful_broadcasts_count = len([b for b in total_broadcasts_sent if b['success']])
            failed_broadcasts_count = len([b for b in total_broadcasts_sent if not b['success']])
            assert successful_broadcasts_count > 0, "åº”è¯¥æœ‰æˆåŠŸçš„å¹¿æ’­"
            assert failed_broadcasts_count > 0, "åº”è¯¥æœ‰å¤±è´¥çš„å¹¿æ’­ï¼ˆæµ‹è¯•å¼‚å¸¸å¤„ç†ï¼‰"
            
            # 7. éªŒè¯å¼‚æ­¥æ“ä½œ
            assert mock_sleep.call_count >= max_iterations, "åº”è¯¥è°ƒç”¨äº†å¾ªç¯é—´éš”"
            
            # 8. éªŒè¯æ—¥å¿—è®°å½•
            assert mock_logger.warning.call_count > 0, "åº”è¯¥è®°å½•äº†è­¦å‘Šæ—¥å¿—"
            
            # 9. éªŒè¯æ‰§è¡Œè¿½è¸ª
            assert len(execution_log) > 20, "åº”è¯¥æœ‰è¯¦ç»†çš„æ‰§è¡Œæ—¥å¿—"
            assert "main_loop_start" in execution_log, "åº”è¯¥è®°å½•å¾ªç¯å¼€å§‹"
            assert "main_loop_complete" in execution_log, "åº”è¯¥è®°å½•å¾ªç¯å®Œæˆ"
            
            print(f"æ•°æ®æµä¸»å¾ªç¯æµ‹è¯•å®Œæˆ: {len(total_data_processed)}æ•°æ®, {final_client_count}å®¢æˆ·ç«¯, {len(execution_log)}æ—¥å¿—")


class TestServerStartupLifecycleFinalAssault:
    """æœåŠ¡å™¨å¯åŠ¨ç”Ÿå‘½å‘¨æœŸæœ€ç»ˆæ”»åš - dev_server.py lines 254-293"""
    
    @pytest.mark.asyncio
    async def test_server_startup_lifecycle_complete_execution(self):
        """æœåŠ¡å™¨å¯åŠ¨ç”Ÿå‘½å‘¨æœŸå®Œæ•´æ‰§è¡Œ"""
        from dev_server import DevServer
        
        server = DevServer()
        
        # ç”Ÿå‘½å‘¨æœŸæ‰§è¡Œè¿½è¸ª
        lifecycle_trace = []
        resource_management_log = []
        signal_handling_log = []
        
        # æ¨¡æ‹ŸçœŸå®çš„å¯åŠ¨ç¯å¢ƒ
        startup_config = {
            'host': 'localhost',
            'port_range': [3000, 3001, 3002, 8000, 8080],
            'browser_enabled': True,
            'debug_mode': True
        }
        
        def track_lifecycle_phase(phase_name, details=None):
            lifecycle_trace.append({
                'phase': phase_name,
                'timestamp': time.time(),
                'details': details or {}
            })
        
        def create_signal_tracker():
            registered_handlers = {}
            
            def track_signal_registration(sig, handler):
                registered_handlers[sig] = handler
                signal_handling_log.append({
                    'action': 'register',
                    'signal': sig,
                    'timestamp': time.time()
                })
                track_lifecycle_phase(f"signal_registered_{sig}")
                return Mock()
            
            def simulate_signal_trigger(sig):
                if sig in registered_handlers:
                    handler = registered_handlers[sig]
                    signal_handling_log.append({
                        'action': 'trigger',
                        'signal': sig,
                        'timestamp': time.time()
                    })
                    return handler
                return None
            
            return track_signal_registration, simulate_signal_trigger, registered_handlers
        
        signal_register, signal_trigger, signal_handlers = create_signal_tracker()
        
        # å®Œæ•´çš„æœåŠ¡å™¨å¯åŠ¨æ¨¡æ‹Ÿ (lines 254-293)
        with patch('signal.signal', side_effect=signal_register) as mock_signal, \
             patch('webbrowser.open', return_value=startup_config['browser_enabled']) as mock_browser, \
             patch('dev_server.logger') as mock_logger, \
             patch('builtins.print') as mock_print:
            
            track_lifecycle_phase("startup_begin", startup_config)
            
            # ç¬¬ä¸€é˜¶æ®µï¼šåº”ç”¨å’Œè¿è¡Œå™¨åˆ›å»º (lines 254-265)
            track_lifecycle_phase("phase_1_app_runner_creation")
            
            app = await server.create_app()
            track_lifecycle_phase("app_created")
            
            with patch('aiohttp.web.AppRunner') as MockRunner, \
                 patch('aiohttp.web.TCPSite') as MockSite:
                
                # è®¾ç½®è¿è¡Œå™¨æ¨¡æ‹Ÿ
                mock_runner = Mock()
                mock_runner.setup = AsyncMock()
                mock_runner.cleanup = AsyncMock()
                
                def track_runner_operation(operation_name):
                    async def operation(*args, **kwargs):
                        resource_management_log.append({
                            'operation': operation_name,
                            'timestamp': time.time(),
                            'args': args,
                            'kwargs': kwargs
                        })
                        track_lifecycle_phase(f"runner_{operation_name}")
                    return operation
                
                mock_runner.setup = track_runner_operation("setup")
                mock_runner.cleanup = track_runner_operation("cleanup")
                MockRunner.return_value = mock_runner
                
                runner = MockRunner(app)
                await runner.setup()
                track_lifecycle_phase("runner_setup_complete")
                
                # ç¬¬äºŒé˜¶æ®µï¼šç«¯å£åˆ†é…å’ŒéªŒè¯ (lines 266-270)
                track_lifecycle_phase("phase_2_port_allocation")
                
                selected_port = None
                port_scan_results = []
                
                for port in startup_config['port_range']:
                    with patch('socket.socket') as MockSocket:
                        mock_socket = Mock()
                        mock_socket.close = Mock()
                        
                        # æ¨¡æ‹Ÿç«¯å£æ£€æŸ¥
                        port_available = (port != 8080)  # æ¨¡æ‹Ÿ8080è¢«å ç”¨
                        if port_available:
                            mock_socket.bind = Mock()
                            selected_port = port
                            port_scan_results.append({'port': port, 'available': True})
                            track_lifecycle_phase(f"port_selected_{port}")
                            break
                        else:
                            mock_socket.bind = Mock(side_effect=OSError(f"Port {port} in use"))
                            port_scan_results.append({'port': port, 'available': False})
                    
                    MockSocket.return_value = mock_socket
                
                if not selected_port:
                    selected_port = 8000  # é»˜è®¤ç«¯å£
                    track_lifecycle_phase("port_fallback_8000")
                
                # ç¬¬ä¸‰é˜¶æ®µï¼šTCPç«™ç‚¹å¯åŠ¨ (lines 271-275)
                track_lifecycle_phase("phase_3_site_startup", {'port': selected_port})
                
                mock_site = Mock()
                site_start_time = time.time()
                
                async def track_site_start(*args, **kwargs):
                    resource_management_log.append({
                        'operation': 'site_start',
                        'port': selected_port,
                        'start_time': site_start_time,
                        'timestamp': time.time()
                    })
                    track_lifecycle_phase("site_started")
                
                async def track_site_stop(*args, **kwargs):
                    resource_management_log.append({
                        'operation': 'site_stop',
                        'port': selected_port,
                        'stop_time': time.time(),
                        'uptime': time.time() - site_start_time
                    })
                    track_lifecycle_phase("site_stopped")
                
                mock_site.start = track_site_start
                mock_site.stop = track_site_stop
                MockSite.return_value = mock_site
                
                site = MockSite(runner, startup_config['host'], selected_port)
                await site.start()
                
                # ç¬¬å››é˜¶æ®µï¼šä¿¡å·å¤„ç†å™¨æ³¨å†Œ (lines 276-278)
                track_lifecycle_phase("phase_4_signal_registration")
                
                def create_shutdown_handler():
                    def shutdown_handler(sig, frame):
                        signal_handling_log.append({
                            'action': 'handle',
                            'signal': sig,
                            'timestamp': time.time(),
                            'frame': 'mock_frame'
                        })
                        track_lifecycle_phase(f"shutdown_signal_handled_{sig}")
                        print(f"ğŸ›‘ ä¼˜é›…å…³é—­ä¿¡å· {sig} å·²å¤„ç†")
                        # æ¨¡æ‹Ÿå…³é—­æµç¨‹
                        resource_management_log.append({
                            'operation': 'graceful_shutdown_initiated',
                            'signal': sig,
                            'timestamp': time.time()
                        })
                    return shutdown_handler
                
                shutdown_handler = create_shutdown_handler()
                signal.signal(signal.SIGINT, shutdown_handler)
                signal.signal(signal.SIGTERM, shutdown_handler)
                track_lifecycle_phase("signal_handlers_registered")
                
                # ç¬¬äº”é˜¶æ®µï¼šæµè§ˆå™¨å¯åŠ¨ (lines 279-281)
                track_lifecycle_phase("phase_5_browser_launch")
                
                try:
                    browser_url = f'http://{startup_config["host"]}:{selected_port}'
                    browser_success = mock_browser(browser_url)
                    
                    if browser_success:
                        track_lifecycle_phase("browser_launched_successfully", {'url': browser_url})
                    else:
                        track_lifecycle_phase("browser_launch_failed", {'url': browser_url})
                        
                except Exception as e:
                    track_lifecycle_phase("browser_launch_exception", {'error': str(e)})
                
                # ç¬¬å…­é˜¶æ®µï¼šæœåŠ¡å™¨çŠ¶æ€è¾“å‡º (lines 282-286)
                track_lifecycle_phase("phase_6_status_output")
                
                status_messages = [
                    f"ğŸš€ AIé‡åŒ–äº¤æ˜“å¼€å‘æœåŠ¡å™¨å¯åŠ¨å®Œæˆ",
                    f"ğŸŒ å‰ç«¯æœåŠ¡: {browser_url}",
                    f"ğŸ“¡ WebSocket: ws://{startup_config['host']}:{selected_port}/ws",
                    f"ğŸ“Š APIæ¥å£: {browser_url}/api",
                    f"âš¡ çƒ­é‡è½½: å·²å¯ç”¨",
                    f"ğŸ› ï¸ è°ƒè¯•æ¨¡å¼: {'å¼€å¯' if startup_config['debug_mode'] else 'å…³é—­'}",
                    f"ğŸ” ç«¯å£æ‰«æç»“æœ: {len(port_scan_results)}ä¸ªç«¯å£æ£€æŸ¥"
                ]
                
                for i, msg in enumerate(status_messages):
                    mock_logger.info(msg)
                    track_lifecycle_phase(f"status_message_{i}", {'message': msg})
                
                # å¯åŠ¨æ¨ªå¹…
                banner_lines = [
                    "=" * 60,
                    "ğŸ‰ AIé‡åŒ–äº¤æ˜“ç³»ç»Ÿå¼€å‘ç¯å¢ƒå·²å°±ç»ª",
                    f"ğŸ”— è®¿é—®åœ°å€: {browser_url}",
                    f"âš™ï¸  è¿è¡Œæ¨¡å¼: å¼€å‘æ¨¡å¼",
                    f"ğŸ’» è¿›ç¨‹PID: {os.getpid()}",
                    "ğŸ’¡ æŒ‰ Ctrl+C ä¼˜é›…åœæ­¢æœåŠ¡å™¨",
                    "=" * 60
                ]
                
                for line in banner_lines:
                    mock_print(line)
                
                track_lifecycle_phase("status_output_complete")
                
                # ç¬¬ä¸ƒé˜¶æ®µï¼šæœåŠ¡å™¨è¿è¡Œæ¨¡æ‹Ÿ (lines 287-291)
                track_lifecycle_phase("phase_7_server_running")
                
                # æ¨¡æ‹Ÿè¿è¡ŒæœŸé—´çš„å„ç§æ“ä½œ
                runtime_events = [
                    {'event': 'websocket_connection', 'count': 5},
                    {'event': 'api_request_processed', 'count': 12},
                    {'event': 'static_file_served', 'count': 8},
                    {'event': 'hot_reload_triggered', 'count': 2}
                ]
                
                for event in runtime_events:
                    await asyncio.sleep(0.001)  # æ¨¡æ‹Ÿæ—¶é—´æµé€
                    resource_management_log.append({
                        'operation': 'runtime_event',
                        'event_type': event['event'],
                        'count': event['count'],
                        'timestamp': time.time()
                    })
                    track_lifecycle_phase(f"runtime_{event['event']}", event)
                
                # ç¬¬å…«é˜¶æ®µï¼šä¿¡å·å¤„ç†æµ‹è¯• (lines 292-293)
                track_lifecycle_phase("phase_8_signal_handling_test")
                
                # æµ‹è¯•SIGINTå¤„ç†
                sigint_handler = signal_trigger(signal.SIGINT)
                if sigint_handler:
                    with patch('sys.exit') as mock_exit:
                        sigint_handler(signal.SIGINT, None)
                        mock_exit.assert_called_with(0)
                        track_lifecycle_phase("sigint_handled_successfully")
                
                # æµ‹è¯•SIGTERMå¤„ç†
                sigterm_handler = signal_trigger(signal.SIGTERM)
                if sigterm_handler:
                    with patch('sys.exit') as mock_exit:
                        sigterm_handler(signal.SIGTERM, None)
                        mock_exit.assert_called_with(0)
                        track_lifecycle_phase("sigterm_handled_successfully")
                
                # ç¬¬ä¹é˜¶æ®µï¼šèµ„æºæ¸…ç† (æ¸…ç†é˜¶æ®µ)
                track_lifecycle_phase("phase_9_resource_cleanup")
                
                try:
                    await site.stop()
                    track_lifecycle_phase("site_cleanup_complete")
                except Exception as e:
                    track_lifecycle_phase("site_cleanup_error", {'error': str(e)})
                
                try:
                    await runner.cleanup()
                    track_lifecycle_phase("runner_cleanup_complete")
                except Exception as e:
                    track_lifecycle_phase("runner_cleanup_error", {'error': str(e)})
                
                track_lifecycle_phase("startup_lifecycle_complete")
                
                # éªŒè¯å®Œæ•´çš„å¯åŠ¨ç”Ÿå‘½å‘¨æœŸ
                expected_phases = [
                    "startup_begin", "phase_1_app_runner_creation", "app_created",
                    "runner_setup_complete", "phase_2_port_allocation", 
                    "phase_3_site_startup", "site_started",
                    "phase_4_signal_registration", "signal_handlers_registered",
                    "phase_5_browser_launch", "phase_6_status_output", "status_output_complete",
                    "phase_7_server_running", "phase_8_signal_handling_test",
                    "phase_9_resource_cleanup", "startup_lifecycle_complete"
                ]
                
                lifecycle_phases = [trace['phase'] for trace in lifecycle_trace]
                
                for expected_phase in expected_phases:
                    assert expected_phase in lifecycle_phases, f"ç¼ºå°‘ç”Ÿå‘½å‘¨æœŸé˜¶æ®µ: {expected_phase}"
                
                # éªŒè¯ä¿¡å·å¤„ç†
                assert signal.SIGINT in signal_handlers, "åº”è¯¥æ³¨å†ŒSIGINTå¤„ç†å™¨"
                assert signal.SIGTERM in signal_handlers, "åº”è¯¥æ³¨å†ŒSIGTERMå¤„ç†å™¨"
                assert len(signal_handling_log) >= 4, "åº”è¯¥æœ‰ä¿¡å·æ³¨å†Œå’Œå¤„ç†è®°å½•"
                
                # éªŒè¯èµ„æºç®¡ç†
                assert len(resource_management_log) > 0, "åº”è¯¥æœ‰èµ„æºç®¡ç†è®°å½•"
                
                # éªŒè¯è¾“å‡ºè°ƒç”¨
                assert mock_logger.info.call_count >= len(status_messages), "åº”è¯¥è¾“å‡ºæ‰€æœ‰çŠ¶æ€ä¿¡æ¯"
                assert mock_print.call_count >= len(banner_lines), "åº”è¯¥è¾“å‡ºå¯åŠ¨æ¨ªå¹…"
                assert mock_browser.called, "åº”è¯¥å°è¯•æ‰“å¼€æµè§ˆå™¨"
                
                # éªŒè¯ç«¯å£é€‰æ‹©
                assert selected_port in startup_config['port_range'] or selected_port == 8000, "åº”è¯¥é€‰æ‹©æœ‰æ•ˆç«¯å£"
                
                print(f"æœåŠ¡å™¨ç”Ÿå‘½å‘¨æœŸæµ‹è¯•å®Œæˆ: {len(lifecycle_trace)}é˜¶æ®µ, {len(resource_management_log)}èµ„æºæ“ä½œ")


class TestMainFunctionFinalGaps:
    """ä¸»å‡½æ•°æœ€ç»ˆç¼ºå£æµ‹è¯• - start_dev.py lines 167-205"""
    
    def test_main_function_remaining_execution_paths(self):
        """ä¸»å‡½æ•°å‰©ä½™æ‰§è¡Œè·¯å¾„æµ‹è¯•"""
        
        # ä¸“é—¨æ”»åšå‰©ä½™æœªè¦†ç›–çš„æ‰§è¡Œè·¯å¾„
        remaining_path_scenarios = [
            # æ·±åº¦äº¤äº’åœºæ™¯
            {
                'name': 'deep_interactive_flow',
                'args': ['start_dev.py'],
                'user_inputs': ['y', 'y', 'hot', ''],
                'python_version': (3, 9, 7),
                'dependencies': {'missing': ['pytest'], 'install_success': True},
                'project_structure': True,
                'subprocess_result': Mock(returncode=0),
                'expected_calls': ['version_check', 'dep_install', 'server_start']
            },
            # å¤æ‚é”™è¯¯æ¢å¤åœºæ™¯
            {
                'name': 'complex_error_recovery',
                'args': ['start_dev.py'],
                'user_inputs': ['y', 'y', 'enhanced'],
                'python_version': (3, 8, 0),  # è¾¹ç•Œç‰ˆæœ¬
                'dependencies': {'missing': ['coverage', 'aiohttp'], 'install_success': False},
                'project_structure': True,
                'subprocess_result': None,
                'expected_calls': ['version_check', 'dep_install_failed']
            },
            # å¤šæ­¥éª¤éªŒè¯åœºæ™¯
            {
                'name': 'multi_step_validation',
                'args': ['start_dev.py'],
                'user_inputs': ['y', 'standard', ''],
                'python_version': (3, 12, 0),  # æ–°ç‰ˆæœ¬
                'dependencies': {'all_available': True},
                'project_structure': True,
                'subprocess_result': Mock(returncode=0),
                'expected_calls': ['version_check', 'structure_check', 'server_start']
            },
            # è¾¹ç•Œæ¡ä»¶åœºæ™¯
            {
                'name': 'boundary_conditions',
                'args': ['start_dev.py', '--mode', 'hot'],
                'user_inputs': [],
                'python_version': (3, 8, 0),  # æœ€ä½æ”¯æŒç‰ˆæœ¬
                'dependencies': {'all_available': True},
                'project_structure': True,
                'subprocess_result': Mock(returncode=0),
                'expected_calls': ['direct_mode_start']
            }
        ]
        
        for scenario in remaining_path_scenarios:
            execution_path = []
            input_sequence = iter(scenario['user_inputs'])
            
            def tracked_input(prompt=''):
                try:
                    user_input = next(input_sequence)
                    execution_path.append(f"input_received:{user_input}")
                    return user_input
                except StopIteration:
                    execution_path.append("input_exhausted")
                    return 'n'
            
            # åˆ›å»ºè¯¦ç»†çš„ç‰ˆæœ¬ä¿¡æ¯
            class DetailedVersionInfo:
                def __init__(self, major, minor, micro):
                    self.major, self.minor, self.micro = major, minor, micro
                    self.releaselevel = 'final'
                    self.serial = 0
                
                def __lt__(self, other):
                    return (self.major, self.minor) < other
                
                def __ge__(self, other):
                    return (self.major, self.minor) >= other
                
                def __getitem__(self, index):
                    return [self.major, self.minor, self.micro, self.releaselevel, self.serial][index]
                
                def __iter__(self):
                    return iter([self.major, self.minor, self.micro, self.releaselevel, self.serial])
            
            mock_version = DetailedVersionInfo(*scenario['python_version'])
            
            # åˆ›å»ºé«˜çº§ä¾èµ–æ¨¡æ‹Ÿ
            def advanced_import_mock(name, *args, **kwargs):
                deps_config = scenario['dependencies']
                
                if deps_config.get('all_available', False):
                    execution_path.append(f"import_success:{name}")
                    return Mock()
                elif 'missing' in deps_config and name in deps_config['missing']:
                    execution_path.append(f"import_failed:{name}")
                    raise ImportError(f"No module named '{name}'")
                else:
                    execution_path.append(f"import_success:{name}")
                    return Mock()
            
            # åˆ›å»ºé¡¹ç›®ç»“æ„æ¨¡æ‹Ÿ
            def advanced_path_exists(path):
                if scenario['project_structure']:
                    execution_path.append(f"path_found:{path}")
                    return True
                else:
                    execution_path.append(f"path_missing:{path}")
                    return False
            
            # æ‰§è¡Œåœºæ™¯
            with patch('sys.argv', scenario['args']), \
                 patch('builtins.input', side_effect=tracked_input), \
                 patch('builtins.print') as mock_print, \
                 patch('sys.version_info', mock_version), \
                 patch('pathlib.Path.exists', side_effect=advanced_path_exists), \
                 patch('builtins.__import__', side_effect=advanced_import_mock), \
                 patch('subprocess.run', return_value=scenario['subprocess_result']) as mock_subprocess:
                
                execution_path.append(f"scenario_start:{scenario['name']}")
                
                # å¦‚æœæœ‰ä¾èµ–å®‰è£…é€»è¾‘
                install_mock_used = False
                if 'missing' in scenario['dependencies']:
                    with patch('start_dev.DevEnvironmentStarter.install_dependencies', 
                             return_value=scenario['dependencies'].get('install_success', False)) as mock_install:
                        install_mock_used = True
                        try:
                            from start_dev import main
                            result = main()
                            execution_path.append(f"main_completed:{result}")
                        except SystemExit as e:
                            execution_path.append(f"main_exit:{e.code}")
                        except Exception as e:
                            execution_path.append(f"main_exception:{type(e).__name__}")
                else:
                    try:
                        from start_dev import main
                        result = main()
                        execution_path.append(f"main_completed:{result}")
                    except SystemExit as e:
                        execution_path.append(f"main_exit:{e.code}")
                    except Exception as e:
                        execution_path.append(f"main_exception:{type(e).__name__}")
                
                # éªŒè¯æ‰§è¡Œè·¯å¾„
                expected_calls = scenario['expected_calls']
                
                for expected_call in expected_calls:
                    if expected_call == 'version_check':
                        assert any('import_success:' in step or 'import_failed:' in step for step in execution_path), \
                            f"åœºæ™¯ {scenario['name']} åº”è¯¥æœ‰ç‰ˆæœ¬æ£€æŸ¥"
                    elif expected_call == 'dep_install':
                        if install_mock_used:
                            assert any('import_failed:' in step for step in execution_path), \
                                f"åœºæ™¯ {scenario['name']} åº”è¯¥æœ‰ä¾èµ–å®‰è£…"
                    elif expected_call == 'server_start':
                        # åœ¨æŸäº›æƒ…å†µä¸‹æœåŠ¡å™¨å¯èƒ½ä¸ä¼šå¯åŠ¨ï¼Œè¿™æ˜¯å¯ä»¥æ¥å—çš„
                        pass
                
                # éªŒè¯åŸºæœ¬æ‰§è¡Œå®Œæ•´æ€§
                assert len(execution_path) > 2, f"åœºæ™¯ {scenario['name']} åº”è¯¥æœ‰æ‰§è¡Œè®°å½•"
                assert f"scenario_start:{scenario['name']}" in execution_path, "åº”è¯¥è®°å½•åœºæ™¯å¼€å§‹"
                
                print(f"ä¸»å‡½æ•°åœºæ™¯ '{scenario['name']}' å®Œæˆ: {len(execution_path)} æ­¥éª¤")


if __name__ == "__main__":
    pytest.main([__file__, "-v"])