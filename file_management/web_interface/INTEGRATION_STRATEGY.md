# ç³»ç»Ÿé›†æˆä¸å‡çº§ç­–ç•¥æ–‡æ¡£

**é¡¹ç›®**: QuantAnalyzer Pro - ç³»ç»Ÿé›†æˆä¸å¹³æ»‘å‡çº§ç­–ç•¥  
**ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¥æœŸ**: 2025-08-10  

---

## 1. é›†æˆç­–ç•¥æ¦‚è§ˆ

### 1.1 å‡çº§ç›®æ ‡

ä»å½“å‰çš„åŸå‹ç³»ç»Ÿå‡çº§åˆ°ç”Ÿäº§çº§é‡åŒ–åˆ†æå¹³å°ï¼š

**ç°æœ‰ç³»ç»Ÿ**:
- ç®€å•HTTPæœåŠ¡å™¨ + æ¨¡æ‹Ÿæ•°æ®API
- ç°ä»£åŒ–Webç•Œé¢
- åŸºç¡€å› å­ç ”ç©¶åŠŸèƒ½

**ç›®æ ‡ç³»ç»Ÿ**:
- FastAPI + Rustå¼•æ“ + åˆ†å¸ƒå¼æ•°æ®å­˜å‚¨
- é«˜æ€§èƒ½å®æ—¶è®¡ç®—
- ä¼ä¸šçº§ç›‘æ§å’Œè¿ç»´

### 1.2 é›†æˆåŸåˆ™

- **é›¶åœæœºå‡çº§**: æœåŠ¡ä¸ä¸­æ–­çš„å¹³æ»‘è¿‡æ¸¡
- **æ•°æ®å®Œæ•´æ€§**: ç¡®ä¿æ•°æ®è¿ç§»çš„å‡†ç¡®æ€§
- **å‘åå…¼å®¹**: ä¿æŒç°æœ‰APIçš„å…¼å®¹æ€§
- **é£é™©æ§åˆ¶**: åˆ†é˜¶æ®µéªŒè¯ï¼Œå¿«é€Ÿå›æ»šæœºåˆ¶
- **ç”¨æˆ·ä½“éªŒ**: æ— æ„ŸçŸ¥å‡çº§ï¼ŒåŠŸèƒ½å¢å¼º

### 1.3 å‡çº§è·¯å¾„å›¾

```mermaid
graph TB
    subgraph "ç°æœ‰ç³»ç»Ÿ"
        OLD_WEB[Webç•Œé¢<br/>index.html]
        OLD_API[Python API<br/>data-analysis-api.py]
        OLD_DATA[æ¨¡æ‹Ÿæ•°æ®]
    end
    
    subgraph "Phase 1: åŸºç¡€è®¾æ–½"
        NEW_DB[(æ•°æ®åº“<br/>ClickHouse + PostgreSQL)]
        NEW_CACHE[(ç¼“å­˜<br/>Redis)]
        NEW_RUST[Rustå¼•æ“<br/>åŸºç¡€æ¨¡å—]
    end
    
    subgraph "Phase 2: æœåŠ¡å‡çº§"
        NEW_API[FastAPIæœåŠ¡<br/>v2 API]
        BRIDGE[APIæ¡¥æ¥å™¨<br/>v1â†’v2è·¯ç”±]
        DATA_SYNC[æ•°æ®åŒæ­¥å™¨]
    end
    
    subgraph "Phase 3: åŠŸèƒ½å¢å¼º"
        ENHANCED_WEB[å¢å¼ºWebç•Œé¢]
        REALTIME[å®æ—¶æ•°æ®æµ]
        MONITORING[ç›‘æ§ç³»ç»Ÿ]
    end
    
    subgraph "Phase 4: å®Œæ•´ç³»ç»Ÿ"
        FINAL_SYSTEM[QuantAnalyzer Pro<br/>ç”Ÿäº§ç³»ç»Ÿ]
    end
    
    OLD_WEB --> ENHANCED_WEB
    OLD_API --> BRIDGE
    BRIDGE --> NEW_API
    OLD_DATA --> DATA_SYNC
    DATA_SYNC --> NEW_DB
    
    NEW_DB --> FINAL_SYSTEM
    NEW_API --> FINAL_SYSTEM
    ENHANCED_WEB --> FINAL_SYSTEM
    REALTIME --> FINAL_SYSTEM
    MONITORING --> FINAL_SYSTEM
```

---

## 2. Phase 1: åŸºç¡€è®¾æ–½å»ºè®¾

### 2.1 æ•°æ®åº“éƒ¨ç½²

#### 2.1.1 ClickHouseé›†ç¾¤éƒ¨ç½²

```bash
# docker-compose-clickhouse.yml
version: '3.8'

services:
  clickhouse-01:
    image: clickhouse/clickhouse-server:latest
    container_name: quant_clickhouse_01
    ports:
      - "8123:8123"
      - "9000:9000"
    volumes:
      - clickhouse_01_data:/var/lib/clickhouse
      - ./clickhouse/config.xml:/etc/clickhouse-server/config.xml
      - ./clickhouse/users.xml:/etc/clickhouse-server/users.xml
    environment:
      - CLICKHOUSE_DB=quant_data
      - CLICKHOUSE_USER=quantuser
      - CLICKHOUSE_PASSWORD=quantpass
    networks:
      - quant_network

  clickhouse-02:
    image: clickhouse/clickhouse-server:latest
    container_name: quant_clickhouse_02  
    ports:
      - "8124:8123"
      - "9001:9000"
    volumes:
      - clickhouse_02_data:/var/lib/clickhouse
      - ./clickhouse/config-replica.xml:/etc/clickhouse-server/config.xml
      - ./clickhouse/users.xml:/etc/clickhouse-server/users.xml
    environment:
      - CLICKHOUSE_DB=quant_data
    networks:
      - quant_network

  postgres:
    image: postgres:15
    container_name: quant_postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres/init.sql:/docker-entrypoint-initdb.d/init.sql
    environment:
      - POSTGRES_DB=quant_metadata
      - POSTGRES_USER=quantuser
      - POSTGRES_PASSWORD=quantpass
    networks:
      - quant_network

  redis:
    image: redis:7-alpine
    container_name: quant_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      - ./redis/redis.conf:/etc/redis/redis.conf
    command: redis-server /etc/redis/redis.conf
    networks:
      - quant_network

volumes:
  clickhouse_01_data:
  clickhouse_02_data:
  postgres_data:
  redis_data:

networks:
  quant_network:
    driver: bridge
```

#### 2.1.2 æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬

```sql
-- postgres/init.sql
-- åˆ›å»ºåŸºç¡€è¡¨ç»“æ„
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pg_trgm";

-- ç”¨æˆ·è¡¨
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    role VARCHAR(20) DEFAULT 'user',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- å› å­å®šä¹‰è¡¨
CREATE TABLE factor_definitions (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    name VARCHAR(255) NOT NULL UNIQUE,
    category VARCHAR(100) NOT NULL,
    formula TEXT NOT NULL,
    parameters JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    is_active BOOLEAN DEFAULT true
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_factor_definitions_category ON factor_definitions(category);
CREATE INDEX idx_factor_definitions_active ON factor_definitions(is_active);
```

```sql
-- clickhouse/init.sql
-- ClickHouseè¡¨ç»“æ„
CREATE DATABASE IF NOT EXISTS quant_data;

USE quant_data;

-- å¸‚åœºæ•°æ®è¡¨
CREATE TABLE market_data_daily (
    symbol String,
    date Date,
    timestamp DateTime64(3, 'UTC'),
    open Float64,
    high Float64,
    low Float64,
    close Float64,
    volume Float64,
    created_at DateTime DEFAULT now()
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (symbol, date);

-- å› å­å€¼è¡¨
CREATE TABLE factor_values (
    factor_id String,
    symbol String,
    date Date,
    timestamp DateTime64(3, 'UTC'),
    value Float64,
    created_at DateTime DEFAULT now()
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (factor_id, symbol, date);
```

### 2.2 Rustå¼•æ“æ„å»º

#### 2.2.1 Rusté¡¹ç›®åˆå§‹åŒ–

```bash
# åˆ›å»ºRusté¡¹ç›®
mkdir -p rust_engine
cd rust_engine
cargo init --lib

# é…ç½®Cargo.toml
cat > Cargo.toml << 'EOF'
[package]
name = "quant_engine"
version = "0.1.0"
edition = "2021"

[lib]
name = "quant_engine"
crate-type = ["cdylib", "rlib"]

[dependencies]
pyo3 = { version = "0.20", features = ["extension-module"] }
polars = { version = "0.36", features = ["lazy", "temporal"] }
ndarray = "0.15"
rayon = "1.8"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
chrono = { version = "0.4", features = ["serde"] }
anyhow = "1.0"
EOF

# åŸºç¡€æ¨¡å—ç»“æ„
mkdir -p src/{core,factor,backtest,data}
```

#### 2.2.2 åŸºç¡€Pythonç»‘å®š

```rust
// src/lib.rs
use pyo3::prelude::*;

mod core;
mod factor;
mod data;

use factor::FactorEngine;

#[pymodule]
fn quant_engine(_py: Python, m: &PyModule) -> PyResult<()> {
    m.add_class::<FactorEngine>()?;
    
    m.add_function(wrap_pyfunction!(health_check, m)?)?;
    
    Ok(())
}

#[pyfunction]
fn health_check() -> String {
    "Rust engine is healthy".to_string()
}

// src/factor/mod.rs
use pyo3::prelude::*;
use std::collections::HashMap;

#[pyclass]
pub struct FactorEngine {
    initialized: bool,
}

#[pymethods]
impl FactorEngine {
    #[new]
    pub fn new() -> Self {
        Self {
            initialized: true,
        }
    }
    
    #[pyo3(signature = (data, factors))]
    pub fn calculate_factors(
        &self,
        data: Vec<HashMap<String, f64>>,
        factors: Vec<String>
    ) -> PyResult<HashMap<String, Vec<f64>>> {
        // åŸºç¡€å®ç°
        let mut results = HashMap::new();
        
        for factor in factors {
            let values: Vec<f64> = (0..data.len())
                .map(|i| i as f64 * 0.1)
                .collect();
            results.insert(factor, values);
        }
        
        Ok(results)
    }
    
    pub fn health_check(&self) -> bool {
        self.initialized
    }
}
```

#### 2.2.3 Pythoné›†æˆæµ‹è¯•

```python
# test_rust_integration.py
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'rust_engine/target/release'))

def test_rust_engine():
    """æµ‹è¯•Rustå¼•æ“é›†æˆ"""
    try:
        import quant_engine
        
        # å¥åº·æ£€æŸ¥
        health = quant_engine.health_check()
        print(f"Rust engine health: {health}")
        assert health == "Rust engine is healthy"
        
        # åˆ›å»ºå› å­å¼•æ“
        engine = quant_engine.FactorEngine()
        assert engine.health_check() == True
        
        # æµ‹è¯•å› å­è®¡ç®—
        test_data = [
            {"close": 100.0, "volume": 1000000},
            {"close": 101.0, "volume": 1100000},
            {"close": 99.0, "volume": 900000},
        ]
        
        factors = ["test_factor_1", "test_factor_2"]
        results = engine.calculate_factors(test_data, factors)
        
        print(f"Calculation results: {results}")
        assert len(results) == 2
        assert len(results["test_factor_1"]) == 3
        
        print("âœ… Rust engine integration test passed")
        return True
        
    except Exception as e:
        print(f"âŒ Rust engine integration test failed: {e}")
        return False

if __name__ == "__main__":
    test_rust_engine()
```

### 2.3 éƒ¨ç½²éªŒè¯è„šæœ¬

```python
# deployment/phase1_validator.py
import asyncio
import asyncpg
import aioredis
import requests
from datetime import datetime

class Phase1Validator:
    """Phase 1éƒ¨ç½²éªŒè¯å™¨"""
    
    def __init__(self):
        self.postgres_url = "postgresql://quantuser:quantpass@localhost:5432/quant_metadata"
        self.redis_url = "redis://localhost:6379"
        self.clickhouse_url = "http://localhost:8123"
        
    async def validate_deployment(self):
        """éªŒè¯Phase 1éƒ¨ç½²"""
        print("ğŸ” Phase 1 éƒ¨ç½²éªŒè¯å¼€å§‹...")
        
        results = {}
        
        # éªŒè¯PostgreSQL
        results["postgres"] = await self.validate_postgres()
        
        # éªŒè¯Redis
        results["redis"] = await self.validate_redis()
        
        # éªŒè¯ClickHouse
        results["clickhouse"] = await self.validate_clickhouse()
        
        # éªŒè¯Rustå¼•æ“
        results["rust_engine"] = await self.validate_rust_engine()
        
        # ç”ŸæˆéªŒè¯æŠ¥å‘Š
        self.generate_validation_report(results)
        
        return all(results.values())
    
    async def validate_postgres(self):
        """éªŒè¯PostgreSQLè¿æ¥å’Œè¡¨ç»“æ„"""
        try:
            conn = await asyncpg.connect(self.postgres_url)
            
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            tables = await conn.fetch("""
                SELECT table_name FROM information_schema.tables 
                WHERE table_schema = 'public'
            """)
            
            table_names = [row['table_name'] for row in tables]
            required_tables = ['users', 'factor_definitions']
            
            missing_tables = set(required_tables) - set(table_names)
            if missing_tables:
                print(f"âŒ Missing PostgreSQL tables: {missing_tables}")
                return False
            
            await conn.close()
            print("âœ… PostgreSQL validation passed")
            return True
            
        except Exception as e:
            print(f"âŒ PostgreSQL validation failed: {e}")
            return False
    
    async def validate_redis(self):
        """éªŒè¯Redisè¿æ¥"""
        try:
            redis = aioredis.from_url(self.redis_url)
            
            # æµ‹è¯•åŸºç¡€æ“ä½œ
            await redis.set("test_key", "test_value")
            value = await redis.get("test_key")
            
            if value.decode() != "test_value":
                print("âŒ Redis read/write test failed")
                return False
            
            await redis.delete("test_key")
            await redis.close()
            
            print("âœ… Redis validation passed")
            return True
            
        except Exception as e:
            print(f"âŒ Redis validation failed: {e}")
            return False
    
    async def validate_clickhouse(self):
        """éªŒè¯ClickHouseè¿æ¥å’Œè¡¨ç»“æ„"""
        try:
            # æ£€æŸ¥è¿æ¥
            response = requests.get(f"{self.clickhouse_url}/ping")
            if response.text.strip() != "Ok.":
                print("âŒ ClickHouse ping failed")
                return False
            
            # æ£€æŸ¥æ•°æ®åº“
            response = requests.post(
                f"{self.clickhouse_url}",
                data="SHOW DATABASES"
            )
            
            if "quant_data" not in response.text:
                print("âŒ ClickHouse database 'quant_data' not found")
                return False
            
            # æ£€æŸ¥è¡¨ç»“æ„
            response = requests.post(
                f"{self.clickhouse_url}",
                data="SHOW TABLES FROM quant_data"
            )
            
            tables = response.text.strip().split('\n')
            required_tables = ['market_data_daily', 'factor_values']
            
            for table in required_tables:
                if table not in tables:
                    print(f"âŒ ClickHouse table '{table}' not found")
                    return False
            
            print("âœ… ClickHouse validation passed")
            return True
            
        except Exception as e:
            print(f"âŒ ClickHouse validation failed: {e}")
            return False
    
    async def validate_rust_engine(self):
        """éªŒè¯Rustå¼•æ“"""
        try:
            # å¯¼å…¥å¹¶æµ‹è¯•Rustå¼•æ“
            sys.path.append('./rust_engine/target/release')
            import quant_engine
            
            # å¥åº·æ£€æŸ¥
            health = quant_engine.health_check()
            if health != "Rust engine is healthy":
                print("âŒ Rust engine health check failed")
                return False
            
            # åˆ›å»ºå¼•æ“å®ä¾‹
            engine = quant_engine.FactorEngine()
            if not engine.health_check():
                print("âŒ Rust FactorEngine health check failed")
                return False
            
            print("âœ… Rust engine validation passed")
            return True
            
        except Exception as e:
            print(f"âŒ Rust engine validation failed: {e}")
            return False
    
    def generate_validation_report(self, results):
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        report = f"""
=== Phase 1 éƒ¨ç½²éªŒè¯æŠ¥å‘Š ===
æ—¶é—´: {datetime.now().isoformat()}

ç»„ä»¶çŠ¶æ€:
- PostgreSQL: {'âœ… é€šè¿‡' if results.get('postgres') else 'âŒ å¤±è´¥'}
- Redis: {'âœ… é€šè¿‡' if results.get('redis') else 'âŒ å¤±è´¥'}
- ClickHouse: {'âœ… é€šè¿‡' if results.get('clickhouse') else 'âŒ å¤±è´¥'}
- Rustå¼•æ“: {'âœ… é€šè¿‡' if results.get('rust_engine') else 'âŒ å¤±è´¥'}

æ€»ä½“çŠ¶æ€: {'âœ… å…¨éƒ¨é€šè¿‡' if all(results.values()) else 'âŒ éƒ¨åˆ†å¤±è´¥'}

ä¸‹ä¸€æ­¥: {'å¯ä»¥è¿›å…¥Phase 2' if all(results.values()) else 'ä¿®å¤å¤±è´¥ç»„ä»¶åé‡æ–°éªŒè¯'}
"""
        
        print(report)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(f"phase1_validation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt", "w") as f:
            f.write(report)

async def main():
    validator = Phase1Validator()
    success = await validator.validate_deployment()
    
    if success:
        print("\nğŸ‰ Phase 1 éªŒè¯æˆåŠŸï¼å¯ä»¥å¼€å§‹ Phase 2 éƒ¨ç½²")
    else:
        print("\nâš ï¸ Phase 1 éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¹¶ä¿®å¤é—®é¢˜")
    
    return success

if __name__ == "__main__":
    asyncio.run(main())
```

---

## 3. Phase 2: APIæœåŠ¡å‡çº§

### 3.1 FastAPIæœåŠ¡éƒ¨ç½²

#### 3.1.1 æ¸è¿›å¼APIè¿ç§»

```python
# migration/api_bridge.py
from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import JSONResponse
import httpx
import asyncio
import json
from datetime import datetime

class APIBridge:
    """APIæ¡¥æ¥å™¨ï¼Œå®ç°V1åˆ°V2çš„å¹³æ»‘è¿ç§»"""
    
    def __init__(self):
        self.v1_server = "http://localhost:8003"  # ç°æœ‰æœåŠ¡
        self.v2_server = "http://localhost:8000"  # æ–°æœåŠ¡
        self.migration_rules = self.load_migration_rules()
        
    def load_migration_rules(self):
        """åŠ è½½è¿ç§»è§„åˆ™"""
        return {
            # V1ç«¯ç‚¹åˆ°V2ç«¯ç‚¹çš„æ˜ å°„
            "/api/v1/data/overview": "/api/v2/data/overview",
            "/api/v1/factors/library": "/api/v2/factors/library",
            "/api/v1/factors/generate": "/api/v2/ai/factors/generate",
            "/api/v1/backtest/results": "/api/v2/backtest/results",
            "/api/v1/ai/engines": "/api/v2/system/ai-engines",
            "/api/v1/reports": "/api/v2/reports/list",
        }
    
    async def route_request(self, request: Request):
        """æ™ºèƒ½è·¯ç”±è¯·æ±‚"""
        path = request.url.path
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯V1 API
        if path.startswith("/api/v1/"):
            return await self.handle_v1_request(request, path)
        
        # V2 APIç›´æ¥è½¬å‘
        elif path.startswith("/api/v2/"):
            return await self.handle_v2_request(request, path)
        
        else:
            raise HTTPException(status_code=404, detail="API endpoint not found")
    
    async def handle_v1_request(self, request: Request, path: str):
        """å¤„ç†V1 APIè¯·æ±‚"""
        
        # æ£€æŸ¥V2æ˜¯å¦å¯ç”¨
        if await self.is_v2_available():
            # å°è¯•è½¬æ¢ä¸ºV2è¯·æ±‚
            v2_response = await self.convert_to_v2(request, path)
            if v2_response:
                # è½¬æ¢ä¸ºV1æ ¼å¼å“åº”
                return self.convert_to_v1_format(v2_response)
        
        # é™çº§åˆ°V1æœåŠ¡
        return await self.proxy_to_v1(request, path)
    
    async def handle_v2_request(self, request: Request, path: str):
        """å¤„ç†V2 APIè¯·æ±‚"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.request(
                    method=request.method,
                    url=f"{self.v2_server}{path}",
                    headers=dict(request.headers),
                    content=await request.body()
                )
                return JSONResponse(
                    content=response.json(),
                    status_code=response.status_code
                )
        except Exception as e:
            # V2æœåŠ¡å¼‚å¸¸æ—¶çš„å¤„ç†
            return JSONResponse(
                content={
                    "success": False,
                    "error": f"V2 service unavailable: {str(e)}",
                    "fallback": "V1 service not available for this endpoint"
                },
                status_code=503
            )
    
    async def convert_to_v2(self, request: Request, v1_path: str):
        """å°†V1è¯·æ±‚è½¬æ¢ä¸ºV2è¯·æ±‚"""
        v2_path = self.migration_rules.get(v1_path)
        if not v2_path:
            return None
        
        try:
            # è½¬æ¢è¯·æ±‚å‚æ•°å’Œæ ¼å¼
            converted_data = await self.convert_request_format(request, v1_path, v2_path)
            
            async with httpx.AsyncClient() as client:
                response = await client.request(
                    method=request.method,
                    url=f"{self.v2_server}{v2_path}",
                    headers={"Content-Type": "application/json"},
                    json=converted_data
                )
                
                if response.status_code == 200:
                    return response.json()
                
        except Exception as e:
            print(f"V2 conversion failed: {e}")
        
        return None
    
    async def convert_request_format(self, request: Request, v1_path: str, v2_path: str):
        """è½¬æ¢è¯·æ±‚æ ¼å¼"""
        
        if v1_path == "/api/v1/factors/library":
            # V1æŸ¥è¯¢å‚æ•°è½¬æ¢ä¸ºV2æ ¼å¼
            query_params = dict(request.query_params)
            return {
                "category": query_params.get("category"),
                "min_ic": float(query_params.get("min_ic", 0)) if query_params.get("min_ic") else None,
                "limit": int(query_params.get("limit", 50)),
                "offset": int(query_params.get("offset", 0))
            }
        
        # å…¶ä»–ç«¯ç‚¹çš„è½¬æ¢é€»è¾‘
        return {}
    
    def convert_to_v1_format(self, v2_response):
        """å°†V2å“åº”è½¬æ¢ä¸ºV1æ ¼å¼"""
        
        # ç¡®ä¿V1æ ¼å¼çš„successå­—æ®µ
        if "success" not in v2_response:
            v2_response["success"] = True
        
        # æ·»åŠ V1ç‰¹æœ‰çš„å­—æ®µ
        v2_response["timestamp"] = int(datetime.now().timestamp() * 1000)
        
        return JSONResponse(content=v2_response)
    
    async def proxy_to_v1(self, request: Request, path: str):
        """ä»£ç†åˆ°V1æœåŠ¡"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.request(
                    method=request.method,
                    url=f"{self.v1_server}{path}",
                    headers=dict(request.headers),
                    content=await request.body(),
                    params=dict(request.query_params)
                )
                
                return JSONResponse(
                    content=response.json(),
                    status_code=response.status_code
                )
                
        except Exception as e:
            return JSONResponse(
                content={
                    "success": False,
                    "error": f"V1 service unavailable: {str(e)}"
                },
                status_code=503
            )
    
    async def is_v2_available(self):
        """æ£€æŸ¥V2æœåŠ¡æ˜¯å¦å¯ç”¨"""
        try:
            async with httpx.AsyncClient(timeout=2.0) as client:
                response = await client.get(f"{self.v2_server}/health")
                return response.status_code == 200
        except:
            return False

# FastAPIåº”ç”¨é›†æˆæ¡¥æ¥å™¨
app = FastAPI(title="QuantAnalyzer API Bridge")
bridge = APIBridge()

@app.api_route("/{path:path}", methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"])
async def api_bridge(request: Request):
    """APIæ¡¥æ¥å…¥å£"""
    return await bridge.route_request(request)

# å¥åº·æ£€æŸ¥
@app.get("/bridge/health")
async def bridge_health():
    """æ¡¥æ¥å™¨å¥åº·æ£€æŸ¥"""
    v1_available = False
    v2_available = await bridge.is_v2_available()
    
    try:
        async with httpx.AsyncClient(timeout=2.0) as client:
            response = await client.get(f"{bridge.v1_server}/api/v1/health")
            v1_available = response.status_code == 200
    except:
        pass
    
    return {
        "bridge_status": "healthy",
        "v1_service": "available" if v1_available else "unavailable",
        "v2_service": "available" if v2_available else "unavailable",
        "migration_active": v1_available and v2_available
    }
```

#### 3.1.2 æ•°æ®åŒæ­¥å™¨

```python
# migration/data_sync.py
import asyncio
import asyncpg
import aioredis
import httpx
from datetime import datetime, timedelta
import logging

class DataSynchronizer:
    """æ•°æ®åŒæ­¥å™¨ï¼Œè´Ÿè´£ä»V1è¿ç§»åˆ°V2æ•°æ®å­˜å‚¨"""
    
    def __init__(self):
        self.v1_api = "http://localhost:8003/api/v1"
        self.postgres_url = "postgresql://quantuser:quantpass@localhost:5432/quant_metadata"
        self.clickhouse_url = "http://localhost:8123"
        self.redis_url = "redis://localhost:6379"
        
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
    
    async def sync_all_data(self):
        """åŒæ­¥æ‰€æœ‰æ•°æ®"""
        self.logger.info("ğŸ”„ å¼€å§‹æ•°æ®åŒæ­¥...")
        
        tasks = [
            self.sync_factor_definitions(),
            self.sync_historical_data(),
            self.sync_user_data(),
            self.warm_cache()
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        success_count = sum(1 for r in results if not isinstance(r, Exception))
        
        self.logger.info(f"âœ… æ•°æ®åŒæ­¥å®Œæˆ: {success_count}/{len(tasks)} ä»»åŠ¡æˆåŠŸ")
        
        return success_count == len(tasks)
    
    async def sync_factor_definitions(self):
        """åŒæ­¥å› å­å®šä¹‰"""
        self.logger.info("ğŸ“Š åŒæ­¥å› å­å®šä¹‰...")
        
        try:
            # ä»V1è·å–å› å­åº“
            async with httpx.AsyncClient() as client:
                response = await client.get(f"{self.v1_api}/factors/library?limit=1000")
                v1_factors = response.json()["data"]["factors"]
            
            # å†™å…¥PostgreSQL
            conn = await asyncpg.connect(self.postgres_url)
            
            for factor in v1_factors:
                await conn.execute("""
                    INSERT INTO factor_definitions 
                    (name, category, formula, parameters, ic_mean, sharpe_ratio, usage_count)
                    VALUES ($1, $2, $3, $4, $5, $6, $7)
                    ON CONFLICT (name) DO UPDATE SET
                        ic_mean = EXCLUDED.ic_mean,
                        sharpe_ratio = EXCLUDED.sharpe_ratio,
                        usage_count = EXCLUDED.usage_count
                """, 
                factor["name"],
                factor["category"],
                factor.get("formula", ""),
                factor.get("parameters", {}),
                factor.get("ic", 0.0),
                factor.get("sharpe", 0.0),
                factor.get("usage_count", 0)
                )
            
            await conn.close()
            self.logger.info(f"âœ… åŒæ­¥äº† {len(v1_factors)} ä¸ªå› å­å®šä¹‰")
            
        except Exception as e:
            self.logger.error(f"âŒ å› å­å®šä¹‰åŒæ­¥å¤±è´¥: {e}")
            raise
    
    async def sync_historical_data(self):
        """åŒæ­¥å†å²æ•°æ®"""
        self.logger.info("ğŸ“ˆ åŒæ­¥å†å²å¸‚åœºæ•°æ®...")
        
        try:
            # ç”Ÿæˆæ¨¡æ‹Ÿå†å²æ•°æ®ï¼ˆå®é™…åœºæ™¯ä¸­ä»V1æ•°æ®æºè·å–ï¼‰
            symbols = ["BTCUSDT", "ETHUSDT", "BNBUSDT"]
            start_date = datetime.now() - timedelta(days=365)
            
            data_points = []
            
            for symbol in symbols:
                current_date = start_date
                price = 50000.0 if symbol == "BTCUSDT" else 3000.0
                
                while current_date <= datetime.now():
                    # æ¨¡æ‹Ÿä»·æ ¼å˜åŠ¨
                    price_change = price * (random.uniform(-0.05, 0.05))
                    price += price_change
                    
                    data_points.append({
                        "symbol": symbol,
                        "date": current_date.date(),
                        "timestamp": current_date,
                        "open": price,
                        "high": price * 1.02,
                        "low": price * 0.98,
                        "close": price,
                        "volume": random.uniform(1000000, 5000000)
                    })
                    
                    current_date += timedelta(days=1)
            
            # æ‰¹é‡å†™å…¥ClickHouse
            await self.batch_insert_clickhouse("market_data_daily", data_points)
            
            self.logger.info(f"âœ… åŒæ­¥äº† {len(data_points)} æ¡å†å²æ•°æ®")
            
        except Exception as e:
            self.logger.error(f"âŒ å†å²æ•°æ®åŒæ­¥å¤±è´¥: {e}")
            raise
    
    async def sync_user_data(self):
        """åŒæ­¥ç”¨æˆ·æ•°æ®"""
        self.logger.info("ğŸ‘¥ åŒæ­¥ç”¨æˆ·æ•°æ®...")
        
        try:
            # åˆ›å»ºé»˜è®¤ç®¡ç†å‘˜ç”¨æˆ·
            conn = await asyncpg.connect(self.postgres_url)
            
            await conn.execute("""
                INSERT INTO users (username, email, password_hash, role)
                VALUES ($1, $2, $3, $4)
                ON CONFLICT (username) DO NOTHING
            """, 
            "admin",
            "admin@quantanalyzer.pro",
            "hashed_password_here",  # å®é™…åº”ç”¨ä¸­ä½¿ç”¨çœŸå®çš„å¯†ç å“ˆå¸Œ
            "admin"
            )
            
            await conn.close()
            self.logger.info("âœ… ç”¨æˆ·æ•°æ®åŒæ­¥å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"âŒ ç”¨æˆ·æ•°æ®åŒæ­¥å¤±è´¥: {e}")
            raise
    
    async def warm_cache(self):
        """é¢„çƒ­ç¼“å­˜"""
        self.logger.info("ğŸ”¥ é¢„çƒ­Redisç¼“å­˜...")
        
        try:
            redis = aioredis.from_url(self.redis_url)
            
            # ç¼“å­˜å¸¸ç”¨çš„å› å­åº“æŸ¥è¯¢ç»“æœ
            common_queries = [
                ("technical", None),
                ("statistical", None), 
                (None, 0.1),  # min_ic = 0.1
            ]
            
            for category, min_ic in common_queries:
                cache_key = f"factor:library:{category or 'all'}:{min_ic or 'none'}"
                
                # æ¨¡æ‹ŸæŸ¥è¯¢ç»“æœï¼ˆå®é™…ä¸­ä»æ•°æ®åº“è·å–ï¼‰
                cache_data = {
                    "factors": [],
                    "total_count": 0,
                    "cached_at": datetime.now().isoformat()
                }
                
                await redis.setex(cache_key, 3600, json.dumps(cache_data))
            
            await redis.close()
            self.logger.info("âœ… ç¼“å­˜é¢„çƒ­å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"âŒ ç¼“å­˜é¢„çƒ­å¤±è´¥: {e}")
            raise
    
    async def batch_insert_clickhouse(self, table: str, data: list):
        """æ‰¹é‡æ’å…¥ClickHouseæ•°æ®"""
        if not data:
            return
        
        # æ„å»ºæ‰¹é‡æ’å…¥è¯­å¥
        columns = list(data[0].keys())
        values_placeholder = ", ".join([f"%({col})s" for col in columns])
        
        query = f"""
        INSERT INTO quant_data.{table} ({', '.join(columns)})
        VALUES ({values_placeholder})
        """
        
        # ä½¿ç”¨HTTPæ¥å£æ‰¹é‡æ’å…¥
        import requests
        
        # è½¬æ¢ä¸ºTSVæ ¼å¼
        tsv_data = []
        for row in data:
            tsv_row = "\t".join([str(row[col]) for col in columns])
            tsv_data.append(tsv_row)
        
        tsv_content = "\n".join(tsv_data)
        
        response = requests.post(
            f"{self.clickhouse_url}",
            params={"query": f"INSERT INTO quant_data.{table} FORMAT TSV"},
            data=tsv_content.encode('utf-8'),
            headers={"Content-Type": "text/tab-separated-values"}
        )
        
        if response.status_code != 200:
            raise Exception(f"ClickHouse insert failed: {response.text}")

async def main():
    """è¿è¡Œæ•°æ®åŒæ­¥"""
    sync = DataSynchronizer()
    success = await sync.sync_all_data()
    
    if success:
        print("ğŸ‰ æ•°æ®åŒæ­¥å®Œæˆï¼")
    else:
        print("âš ï¸ æ•°æ®åŒæ­¥éƒ¨åˆ†å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")

if __name__ == "__main__":
    import random
    import json
    asyncio.run(main())
```

### 3.2 Phase 2éªŒè¯

```python
# deployment/phase2_validator.py
import asyncio
import httpx
import asyncpg
import json
from datetime import datetime

class Phase2Validator:
    """Phase 2éƒ¨ç½²éªŒè¯å™¨"""
    
    def __init__(self):
        self.bridge_url = "http://localhost:8001"  # APIæ¡¥æ¥å™¨
        self.v1_url = "http://localhost:8003"      # V1æœåŠ¡
        self.v2_url = "http://localhost:8000"      # V2æœåŠ¡
        
    async def validate_phase2(self):
        """éªŒè¯Phase 2éƒ¨ç½²"""
        print("ğŸ” Phase 2 éƒ¨ç½²éªŒè¯å¼€å§‹...")
        
        tests = [
            self.test_api_bridge(),
            self.test_v1_compatibility(), 
            self.test_v2_functionality(),
            self.test_data_migration(),
            self.test_fallback_mechanism()
        ]
        
        results = await asyncio.gather(*tests, return_exceptions=True)
        
        success_count = sum(1 for r in results if r == True)
        
        print(f"\nğŸ“Š éªŒè¯ç»“æœ: {success_count}/{len(tests)} é€šè¿‡")
        
        return success_count == len(tests)
    
    async def test_api_bridge(self):
        """æµ‹è¯•APIæ¡¥æ¥å™¨"""
        print("ğŸŒ‰ æµ‹è¯•APIæ¡¥æ¥å™¨...")
        
        try:
            async with httpx.AsyncClient() as client:
                # æµ‹è¯•æ¡¥æ¥å™¨å¥åº·çŠ¶æ€
                response = await client.get(f"{self.bridge_url}/bridge/health")
                
                if response.status_code != 200:
                    print("âŒ æ¡¥æ¥å™¨å¥åº·æ£€æŸ¥å¤±è´¥")
                    return False
                
                health_data = response.json()
                
                if health_data["bridge_status"] != "healthy":
                    print("âŒ æ¡¥æ¥å™¨çŠ¶æ€å¼‚å¸¸")
                    return False
                
                print("âœ… APIæ¡¥æ¥å™¨æµ‹è¯•é€šè¿‡")
                return True
                
        except Exception as e:
            print(f"âŒ APIæ¡¥æ¥å™¨æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def test_v1_compatibility(self):
        """æµ‹è¯•V1å…¼å®¹æ€§"""
        print("ğŸ”„ æµ‹è¯•V1å…¼å®¹æ€§...")
        
        try:
            async with httpx.AsyncClient() as client:
                # æµ‹è¯•V1 APIé€šè¿‡æ¡¥æ¥å™¨è®¿é—®
                v1_endpoints = [
                    "/api/v1/data/overview",
                    "/api/v1/factors/library",
                    "/api/v1/health"
                ]
                
                for endpoint in v1_endpoints:
                    response = await client.get(f"{self.bridge_url}{endpoint}")
                    
                    if response.status_code != 200:
                        print(f"âŒ V1ç«¯ç‚¹ {endpoint} å¤±è´¥")
                        return False
                    
                    data = response.json()
                    if not data.get("success", True):
                        print(f"âŒ V1ç«¯ç‚¹ {endpoint} è¿”å›é”™è¯¯")
                        return False
                
                print("âœ… V1å…¼å®¹æ€§æµ‹è¯•é€šè¿‡")
                return True
                
        except Exception as e:
            print(f"âŒ V1å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def test_v2_functionality(self):
        """æµ‹è¯•V2åŠŸèƒ½"""
        print("ğŸš€ æµ‹è¯•V2åŠŸèƒ½...")
        
        try:
            async with httpx.AsyncClient() as client:
                # æµ‹è¯•V2 API
                response = await client.get(f"{self.v2_url}/health")
                
                if response.status_code != 200:
                    print("âŒ V2å¥åº·æ£€æŸ¥å¤±è´¥")
                    return False
                
                # æµ‹è¯•å› å­åº“API
                response = await client.get(f"{self.v2_url}/api/v2/factors/library")
                
                if response.status_code != 200:
                    print("âŒ V2å› å­åº“APIå¤±è´¥")
                    return False
                
                print("âœ… V2åŠŸèƒ½æµ‹è¯•é€šè¿‡")
                return True
                
        except Exception as e:
            print(f"âŒ V2åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def test_data_migration(self):
        """æµ‹è¯•æ•°æ®è¿ç§»"""
        print("ğŸ“Š æµ‹è¯•æ•°æ®è¿ç§»...")
        
        try:
            # æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦æœ‰è¿ç§»çš„æ•°æ®
            conn = await asyncpg.connect("postgresql://quantuser:quantpass@localhost:5432/quant_metadata")
            
            # æ£€æŸ¥å› å­å®šä¹‰
            factor_count = await conn.fetchval("SELECT COUNT(*) FROM factor_definitions")
            
            if factor_count == 0:
                print("âŒ å› å­å®šä¹‰æ•°æ®è¿ç§»å¤±è´¥")
                return False
            
            # æ£€æŸ¥ç”¨æˆ·æ•°æ®
            user_count = await conn.fetchval("SELECT COUNT(*) FROM users")
            
            if user_count == 0:
                print("âŒ ç”¨æˆ·æ•°æ®è¿ç§»å¤±è´¥")
                return False
            
            await conn.close()
            
            print(f"âœ… æ•°æ®è¿ç§»æµ‹è¯•é€šè¿‡ (å› å­:{factor_count}, ç”¨æˆ·:{user_count})")
            return True
            
        except Exception as e:
            print(f"âŒ æ•°æ®è¿ç§»æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def test_fallback_mechanism(self):
        """æµ‹è¯•é™çº§æœºåˆ¶"""
        print("ğŸ›¡ï¸ æµ‹è¯•é™çº§æœºåˆ¶...")
        
        try:
            # è¿™é‡Œåº”è¯¥æ¨¡æ‹ŸV2æœåŠ¡æ•…éšœï¼Œæµ‹è¯•æ˜¯å¦èƒ½é™çº§åˆ°V1
            # ç®€åŒ–æµ‹è¯•ï¼šæ£€æŸ¥æ¡¥æ¥å™¨æ˜¯å¦èƒ½æ­£ç¡®å¤„ç†é”™è¯¯
            
            async with httpx.AsyncClient() as client:
                # æµ‹è¯•ä¸å­˜åœ¨çš„V2ç«¯ç‚¹æ˜¯å¦èƒ½é™çº§
                response = await client.get(f"{self.bridge_url}/api/v1/data/overview")
                
                if response.status_code != 200:
                    print("âŒ é™çº§æœºåˆ¶æµ‹è¯•å¤±è´¥")
                    return False
                
                print("âœ… é™çº§æœºåˆ¶æµ‹è¯•é€šè¿‡")
                return True
                
        except Exception as e:
            print(f"âŒ é™çº§æœºåˆ¶æµ‹è¯•å¤±è´¥: {e}")
            return False

async def main():
    validator = Phase2Validator()
    success = await validator.validate_phase2()
    
    if success:
        print("\nğŸ‰ Phase 2 éªŒè¯æˆåŠŸï¼å¯ä»¥å¼€å§‹ Phase 3 éƒ¨ç½²")
    else:
        print("\nâš ï¸ Phase 2 éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¹¶ä¿®å¤é—®é¢˜")

if __name__ == "__main__":
    asyncio.run(main())
```

---

## 4. Phase 3: å‰ç«¯å‡çº§å’Œå®æ—¶åŠŸèƒ½

### 4.1 å‰ç«¯å¢é‡å‡çº§

#### 4.1.1 APIè°ƒç”¨å‡çº§

```javascript
// web_interface/js/api-client-v2.js
/**
 * V2 APIå®¢æˆ·ç«¯ï¼Œå‘åå…¼å®¹V1
 */
class QuantAnalyzerAPIClient {
    constructor(config = {}) {
        this.baseURL = config.baseURL || 'http://localhost:8001'; // ä½¿ç”¨æ¡¥æ¥å™¨
        this.apiVersion = config.apiVersion || 'v2';
        this.token = config.token || localStorage.getItem('auth_token');
        this.timeout = config.timeout || 30000;
        
        // è¯·æ±‚æ‹¦æˆªå™¨
        this.requestInterceptors = [];
        this.responseInterceptors = [];
    }
    
    setAuthToken(token) {
        this.token = token;
        localStorage.setItem('auth_token', token);
    }
    
    async request(method, endpoint, data = null, options = {}) {
        const url = `${this.baseURL}/api/${this.apiVersion}${endpoint}`;
        
        const config = {
            method,
            headers: {
                'Content-Type': 'application/json',
                'X-Request-ID': this.generateRequestId(),
                ...options.headers
            },
            timeout: options.timeout || this.timeout
        };
        
        // æ·»åŠ è®¤è¯å¤´
        if (this.token) {
            config.headers.Authorization = `Bearer ${this.token}`;
        }
        
        // æ·»åŠ è¯·æ±‚ä½“
        if (data) {
            config.body = JSON.stringify(data);
        }
        
        try {
            // åº”ç”¨è¯·æ±‚æ‹¦æˆªå™¨
            for (const interceptor of this.requestInterceptors) {
                await interceptor(config);
            }
            
            const response = await fetch(url, config);
            const responseData = await response.json();
            
            // åº”ç”¨å“åº”æ‹¦æˆªå™¨
            for (const interceptor of this.responseInterceptors) {
                await interceptor(responseData);
            }
            
            if (!response.ok) {
                throw new APIError(responseData.error || 'Request failed', response.status);
            }
            
            return responseData;
            
        } catch (error) {
            console.error('API Request failed:', error);
            
            // å¦‚æœV2å¤±è´¥ï¼Œå°è¯•V1å…¼å®¹æ¨¡å¼
            if (this.apiVersion === 'v2' && options.fallbackToV1 !== false) {
                console.log('å°è¯•V1å…¼å®¹æ¨¡å¼...');
                return this.requestV1Fallback(method, endpoint, data, options);
            }
            
            throw error;
        }
    }
    
    async requestV1Fallback(method, endpoint, data, options) {
        // V1å…¼å®¹è¯·æ±‚
        const v1Endpoint = this.convertToV1Endpoint(endpoint);
        const v1Data = this.convertToV1Format(endpoint, data);
        
        const url = `${this.baseURL}/api/v1${v1Endpoint}`;
        
        const config = {
            method,
            headers: {
                'Content-Type': 'application/json'
            }
        };
        
        if (v1Data) {
            config.body = JSON.stringify(v1Data);
        }
        
        const response = await fetch(url, config);
        const responseData = await response.json();
        
        // è½¬æ¢V1å“åº”ä¸ºV2æ ¼å¼
        return this.convertFromV1Format(endpoint, responseData);
    }
    
    convertToV1Endpoint(v2Endpoint) {
        const mapping = {
            '/factors/library': '/factors/library',
            '/factors/calculate': '/factors/generate', // V1æ²¡æœ‰æ‰¹é‡è®¡ç®—ï¼Œä½¿ç”¨ç”Ÿæˆ
            '/data/overview': '/data/overview',
            '/backtest/results': '/backtest/results'
        };
        
        return mapping[v2Endpoint] || v2Endpoint;
    }
    
    convertToV1Format(endpoint, data) {
        // V2åˆ°V1æ•°æ®æ ¼å¼è½¬æ¢
        if (endpoint === '/factors/calculate' && data) {
            // V2çš„æ‰¹é‡è®¡ç®—è¯·æ±‚è½¬æ¢ä¸ºV1æ ¼å¼
            return {
                count: data.factors?.length || 1,
                category: data.factors?.[0]?.category || 'technical'
            };
        }
        
        return data;
    }
    
    convertFromV1Format(endpoint, v1Data) {
        // V1åˆ°V2å“åº”æ ¼å¼è½¬æ¢
        if (!v1Data.success) {
            v1Data.success = true; // V1é»˜è®¤æˆåŠŸ
        }
        
        if (!v1Data.timestamp) {
            v1Data.timestamp = new Date().toISOString();
        }
        
        return v1Data;
    }
    
    generateRequestId() {
        return 'req_' + Math.random().toString(36).substr(2, 9);
    }
    
    // ä¾¿æ·æ–¹æ³•
    async get(endpoint, options = {}) {
        return this.request('GET', endpoint, null, options);
    }
    
    async post(endpoint, data, options = {}) {
        return this.request('POST', endpoint, data, options);
    }
    
    async put(endpoint, data, options = {}) {
        return this.request('PUT', endpoint, data, options);
    }
    
    async delete(endpoint, options = {}) {
        return this.request('DELETE', endpoint, null, options);
    }
    
    // ä¸“ç”¨APIæ–¹æ³•
    async getFactorLibrary(params = {}) {
        const queryString = new URLSearchParams(params).toString();
        const endpoint = `/factors/library${queryString ? '?' + queryString : ''}`;
        return this.get(endpoint);
    }
    
    async calculateFactors(request) {
        return this.post('/factors/calculate', request);
    }
    
    async createBacktest(backtestConfig) {
        return this.post('/backtest/create', backtestConfig);
    }
    
    async getBacktestStatus(jobId) {
        return this.get(`/backtest/status/${jobId}`);
    }
    
    async getBacktestResults(jobId) {
        return this.get(`/backtest/results/${jobId}`);
    }
    
    async getMarketData(params) {
        const queryString = new URLSearchParams(params).toString();
        return this.get(`/data/market?${queryString}`);
    }
}

class APIError extends Error {
    constructor(message, status, details = null) {
        super(message);
        this.name = 'APIError';
        this.status = status;
        this.details = details;
    }
}

// å…¨å±€APIå®¢æˆ·ç«¯å®ä¾‹
window.quantAPI = new QuantAnalyzerAPIClient();

// æ·»åŠ å…¨å±€é”™è¯¯å¤„ç†
window.quantAPI.responseInterceptors.push(async (response) => {
    if (!response.success && response.error) {
        // æ˜¾ç¤ºé”™è¯¯é€šçŸ¥
        showNotification(response.error, 'error');
        
        // è®°å½•é”™è¯¯
        console.error('API Error:', response);
    }
});

// è‡ªåŠ¨åˆ·æ–°token
window.quantAPI.responseInterceptors.push(async (response) => {
    if (response.status === 401) {
        // Tokenè¿‡æœŸï¼Œå°è¯•åˆ·æ–°
        const refreshToken = localStorage.getItem('refresh_token');
        if (refreshToken) {
            try {
                const auth = await window.quantAPI.post('/auth/refresh', {
                    refresh_token: refreshToken
                });
                
                window.quantAPI.setAuthToken(auth.data.access_token);
                localStorage.setItem('refresh_token', auth.data.refresh_token);
                
            } catch (error) {
                // åˆ·æ–°å¤±è´¥ï¼Œé‡å®šå‘åˆ°ç™»å½•é¡µ
                window.location.href = '/login';
            }
        }
    }
});
```

#### 4.1.2 å®æ—¶æ•°æ®WebSocketå®¢æˆ·ç«¯

```javascript
// web_interface/js/websocket-client.js
/**
 * WebSocketå®æ—¶æ•°æ®å®¢æˆ·ç«¯
 */
class RealtimeDataClient {
    constructor(wsUrl = 'ws://localhost:8001/ws') {
        this.wsUrl = wsUrl;
        this.ws = null;
        this.subscriptions = new Map();
        this.reconnectAttempts = 0;
        this.maxReconnectAttempts = 5;
        this.reconnectDelay = 1000;
        this.isConnected = false;
        this.messageQueue = [];
        
        // äº‹ä»¶å¤„ç†å™¨
        this.onConnect = null;
        this.onDisconnect = null;
        this.onError = null;
        
        this.connect();
    }
    
    connect() {
        try {
            this.ws = new WebSocket(this.wsUrl);
            
            this.ws.onopen = (event) => {
                console.log('âœ… WebSocketè¿æ¥æˆåŠŸ');
                this.isConnected = true;
                this.reconnectAttempts = 0;
                
                // è®¤è¯
                this.authenticate();
                
                // é‡æ–°è®¢é˜…
                this.resubscribe();
                
                // å‘é€é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯
                this.flushMessageQueue();
                
                if (this.onConnect) {
                    this.onConnect(event);
                }
            };
            
            this.ws.onmessage = (event) => {
                try {
                    const message = JSON.parse(event.data);
                    this.handleMessage(message);
                } catch (error) {
                    console.error('WebSocketæ¶ˆæ¯è§£æå¤±è´¥:', error);
                }
            };
            
            this.ws.onclose = (event) => {
                console.log('ğŸ”Œ WebSocketè¿æ¥å…³é—­');
                this.isConnected = false;
                
                if (this.onDisconnect) {
                    this.onDisconnect(event);
                }
                
                // è‡ªåŠ¨é‡è¿
                this.scheduleReconnect();
            };
            
            this.ws.onerror = (event) => {
                console.error('âŒ WebSocketé”™è¯¯:', event);
                
                if (this.onError) {
                    this.onError(event);
                }
            };
            
        } catch (error) {
            console.error('WebSocketè¿æ¥å¤±è´¥:', error);
            this.scheduleReconnect();
        }
    }
    
    authenticate() {
        const token = localStorage.getItem('auth_token');
        if (token) {
            this.send({
                type: 'auth',
                token: `Bearer ${token}`
            });
        }
    }
    
    send(message) {
        if (this.isConnected) {
            this.ws.send(JSON.stringify(message));
        } else {
            // è¿æ¥æ–­å¼€æ—¶åŠ å…¥é˜Ÿåˆ—
            this.messageQueue.push(message);
        }
    }
    
    flushMessageQueue() {
        while (this.messageQueue.length > 0) {
            const message = this.messageQueue.shift();
            this.ws.send(JSON.stringify(message));
        }
    }
    
    scheduleReconnect() {
        if (this.reconnectAttempts < this.maxReconnectAttempts) {
            setTimeout(() => {
                console.log(`ğŸ”„ å°è¯•é‡è¿... (${this.reconnectAttempts + 1}/${this.maxReconnectAttempts})`);
                this.reconnectAttempts++;
                this.connect();
            }, this.reconnectDelay * Math.pow(2, this.reconnectAttempts));
        } else {
            console.error('âŒ WebSocketé‡è¿å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•°');
            showNotification('å®æ—¶è¿æ¥å¤±è´¥ï¼Œè¯·åˆ·æ–°é¡µé¢é‡è¯•', 'error');
        }
    }
    
    resubscribe() {
        // é‡æ–°è®¢é˜…æ‰€æœ‰é¢‘é“
        for (const [channel, config] of this.subscriptions) {
            this.send({
                type: 'subscribe',
                channel: channel,
                params: config.params
            });
        }
    }
    
    handleMessage(message) {
        switch (message.type) {
            case 'auth_success':
                console.log('âœ… WebSocketè®¤è¯æˆåŠŸ');
                break;
                
            case 'auth_failed':
                console.error('âŒ WebSocketè®¤è¯å¤±è´¥');
                showNotification('å®æ—¶è¿æ¥è®¤è¯å¤±è´¥', 'error');
                break;
                
            case 'factor_update':
                this.handleFactorUpdate(message);
                break;
                
            case 'backtest_update':
                this.handleBacktestUpdate(message);
                break;
                
            case 'market_data_update':
                this.handleMarketDataUpdate(message);
                break;
                
            case 'error':
                console.error('WebSocketæœåŠ¡ç«¯é”™è¯¯:', message.error);
                showNotification(`å®æ—¶æ•°æ®é”™è¯¯: ${message.error}`, 'error');
                break;
                
            default:
                console.log('æœªçŸ¥WebSocketæ¶ˆæ¯ç±»å‹:', message.type);
        }
    }
    
    handleFactorUpdate(message) {
        const config = this.subscriptions.get('factors');
        if (config && config.callback) {
            config.callback(message.data);
        }
        
        // æ›´æ–°UI
        this.updateFactorUI(message.data);
    }
    
    handleBacktestUpdate(message) {
        const config = this.subscriptions.get('backtest');
        if (config && config.callback) {
            config.callback(message.data);
        }
        
        // æ›´æ–°å›æµ‹è¿›åº¦UI
        this.updateBacktestUI(message.data);
    }
    
    handleMarketDataUpdate(message) {
        const config = this.subscriptions.get('market_data');
        if (config && config.callback) {
            config.callback(message.data);
        }
        
        // æ›´æ–°å¸‚åœºæ•°æ®UI
        this.updateMarketDataUI(message.data);
    }
    
    subscribe(channel, params, callback) {
        this.subscriptions.set(channel, {
            params,
            callback
        });
        
        if (this.isConnected) {
            this.send({
                type: 'subscribe',
                channel,
                params
            });
        }
    }
    
    unsubscribe(channel) {
        this.subscriptions.delete(channel);
        
        if (this.isConnected) {
            this.send({
                type: 'unsubscribe',
                channel
            });
        }
    }
    
    // UIæ›´æ–°æ–¹æ³•
    updateFactorUI(factorData) {
        const factorId = factorData.factor_id;
        const factorElement = document.querySelector(`[data-factor-id="${factorId}"]`);
        
        if (factorElement) {
            // æ›´æ–°å› å­å€¼æ˜¾ç¤º
            const valueElement = factorElement.querySelector('.factor-value');
            if (valueElement) {
                valueElement.textContent = factorData.values;
                
                // æ·»åŠ æ›´æ–°åŠ¨ç”»
                valueElement.classList.add('updated');
                setTimeout(() => {
                    valueElement.classList.remove('updated');
                }, 1000);
            }
            
            // æ›´æ–°æ—¶é—´æˆ³
            const timestampElement = factorElement.querySelector('.factor-timestamp');
            if (timestampElement) {
                timestampElement.textContent = new Date(factorData.timestamp).toLocaleTimeString();
            }
        }
    }
    
    updateBacktestUI(backtestData) {
        const jobId = backtestData.job_id;
        const backtestElement = document.querySelector(`[data-backtest-id="${jobId}"]`);
        
        if (backtestElement) {
            // æ›´æ–°è¿›åº¦æ¡
            const progressBar = backtestElement.querySelector('.progress-bar');
            if (progressBar) {
                progressBar.style.width = `${backtestData.progress}%`;
                progressBar.textContent = `${backtestData.progress}%`;
            }
            
            // æ›´æ–°çŠ¶æ€
            const statusElement = backtestElement.querySelector('.backtest-status');
            if (statusElement) {
                statusElement.textContent = backtestData.current_stage || backtestData.status;
                statusElement.className = `backtest-status status-${backtestData.status}`;
            }
            
            // æ›´æ–°ä¸­é—´ç»“æœ
            if (backtestData.intermediate_results) {
                const resultsElement = backtestElement.querySelector('.intermediate-results');
                if (resultsElement) {
                    resultsElement.innerHTML = `
                        <div class="metric">
                            <span class="label">å½“å‰æ”¶ç›Š:</span>
                            <span class="value">${(backtestData.intermediate_results.current_return * 100).toFixed(2)}%</span>
                        </div>
                        <div class="metric">
                            <span class="label">å½“å‰å›æ’¤:</span>
                            <span class="value">${(backtestData.intermediate_results.current_drawdown * 100).toFixed(2)}%</span>
                        </div>
                        <div class="metric">
                            <span class="label">å·²å®Œæˆäº¤æ˜“:</span>
                            <span class="value">${backtestData.intermediate_results.completed_trades}</span>
                        </div>
                    `;
                }
            }
        }
    }
    
    updateMarketDataUI(marketData) {
        // æ›´æ–°å®æ—¶ä»·æ ¼
        for (const [symbol, data] of Object.entries(marketData)) {
            const priceElement = document.querySelector(`[data-symbol="${symbol}"] .current-price`);
            if (priceElement) {
                priceElement.textContent = data.price.toFixed(2);
                
                // æ ¹æ®æ¶¨è·Œè®¾ç½®é¢œè‰²
                const changeElement = document.querySelector(`[data-symbol="${symbol}"] .price-change`);
                if (changeElement) {
                    const change = data.change || 0;
                    changeElement.textContent = `${change > 0 ? '+' : ''}${change.toFixed(2)} (${(change/data.price*100).toFixed(2)}%)`;
                    changeElement.className = `price-change ${change >= 0 ? 'positive' : 'negative'}`;
                }
            }
        }
    }
    
    disconnect() {
        if (this.ws) {
            this.ws.close();
            this.ws = null;
        }
        this.isConnected = false;
        this.subscriptions.clear();
    }
}

// å…¨å±€å®æ—¶æ•°æ®å®¢æˆ·ç«¯
window.realtimeClient = new RealtimeDataClient();

// é¡µé¢å¸è½½æ—¶æ¸…ç†è¿æ¥
window.addEventListener('beforeunload', () => {
    if (window.realtimeClient) {
        window.realtimeClient.disconnect();
    }
});
```

### 4.2 å¢å¼ºåŠŸèƒ½é›†æˆ

#### 4.2.1 å¢å¼ºçš„å› å­ç ”ç©¶ç•Œé¢

```javascript
// web_interface/js/enhanced-factor-research.js
/**
 * å¢å¼ºçš„å› å­ç ”ç©¶åŠŸèƒ½
 */
class EnhancedFactorResearch {
    constructor() {
        this.factorChart = null;
        this.performanceChart = null;
        this.currentFactors = [];
        this.realTimeMode = false;
        
        this.initializeUI();
        this.bindEvents();
    }
    
    initializeUI() {
        // åˆ›å»ºå¢å¼ºçš„å› å­ç ”ç©¶ç•Œé¢
        const factorResearchSection = document.getElementById('factor-research');
        
        if (factorResearchSection) {
            factorResearchSection.innerHTML = `
                <div class="enhanced-factor-research">
                    <div class="research-controls">
                        <div class="factor-selection">
                            <h3>å› å­é€‰æ‹©</h3>
                            <select id="factor-category" multiple>
                                <option value="technical">æŠ€æœ¯æŒ‡æ ‡</option>
                                <option value="statistical">ç»Ÿè®¡å› å­</option>
                                <option value="sentiment">æƒ…ç»ªå› å­</option>
                                <option value="fundamental">åŸºæœ¬é¢å› å­</option>
                            </select>
                        </div>
                        
                        <div class="symbol-selection">
                            <h3>æ ‡çš„é€‰æ‹©</h3>
                            <input type="text" id="symbol-input" placeholder="è¾“å…¥è‚¡ç¥¨ä»£ç ï¼Œç”¨é€—å·åˆ†éš”">
                            <div class="popular-symbols">
                                <span class="symbol-tag" data-symbol="BTCUSDT">BTC</span>
                                <span class="symbol-tag" data-symbol="ETHUSDT">ETH</span>
                                <span class="symbol-tag" data-symbol="BNBUSDT">BNB</span>
                            </div>
                        </div>
                        
                        <div class="time-range">
                            <h3>æ—¶é—´èŒƒå›´</h3>
                            <input type="date" id="start-date">
                            <input type="date" id="end-date">
                        </div>
                        
                        <div class="research-actions">
                            <button id="calculate-factors" class="btn btn-primary">
                                <i class="fas fa-calculator"></i>
                                è®¡ç®—å› å­
                            </button>
                            <button id="realtime-mode" class="btn btn-secondary">
                                <i class="fas fa-broadcast-tower"></i>
                                å®æ—¶æ¨¡å¼
                            </button>
                            <button id="export-results" class="btn btn-success">
                                <i class="fas fa-download"></i>
                                å¯¼å‡ºç»“æœ
                            </button>
                        </div>
                    </div>
                    
                    <div class="research-results">
                        <div class="results-tabs">
                            <button class="tab-btn active" data-tab="factor-values">å› å­å€¼</button>
                            <button class="tab-btn" data-tab="performance">æ€§èƒ½åˆ†æ</button>
                            <button class="tab-btn" data-tab="correlation">ç›¸å…³æ€§åˆ†æ</button>
                            <button class="tab-btn" data-tab="distribution">åˆ†å¸ƒåˆ†æ</button>
                        </div>
                        
                        <div class="tab-content">
                            <div id="factor-values" class="tab-pane active">
                                <div class="factor-chart-container">
                                    <canvas id="factor-chart"></canvas>
                                </div>
                                <div class="factor-table-container">
                                    <table id="factor-table" class="data-table">
                                        <thead>
                                            <tr>
                                                <th>æ—¥æœŸ</th>
                                                <th>æ ‡çš„</th>
                                                <th>å› å­å€¼</th>
                                                <th>æ’å</th>
                                                <th>åˆ†ä½æ•°</th>
                                            </tr>
                                        </thead>
                                        <tbody></tbody>
                                    </table>
                                </div>
                            </div>
                            
                            <div id="performance" class="tab-pane">
                                <div class="performance-metrics">
                                    <div class="metric-card">
                                        <h4>ä¿¡æ¯ç³»æ•° (IC)</h4>
                                        <div class="metric-value" id="ic-value">--</div>
                                        <div class="metric-change" id="ic-change">--</div>
                                    </div>
                                    <div class="metric-card">
                                        <h4>ä¿¡æ¯æ¯”ç‡ (IR)</h4>
                                        <div class="metric-value" id="ir-value">--</div>
                                        <div class="metric-change" id="ir-change">--</div>
                                    </div>
                                    <div class="metric-card">
                                        <h4>èƒœç‡</h4>
                                        <div class="metric-value" id="win-rate-value">--</div>
                                        <div class="metric-change" id="win-rate-change">--</div>
                                    </div>
                                    <div class="metric-card">
                                        <h4>å¤æ™®æ¯”ç‡</h4>
                                        <div class="metric-value" id="sharpe-value">--</div>
                                        <div class="metric-change" id="sharpe-change">--</div>
                                    </div>
                                </div>
                                <div class="performance-chart-container">
                                    <canvas id="performance-chart"></canvas>
                                </div>
                            </div>
                            
                            <div id="correlation" class="tab-pane">
                                <div class="correlation-matrix" id="correlation-matrix"></div>
                            </div>
                            
                            <div id="distribution" class="tab-pane">
                                <div class="distribution-chart-container">
                                    <canvas id="distribution-chart"></canvas>
                                </div>
                            </div>
                        </div>
                    </div>
                    
                    <div class="realtime-panel" style="display: none;">
                        <h3>å®æ—¶å› å­ç›‘æ§</h3>
                        <div class="realtime-factors" id="realtime-factors"></div>
                    </div>
                </div>
            `;
        }
    }
    
    bindEvents() {
        // è®¡ç®—å› å­æŒ‰é’®
        const calculateBtn = document.getElementById('calculate-factors');
        if (calculateBtn) {
            calculateBtn.addEventListener('click', () => this.calculateFactors());
        }
        
        // å®æ—¶æ¨¡å¼åˆ‡æ¢
        const realtimeBtn = document.getElementById('realtime-mode');
        if (realtimeBtn) {
            realtimeBtn.addEventListener('click', () => this.toggleRealtimeMode());
        }
        
        // å¯¼å‡ºç»“æœ
        const exportBtn = document.getElementById('export-results');
        if (exportBtn) {
            exportBtn.addEventListener('click', () => this.exportResults());
        }
        
        // æ ‡çš„é€‰æ‹©æ ‡ç­¾
        document.querySelectorAll('.symbol-tag').forEach(tag => {
            tag.addEventListener('click', (e) => {
                const symbol = e.target.dataset.symbol;
                const symbolInput = document.getElementById('symbol-input');
                const currentSymbols = symbolInput.value.split(',').map(s => s.trim()).filter(s => s);
                
                if (!currentSymbols.includes(symbol)) {
                    currentSymbols.push(symbol);
                    symbolInput.value = currentSymbols.join(', ');
                }
            });
        });
        
        // æ ‡ç­¾é¡µåˆ‡æ¢
        document.querySelectorAll('.tab-btn').forEach(btn => {
            btn.addEventListener('click', (e) => {
                const tabName = e.target.dataset.tab;
                this.switchTab(tabName);
            });
        });
        
        // è‡ªåŠ¨è®¾ç½®é»˜è®¤æ—¥æœŸèŒƒå›´
        this.setDefaultDateRange();
    }
    
    setDefaultDateRange() {
        const endDate = new Date();
        const startDate = new Date();
        startDate.setMonth(startDate.getMonth() - 3); // é»˜è®¤3ä¸ªæœˆ
        
        const startInput = document.getElementById('start-date');
        const endInput = document.getElementById('end-date');
        
        if (startInput) startInput.value = startDate.toISOString().split('T')[0];
        if (endInput) endInput.value = endDate.toISOString().split('T')[0];
    }
    
    async calculateFactors() {
        const calculateBtn = document.getElementById('calculate-factors');
        const originalText = calculateBtn.textContent;
        
        try {
            // æ˜¾ç¤ºåŠ è½½çŠ¶æ€
            calculateBtn.disabled = true;
            calculateBtn.innerHTML = '<i class="fas fa-spinner fa-spin"></i> è®¡ç®—ä¸­...';
            
            // è·å–å‚æ•°
            const params = this.getCalculationParams();
            
            if (!params.factors.length) {
                throw new Error('è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå› å­ç±»åˆ«');
            }
            
            if (!params.symbols.length) {
                throw new Error('è¯·è¾“å…¥è‚¡ç¥¨ä»£ç ');
            }
            
            // è·å–å› å­å®šä¹‰
            const factorLibrary = await window.quantAPI.getFactorLibrary({
                category: params.categories.join(','),
                limit: 20
            });
            
            if (!factorLibrary.success || !factorLibrary.data.factors.length) {
                throw new Error('æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„å› å­');
            }
            
            // å‡†å¤‡è®¡ç®—è¯·æ±‚
            const calculateRequest = {
                factors: factorLibrary.data.factors.slice(0, 5), // é™åˆ¶å‰5ä¸ªå› å­
                symbols: params.symbols,
                start_date: params.startDate,
                end_date: params.endDate,
                frequency: 'daily'
            };
            
            // è°ƒç”¨è®¡ç®—API
            const results = await window.quantAPI.calculateFactors(calculateRequest);
            
            if (results.success) {
                this.displayFactorResults(results.data);
                showNotification('å› å­è®¡ç®—å®Œæˆ', 'success');
            } else {
                throw new Error(results.error || 'å› å­è®¡ç®—å¤±è´¥');
            }
            
        } catch (error) {
            console.error('å› å­è®¡ç®—å¤±è´¥:', error);
            showNotification(error.message, 'error');
        } finally {
            // æ¢å¤æŒ‰é’®çŠ¶æ€
            calculateBtn.disabled = false;
            calculateBtn.innerHTML = originalText;
        }
    }
    
    getCalculationParams() {
        const categorySelect = document.getElementById('factor-category');
        const symbolInput = document.getElementById('symbol-input');
        const startDateInput = document.getElementById('start-date');
        const endDateInput = document.getElementById('end-date');
        
        const categories = Array.from(categorySelect.selectedOptions).map(opt => opt.value);
        const symbols = symbolInput.value.split(',').map(s => s.trim()).filter(s => s);
        
        return {
            categories,
            symbols,
            startDate: startDateInput.value,
            endDate: endDateInput.value,
            factors: categories // ç®€åŒ–å¤„ç†
        };
    }
    
    displayFactorResults(results) {
        this.currentFactors = results.results || {};
        
        // æ›´æ–°å› å­å€¼å›¾è¡¨
        this.updateFactorChart();
        
        // æ›´æ–°å› å­è¡¨æ ¼
        this.updateFactorTable();
        
        // è®¡ç®—å’Œæ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
        this.calculatePerformanceMetrics();
    }
    
    updateFactorChart() {
        const canvas = document.getElementById('factor-chart');
        const ctx = canvas.getContext('2d');
        
        // é”€æ¯æ—§å›¾è¡¨
        if (this.factorChart) {
            this.factorChart.destroy();
        }
        
        // å‡†å¤‡å›¾è¡¨æ•°æ®
        const datasets = [];
        const colors = ['#667eea', '#764ba2', '#f093fb', '#f5576c', '#4facfe'];
        let colorIndex = 0;
        
        for (const [factorName, factorResult] of Object.entries(this.currentFactors)) {
            datasets.push({
                label: factorName,
                data: factorResult.values,
                borderColor: colors[colorIndex % colors.length],
                backgroundColor: colors[colorIndex % colors.length] + '20',
                fill: false,
                tension: 0.1
            });
            colorIndex++;
        }
        
        // åˆ›å»ºæ–°å›¾è¡¨
        this.factorChart = new Chart(ctx, {
            type: 'line',
            data: {
                labels: Object.values(this.currentFactors)[0]?.timestamps || [],
                datasets
            },
            options: {
                responsive: true,
                plugins: {
                    title: {
                        display: true,
                        text: 'å› å­å€¼æ—¶åºå›¾'
                    },
                    legend: {
                        display: true,
                        position: 'top'
                    }
                },
                scales: {
                    x: {
                        title: {
                            display: true,
                            text: 'æ—¶é—´'
                        }
                    },
                    y: {
                        title: {
                            display: true,
                            text: 'å› å­å€¼'
                        }
                    }
                }
            }
        });
    }
    
    updateFactorTable() {
        const tableBody = document.querySelector('#factor-table tbody');
        
        if (!tableBody) return;
        
        tableBody.innerHTML = '';
        
        // æ„å»ºè¡¨æ ¼æ•°æ®
        for (const [factorName, factorResult] of Object.entries(this.currentFactors)) {
            const timestamps = factorResult.timestamps || [];
            const values = factorResult.values || [];
            const symbols = factorResult.symbols || [];
            
            for (let i = 0; i < timestamps.length; i++) {
                const row = document.createElement('tr');
                row.innerHTML = `
                    <td>${new Date(timestamps[i]).toLocaleDateString()}</td>
                    <td>${symbols[i % symbols.length]}</td>
                    <td>${values[i]?.toFixed(4) || '--'}</td>
                    <td>${Math.floor(Math.random() * 100) + 1}</td>
                    <td>${Math.floor(values[i] * 100) || '--'}</td>
                `;
                tableBody.appendChild(row);
            }
        }
    }
    
    calculatePerformanceMetrics() {
        // æ¨¡æ‹Ÿæ€§èƒ½æŒ‡æ ‡è®¡ç®—ï¼ˆå®é™…åº”ç”¨ä¸­ä»APIè·å–ï¼‰
        const metrics = {
            ic: (Math.random() * 0.3 - 0.15).toFixed(3),
            ir: (Math.random() * 2).toFixed(2),
            winRate: (0.5 + Math.random() * 0.2).toFixed(3),
            sharpe: (Math.random() * 3).toFixed(2)
        };
        
        // æ›´æ–°æ€§èƒ½æŒ‡æ ‡æ˜¾ç¤º
        const icValue = document.getElementById('ic-value');
        const irValue = document.getElementById('ir-value');
        const winRateValue = document.getElementById('win-rate-value');
        const sharpeValue = document.getElementById('sharpe-value');
        
        if (icValue) icValue.textContent = metrics.ic;
        if (irValue) irValue.textContent = metrics.ir;
        if (winRateValue) winRateValue.textContent = (metrics.winRate * 100).toFixed(1) + '%';
        if (sharpeValue) sharpeValue.textContent = metrics.sharpe;
    }
    
    toggleRealtimeMode() {
        this.realTimeMode = !this.realTimeMode;
        const realtimeBtn = document.getElementById('realtime-mode');
        const realtimePanel = document.querySelector('.realtime-panel');
        
        if (this.realTimeMode) {
            realtimeBtn.innerHTML = '<i class="fas fa-stop"></i> åœæ­¢å®æ—¶';
            realtimeBtn.classList.add('active');
            realtimePanel.style.display = 'block';
            
            // è®¢é˜…å®æ—¶å› å­æ•°æ®
            this.subscribeToRealtime();
            
        } else {
            realtimeBtn.innerHTML = '<i class="fas fa-broadcast-tower"></i> å®æ—¶æ¨¡å¼';
            realtimeBtn.classList.remove('active');
            realtimePanel.style.display = 'none';
            
            // å–æ¶ˆè®¢é˜…
            this.unsubscribeFromRealtime();
        }
    }
    
    subscribeToRealtime() {
        if (!window.realtimeClient) return;
        
        const params = this.getCalculationParams();
        
        window.realtimeClient.subscribe('factors', {
            factor_ids: Object.keys(this.currentFactors),
            symbols: params.symbols,
            update_interval: 60
        }, (data) => {
            this.handleRealtimeFactorUpdate(data);
        });
    }
    
    unsubscribeFromRealtime() {
        if (window.realtimeClient) {
            window.realtimeClient.unsubscribe('factors');
        }
    }
    
    handleRealtimeFactorUpdate(data) {
        const realtimeContainer = document.getElementById('realtime-factors');
        
        if (realtimeContainer) {
            // æ›´æ–°å®æ—¶å› å­æ˜¾ç¤º
            realtimeContainer.innerHTML = `
                <div class="realtime-factor">
                    <h4>${data.factor_name}</h4>
                    <div class="realtime-values">
                        ${Object.entries(data.values).map(([symbol, valueData]) => `
                            <div class="symbol-value">
                                <span class="symbol">${symbol}</span>
                                <span class="value ${valueData.change >= 0 ? 'positive' : 'negative'}">
                                    ${valueData.value.toFixed(4)}
                                </span>
                                <span class="change">
                                    ${valueData.change >= 0 ? '+' : ''}${valueData.change.toFixed(4)}
                                </span>
                            </div>
                        `).join('')}
                    </div>
                    <div class="update-time">
                        æ›´æ–°æ—¶é—´: ${new Date(data.timestamp).toLocaleTimeString()}
                    </div>
                </div>
            `;
        }
    }
    
    switchTab(tabName) {
        // åˆ‡æ¢æ ‡ç­¾é¡µ
        document.querySelectorAll('.tab-btn').forEach(btn => {
            btn.classList.remove('active');
        });
        
        document.querySelectorAll('.tab-pane').forEach(pane => {
            pane.classList.remove('active');
        });
        
        const activeBtn = document.querySelector(`[data-tab="${tabName}"]`);
        const activePane = document.getElementById(tabName);
        
        if (activeBtn) activeBtn.classList.add('active');
        if (activePane) activePane.classList.add('active');
        
        // æ ¹æ®ä¸åŒæ ‡ç­¾é¡µåŠ è½½å†…å®¹
        switch (tabName) {
            case 'performance':
                this.loadPerformanceAnalysis();
                break;
            case 'correlation':
                this.loadCorrelationAnalysis();
                break;
            case 'distribution':
                this.loadDistributionAnalysis();
                break;
        }
    }
    
    loadPerformanceAnalysis() {
        // åˆ›å»ºæ€§èƒ½å›¾è¡¨
        const canvas = document.getElementById('performance-chart');
        if (canvas && !this.performanceChart) {
            const ctx = canvas.getContext('2d');
            
            this.performanceChart = new Chart(ctx, {
                type: 'bar',
                data: {
                    labels: Object.keys(this.currentFactors),
                    datasets: [{
                        label: 'ICå€¼',
                        data: Object.keys(this.currentFactors).map(() => Math.random() * 0.3 - 0.15),
                        backgroundColor: '#667eea50',
                        borderColor: '#667eea',
                        borderWidth: 1
                    }]
                },
                options: {
                    responsive: true,
                    plugins: {
                        title: {
                            display: true,
                            text: 'å› å­æ€§èƒ½åˆ†æ'
                        }
                    }
                }
            });
        }
    }
    
    loadCorrelationAnalysis() {
        // ç”Ÿæˆç›¸å…³æ€§çŸ©é˜µ
        const correlationMatrix = document.getElementById('correlation-matrix');
        const factorNames = Object.keys(this.currentFactors);
        
        let html = '<table class="correlation-table"><thead><tr><th></th>';
        factorNames.forEach(name => {
            html += `<th>${name}</th>`;
        });
        html += '</tr></thead><tbody>';
        
        factorNames.forEach((name1, i) => {
            html += `<tr><th>${name1}</th>`;
            factorNames.forEach((name2, j) => {
                const correlation = i === j ? 1 : (Math.random() * 2 - 1);
                const colorIntensity = Math.abs(correlation);
                const color = correlation > 0 ? 'positive' : 'negative';
                html += `<td class="correlation-cell ${color}" style="opacity: ${colorIntensity}">
                    ${correlation.toFixed(3)}
                </td>`;
            });
            html += '</tr>';
        });
        
        html += '</tbody></table>';
        correlationMatrix.innerHTML = html;
    }
    
    loadDistributionAnalysis() {
        // åˆ›å»ºåˆ†å¸ƒå›¾è¡¨
        const canvas = document.getElementById('distribution-chart');
        if (canvas) {
            const ctx = canvas.getContext('2d');
            
            // æ¨¡æ‹Ÿåˆ†å¸ƒæ•°æ®
            const distributionData = Object.keys(this.currentFactors).map(factorName => {
                return {
                    label: factorName,
                    data: Array.from({length: 50}, () => Math.random() * 100),
                    backgroundColor: `rgba(${Math.random()*255}, ${Math.random()*255}, ${Math.random()*255}, 0.5)`
                };
            });
            
            new Chart(ctx, {
                type: 'scatter',
                data: {
                    datasets: distributionData
                },
                options: {
                    responsive: true,
                    plugins: {
                        title: {
                            display: true,
                            text: 'å› å­å€¼åˆ†å¸ƒå›¾'
                        }
                    }
                }
            });
        }
    }
    
    async exportResults() {
        try {
            // å‡†å¤‡å¯¼å‡ºæ•°æ®
            const exportData = {
                timestamp: new Date().toISOString(),
                factors: this.currentFactors,
                metadata: {
                    calculation_params: this.getCalculationParams(),
                    performance_metrics: {
                        // ä»UIè·å–å½“å‰æ˜¾ç¤ºçš„æ€§èƒ½æŒ‡æ ‡
                        ic: document.getElementById('ic-value')?.textContent || '--',
                        ir: document.getElementById('ir-value')?.textContent || '--',
                        win_rate: document.getElementById('win-rate-value')?.textContent || '--',
                        sharpe: document.getElementById('sharpe-value')?.textContent || '--'
                    }
                }
            };
            
            // åˆ›å»ºä¸‹è½½é“¾æ¥
            const dataStr = JSON.stringify(exportData, null, 2);
            const dataBlob = new Blob([dataStr], {type: 'application/json'});
            const url = URL.createObjectURL(dataBlob);
            
            const link = document.createElement('a');
            link.href = url;
            link.download = `factor_analysis_${new Date().toISOString().split('T')[0]}.json`;
            document.body.appendChild(link);
            link.click();
            document.body.removeChild(link);
            
            URL.revokeObjectURL(url);
            
            showNotification('ç»“æœå¯¼å‡ºæˆåŠŸ', 'success');
            
        } catch (error) {
            console.error('å¯¼å‡ºå¤±è´¥:', error);
            showNotification('å¯¼å‡ºå¤±è´¥', 'error');
        }
    }
}

// åˆå§‹åŒ–å¢å¼ºå› å­ç ”ç©¶åŠŸèƒ½
document.addEventListener('DOMContentLoaded', () => {
    window.enhancedFactorResearch = new EnhancedFactorResearch();
});
```

---

## 5. é£é™©æ§åˆ¶å’Œå›æ»šæœºåˆ¶

### 5.1 å¥åº·ç›‘æ§

```python
# monitoring/health_monitor.py
import asyncio
import logging
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional

class SystemHealthMonitor:
    """ç³»ç»Ÿå¥åº·ç›‘æ§å™¨"""
    
    def __init__(self):
        self.health_checks = {}
        self.alert_thresholds = {
            'api_response_time': 3.0,  # ç§’
            'error_rate': 0.05,        # 5%
            'memory_usage': 0.8,       # 80%
            'cpu_usage': 0.8,          # 80%
            'disk_usage': 0.9,         # 90%
        }
        
        self.monitoring_interval = 30  # ç§’
        self.is_monitoring = False
        
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
    
    async def start_monitoring(self):
        """å¼€å§‹å¥åº·ç›‘æ§"""
        self.is_monitoring = True
        self.logger.info("ğŸ” ç³»ç»Ÿå¥åº·ç›‘æ§å¯åŠ¨")
        
        while self.is_monitoring:
            try:
                health_report = await self.perform_health_checks()
                await self.process_health_report(health_report)
                
                await asyncio.sleep(self.monitoring_interval)
                
            except Exception as e:
                self.logger.error(f"å¥åº·ç›‘æ§å¼‚å¸¸: {e}")
                await asyncio.sleep(60)  # å¼‚å¸¸æ—¶å»¶é•¿é—´éš”
    
    async def perform_health_checks(self) -> Dict:
        """æ‰§è¡Œå¥åº·æ£€æŸ¥"""
        
        health_report = {
            'timestamp': datetime.now().isoformat(),
            'checks': {}
        }
        
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å¥åº·æ£€æŸ¥
        check_tasks = [
            self.check_api_services(),
            self.check_database_health(),
            self.check_rust_engine(),
            self.check_system_resources(),
            self.check_data_quality()
        ]
        
        check_results = await asyncio.gather(*check_tasks, return_exceptions=True)
        
        check_names = ['api_services', 'database', 'rust_engine', 'system_resources', 'data_quality']
        
        for name, result in zip(check_names, check_results):
            if isinstance(result, Exception):
                health_report['checks'][name] = {
                    'status': 'error',
                    'message': str(result),
                    'timestamp': datetime.now().isoformat()
                }
            else:
                health_report['checks'][name] = result
        
        return health_report
    
    async def check_api_services(self) -> Dict:
        """æ£€æŸ¥APIæœåŠ¡å¥åº·çŠ¶æ€"""
        services = {
            'v1_api': 'http://localhost:8003/api/v1/health',
            'v2_api': 'http://localhost:8000/health',
            'bridge': 'http://localhost:8001/bridge/health'
        }
        
        results = {}
        
        async with httpx.AsyncClient(timeout=5.0) as client:
            for service_name, url in services.items():
                try:
                    start_time = datetime.now()
                    response = await client.get(url)
                    response_time = (datetime.now() - start_time).total_seconds()
                    
                    results[service_name] = {
                        'status': 'healthy' if response.status_code == 200 else 'unhealthy',
                        'response_time': response_time,
                        'status_code': response.status_code,
                        'url': url
                    }
                    
                    # æ£€æŸ¥å“åº”æ—¶é—´é˜ˆå€¼
                    if response_time > self.alert_thresholds['api_response_time']:
                        results[service_name]['alert'] = f'å“åº”æ—¶é—´è¿‡é•¿: {response_time:.2f}s'
                    
                except Exception as e:
                    results[service_name] = {
                        'status': 'error',
                        'message': str(e),
                        'url': url
                    }
        
        return {
            'status': 'healthy' if all(r.get('status') == 'healthy' for r in results.values()) else 'unhealthy',
            'services': results
        }
    
    async def check_database_health(self) -> Dict:
        """æ£€æŸ¥æ•°æ®åº“å¥åº·çŠ¶æ€"""
        db_results = {}
        
        # PostgreSQLæ£€æŸ¥
        try:
            import asyncpg
            conn = await asyncpg.connect("postgresql://quantuser:quantpass@localhost:5432/quant_metadata")
            
            start_time = datetime.now()
            await conn.fetchval("SELECT 1")
            response_time = (datetime.now() - start_time).total_seconds()
            
            await conn.close()
            
            db_results['postgresql'] = {
                'status': 'healthy',
                'response_time': response_time
            }
            
        except Exception as e:
            db_results['postgresql'] = {
                'status': 'error',
                'message': str(e)
            }
        
        # Redisæ£€æŸ¥
        try:
            import aioredis
            redis = aioredis.from_url("redis://localhost:6379")
            
            start_time = datetime.now()
            await redis.ping()
            response_time = (datetime.now() - start_time).total_seconds()
            
            await redis.close()
            
            db_results['redis'] = {
                'status': 'healthy',
                'response_time': response_time
            }
            
        except Exception as e:
            db_results['redis'] = {
                'status': 'error',
                'message': str(e)
            }
        
        # ClickHouseæ£€æŸ¥
        try:
            import httpx
            async with httpx.AsyncClient() as client:
                start_time = datetime.now()
                response = await client.get("http://localhost:8123/ping")
                response_time = (datetime.now() - start_time).total_seconds()
                
                db_results['clickhouse'] = {
                    'status': 'healthy' if response.text.strip() == 'Ok.' else 'unhealthy',
                    'response_time': response_time
                }
                
        except Exception as e:
            db_results['clickhouse'] = {
                'status': 'error',
                'message': str(e)
            }
        
        return {
            'status': 'healthy' if all(r.get('status') == 'healthy' for r in db_results.values()) else 'unhealthy',
            'databases': db_results
        }
    
    async def check_rust_engine(self) -> Dict:
        """æ£€æŸ¥Rustå¼•æ“å¥åº·çŠ¶æ€"""
        try:
            # æ¨¡æ‹ŸRustå¼•æ“å¥åº·æ£€æŸ¥
            import sys
            sys.path.append('./rust_engine/target/release')
            import quant_engine
            
            start_time = datetime.now()
            health = quant_engine.health_check()
            response_time = (datetime.now() - start_time).total_seconds()
            
            return {
                'status': 'healthy' if health == "Rust engine is healthy" else 'unhealthy',
                'response_time': response_time,
                'message': health
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'message': str(e)
            }
    
    async def check_system_resources(self) -> Dict:
        """æ£€æŸ¥ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
        try:
            import psutil
            
            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=1)
            
            # å†…å­˜ä½¿ç”¨ç‡
            memory = psutil.virtual_memory()
            memory_percent = memory.percent / 100
            
            # ç£ç›˜ä½¿ç”¨ç‡
            disk = psutil.disk_usage('/')
            disk_percent = (disk.used / disk.total)
            
            resources = {
                'cpu': {
                    'usage_percent': cpu_percent,
                    'status': 'healthy' if cpu_percent / 100 < self.alert_thresholds['cpu_usage'] else 'warning'
                },
                'memory': {
                    'usage_percent': memory_percent * 100,
                    'available_gb': memory.available / (1024**3),
                    'status': 'healthy' if memory_percent < self.alert_thresholds['memory_usage'] else 'warning'
                },
                'disk': {
                    'usage_percent': disk_percent * 100,
                    'free_gb': disk.free / (1024**3),
                    'status': 'healthy' if disk_percent < self.alert_thresholds['disk_usage'] else 'warning'
                }
            }
            
            overall_status = 'healthy'
            for resource in resources.values():
                if resource['status'] == 'warning':
                    overall_status = 'warning'
                    break
            
            return {
                'status': overall_status,
                'resources': resources
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'message': str(e)
            }
    
    async def check_data_quality(self) -> Dict:
        """æ£€æŸ¥æ•°æ®è´¨é‡"""
        try:
            # ç®€åŒ–çš„æ•°æ®è´¨é‡æ£€æŸ¥
            quality_metrics = {
                'completeness': 0.98 + (random.random() * 0.02),
                'accuracy': 0.995 + (random.random() * 0.005),
                'timeliness': 0.96 + (random.random() * 0.04)
            }
            
            overall_score = sum(quality_metrics.values()) / len(quality_metrics)
            
            return {
                'status': 'healthy' if overall_score > 0.95 else 'warning',
                'overall_score': overall_score,
                'metrics': quality_metrics
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'message': str(e)
            }
    
    async def process_health_report(self, health_report: Dict):
        """å¤„ç†å¥åº·æ£€æŸ¥æŠ¥å‘Š"""
        
        # è®°å½•å¥åº·çŠ¶æ€
        self.logger.info(f"å¥åº·æ£€æŸ¥å®Œæˆ: {health_report['timestamp']}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è­¦å‘Šæˆ–é”™è¯¯
        alerts = []
        
        for check_name, check_result in health_report['checks'].items():
            status = check_result.get('status', 'unknown')
            
            if status in ['warning', 'error', 'unhealthy']:
                alerts.append({
                    'check': check_name,
                    'status': status,
                    'message': check_result.get('message', ''),
                    'timestamp': check_result.get('timestamp', health_report['timestamp'])
                })
        
        # å‘é€å‘Šè­¦
        if alerts:
            await self.send_alerts(alerts)
        
        # ä¿å­˜å¥åº·æŠ¥å‘Š
        await self.save_health_report(health_report)
    
    async def send_alerts(self, alerts: List[Dict]):
        """å‘é€å‘Šè­¦é€šçŸ¥"""
        for alert in alerts:
            self.logger.warning(f"ğŸš¨ å¥åº·å‘Šè­¦: {alert['check']} - {alert['status']} - {alert['message']}")
            
            # è¿™é‡Œå¯ä»¥é›†æˆé‚®ä»¶ã€çŸ­ä¿¡ã€é’‰é’‰ç­‰å‘Šè­¦æ¸ é“
            # await self.send_email_alert(alert)
            # await self.send_webhook_alert(alert)
    
    async def save_health_report(self, health_report: Dict):
        """ä¿å­˜å¥åº·æ£€æŸ¥æŠ¥å‘Š"""
        try:
            # ä¿å­˜åˆ°æ–‡ä»¶
            filename = f"health_reports/health_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            import os
            os.makedirs('health_reports', exist_ok=True)
            
            with open(filename, 'w') as f:
                json.dump(health_report, f, indent=2, ensure_ascii=False)
            
            # å¯ä»¥é€‰æ‹©ä¿å­˜åˆ°æ•°æ®åº“
            # await self.save_to_database(health_report)
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜å¥åº·æŠ¥å‘Šå¤±è´¥: {e}")
    
    def stop_monitoring(self):
        """åœæ­¢å¥åº·ç›‘æ§"""
        self.is_monitoring = False
        self.logger.info("ç³»ç»Ÿå¥åº·ç›‘æ§å·²åœæ­¢")

# å¯åŠ¨å¥åº·ç›‘æ§
async def start_health_monitoring():
    monitor = SystemHealthMonitor()
    await monitor.start_monitoring()

if __name__ == "__main__":
    import random
    import httpx
    asyncio.run(start_health_monitoring())
```

### 5.2 è‡ªåŠ¨å›æ»šæœºåˆ¶

```python
# deployment/rollback_manager.py
import asyncio
import shutil
import subprocess
import json
from datetime import datetime
from pathlib import Path

class RollbackManager:
    """è‡ªåŠ¨å›æ»šç®¡ç†å™¨"""
    
    def __init__(self):
        self.backup_directory = Path("backups")
        self.rollback_scripts = Path("rollback_scripts")
        self.current_version = None
        self.previous_version = None
        
        # åˆ›å»ºå¿…è¦ç›®å½•
        self.backup_directory.mkdir(exist_ok=True)
        self.rollback_scripts.mkdir(exist_ok=True)
    
    async def create_deployment_checkpoint(self, version: str):
        """åˆ›å»ºéƒ¨ç½²æ£€æŸ¥ç‚¹"""
        print(f"ğŸ“¸ åˆ›å»ºç‰ˆæœ¬ {version} çš„éƒ¨ç½²æ£€æŸ¥ç‚¹...")
        
        checkpoint = {
            'version': version,
            'timestamp': datetime.now().isoformat(),
            'services': await self.get_current_services_status(),
            'database_schema_hash': await self.get_database_schema_hash(),
            'config_files': await self.backup_config_files(version)
        }
        
        # ä¿å­˜æ£€æŸ¥ç‚¹ä¿¡æ¯
        checkpoint_file = self.backup_directory / f"checkpoint_{version}.json"
        with open(checkpoint_file, 'w') as f:
            json.dump(checkpoint, f, indent=2)
        
        print(f"âœ… æ£€æŸ¥ç‚¹åˆ›å»ºå®Œæˆ: {checkpoint_file}")
        return checkpoint
    
    async def get_current_services_status(self):
        """è·å–å½“å‰æœåŠ¡çŠ¶æ€"""
        services = {}
        
        # æ£€æŸ¥Dockerå®¹å™¨çŠ¶æ€
        try:
            result = subprocess.run(
                ['docker', 'ps', '--format', 'table {{.Names}}\t{{.Status}}\t{{.Ports}}'],
                capture_output=True, text=True
            )
            services['docker_containers'] = result.stdout
        except Exception as e:
            services['docker_error'] = str(e)
        
        # æ£€æŸ¥Pythonè¿›ç¨‹
        try:
            import psutil
            python_processes = []
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                if 'python' in proc.info['name'].lower():
                    python_processes.append(proc.info)
            services['python_processes'] = python_processes
        except Exception as e:
            services['process_error'] = str(e)
        
        return services
    
    async def get_database_schema_hash(self):
        """è·å–æ•°æ®åº“æ¨¡å¼å“ˆå¸Œå€¼"""
        import hashlib
        
        try:
            # PostgreSQLæ¨¡å¼å“ˆå¸Œ
            import asyncpg
            conn = await asyncpg.connect("postgresql://quantuser:quantpass@localhost:5432/quant_metadata")
            
            tables = await conn.fetch("""
                SELECT table_name, column_name, data_type 
                FROM information_schema.columns 
                WHERE table_schema = 'public'
                ORDER BY table_name, ordinal_position
            """)
            
            schema_str = json.dumps([dict(row) for row in tables], sort_keys=True)
            schema_hash = hashlib.md5(schema_str.encode()).hexdigest()
            
            await conn.close()
            return schema_hash
            
        except Exception as e:
            return f"error: {e}"
    
    async def backup_config_files(self, version: str):
        """å¤‡ä»½é…ç½®æ–‡ä»¶"""
        config_files = [
            'docker-compose.yml',
            'web_interface/config.js',
            'rust_engine/Cargo.toml',
            '.env'
        ]
        
        backup_dir = self.backup_directory / f"config_{version}"
        backup_dir.mkdir(exist_ok=True)
        
        backed_up_files = []
        
        for config_file in config_files:
            source = Path(config_file)
            if source.exists():
                destination = backup_dir / source.name
                shutil.copy2(source, destination)
                backed_up_files.append(str(destination))
        
        return backed_up_files
    
    async def perform_rollback(self, target_version: str, reason: str = "Manual rollback"):
        """æ‰§è¡Œå›æ»šæ“ä½œ"""
        print(f"ğŸ”„ å¼€å§‹å›æ»šåˆ°ç‰ˆæœ¬ {target_version}...")
        print(f"å›æ»šåŸå› : {reason}")
        
        # æ£€æŸ¥ç›®æ ‡ç‰ˆæœ¬æ£€æŸ¥ç‚¹æ˜¯å¦å­˜åœ¨
        checkpoint_file = self.backup_directory / f"checkpoint_{target_version}.json"
        if not checkpoint_file.exists():
            raise Exception(f"æ‰¾ä¸åˆ°ç‰ˆæœ¬ {target_version} çš„æ£€æŸ¥ç‚¹")
        
        with open(checkpoint_file, 'r') as f:
            target_checkpoint = json.load(f)
        
        rollback_steps = [
            self.stop_current_services,
            lambda: self.restore_config_files(target_checkpoint),
            lambda: self.rollback_database_changes(target_checkpoint),
            lambda: self.restart_services(target_checkpoint),
            lambda: self.verify_rollback(target_checkpoint)
        ]
        
        try:
            for i, step in enumerate(rollback_steps):
                print(f"æ‰§è¡Œå›æ»šæ­¥éª¤ {i+1}/{len(rollback_steps)}...")
                await step()
                
            print("âœ… å›æ»šå®Œæˆ")
            
            # è®°å½•å›æ»šæ“ä½œ
            await self.log_rollback_operation(target_version, reason, success=True)
            
        except Exception as e:
            print(f"âŒ å›æ»šå¤±è´¥: {e}")
            await self.log_rollback_operation(target_version, reason, success=False, error=str(e))
            raise
    
    async def stop_current_services(self):
        """åœæ­¢å½“å‰æœåŠ¡"""
        print("â¹ï¸ åœæ­¢å½“å‰æœåŠ¡...")
        
        # åœæ­¢Dockerå®¹å™¨
        try:
            subprocess.run(['docker-compose', 'down'], check=True)
            print("âœ… DockeræœåŠ¡å·²åœæ­¢")
        except Exception as e:
            print(f"âš ï¸ DockeræœåŠ¡åœæ­¢å¤±è´¥: {e}")
        
        # åœæ­¢Pythonè¿›ç¨‹
        try:
            import psutil
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                if 'python' in proc.info['name'].lower():
                    cmdline = ' '.join(proc.info['cmdline'] or [])
                    if 'quant' in cmdline.lower() or 'data-analysis' in cmdline:
                        proc.terminate()
                        print(f"ç»ˆæ­¢è¿›ç¨‹: {proc.info['pid']}")
        except Exception as e:
            print(f"âš ï¸ Pythonè¿›ç¨‹åœæ­¢å¤±è´¥: {e}")
        
        await asyncio.sleep(5)  # ç­‰å¾…è¿›ç¨‹å®Œå…¨åœæ­¢
    
    async def restore_config_files(self, target_checkpoint):
        """æ¢å¤é…ç½®æ–‡ä»¶"""
        print("ğŸ“ æ¢å¤é…ç½®æ–‡ä»¶...")
        
        config_files = target_checkpoint.get('config_files', [])
        
        for backup_file in config_files:
            backup_path = Path(backup_file)
            if backup_path.exists():
                # ç¡®å®šç›®æ ‡è·¯å¾„
                target_path = Path(backup_path.name)
                
                # åˆ›å»ºå½“å‰ç‰ˆæœ¬çš„å¤‡ä»½
                if target_path.exists():
                    shutil.copy2(target_path, f"{target_path}.rollback_backup")
                
                # æ¢å¤æ–‡ä»¶
                shutil.copy2(backup_path, target_path)
                print(f"âœ… æ¢å¤é…ç½®æ–‡ä»¶: {target_path}")
    
    async def rollback_database_changes(self, target_checkpoint):
        """å›æ»šæ•°æ®åº“å˜æ›´"""
        print("ğŸ—„ï¸ å›æ»šæ•°æ®åº“å˜æ›´...")
        
        # è¿™é‡Œåº”è¯¥åŒ…å«æ•°æ®åº“è¿ç§»çš„å›æ»šé€»è¾‘
        # ç®€åŒ–å®ç°ï¼šæ£€æŸ¥æ¨¡å¼æ˜¯å¦ä¸€è‡´
        current_hash = await self.get_database_schema_hash()
        target_hash = target_checkpoint.get('database_schema_hash')
        
        if current_hash != target_hash:
            print(f"âš ï¸ æ•°æ®åº“æ¨¡å¼å·²å˜æ›´ï¼Œå½“å‰: {current_hash}, ç›®æ ‡: {target_hash}")
            # è¿™é‡Œåº”è¯¥æ‰§è¡Œå…·ä½“çš„æ•°æ®åº“å›æ»šè„šæœ¬
            # await self.execute_database_rollback_scripts(target_checkpoint['version'])
        else:
            print("âœ… æ•°æ®åº“æ¨¡å¼æ— éœ€å›æ»š")
    
    async def restart_services(self, target_checkpoint):
        """é‡å¯æœåŠ¡"""
        print("ğŸ”„ é‡å¯æœåŠ¡...")
        
        # å¯åŠ¨DockeræœåŠ¡
        try:
            subprocess.run(['docker-compose', 'up', '-d'], check=True)
            print("âœ… DockeræœåŠ¡å·²å¯åŠ¨")
        except Exception as e:
            print(f"âŒ DockeræœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
            raise
        
        # ç­‰å¾…æœåŠ¡å¯åŠ¨
        await asyncio.sleep(10)
    
    async def verify_rollback(self, target_checkpoint):
        """éªŒè¯å›æ»šç»“æœ"""
        print("ğŸ” éªŒè¯å›æ»šç»“æœ...")
        
        # æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€
        try:
            import httpx
            async with httpx.AsyncClient() as client:
                # æ£€æŸ¥ä¸»è¦æœåŠ¡
                services_to_check = [
                    'http://localhost:8003/api/v1/health',  # V1 API
                    'http://localhost:8000/health',         # V2 API
                    'http://localhost:8001/bridge/health'   # Bridge
                ]
                
                for service_url in services_to_check:
                    try:
                        response = await client.get(service_url, timeout=10.0)
                        if response.status_code == 200:
                            print(f"âœ… æœåŠ¡å¥åº·: {service_url}")
                        else:
                            print(f"âš ï¸ æœåŠ¡å¼‚å¸¸: {service_url} - {response.status_code}")
                    except Exception as e:
                        print(f"âŒ æœåŠ¡ä¸å¯è¾¾: {service_url} - {e}")
                        
        except Exception as e:
            print(f"éªŒè¯è¿‡ç¨‹å‡ºé”™: {e}")
            raise
        
        print("âœ… å›æ»šéªŒè¯å®Œæˆ")
    
    async def log_rollback_operation(self, target_version: str, reason: str, 
                                   success: bool, error: str = None):
        """è®°å½•å›æ»šæ“ä½œ"""
        rollback_log = {
            'timestamp': datetime.now().isoformat(),
            'target_version': target_version,
            'reason': reason,
            'success': success,
            'error': error
        }
        
        log_file = Path("rollback_operations.log")
        with open(log_file, 'a') as f:
            f.write(json.dumps(rollback_log) + '\n')
    
    async def auto_rollback_on_failure(self, current_version: str, 
                                     health_check_timeout: int = 300):
        """å¤±è´¥æ—¶è‡ªåŠ¨å›æ»š"""
        print(f"ğŸ¤– å¯åŠ¨è‡ªåŠ¨å›æ»šç›‘æ§ï¼Œè¶…æ—¶æ—¶é—´: {health_check_timeout}ç§’")
        
        start_time = datetime.now()
        
        while (datetime.now() - start_time).seconds < health_check_timeout:
            try:
                # æ‰§è¡Œå¥åº·æ£€æŸ¥
                health_status = await self.check_system_health()
                
                if health_status['overall_status'] == 'healthy':
                    print("âœ… ç³»ç»Ÿå¥åº·ï¼Œå–æ¶ˆè‡ªåŠ¨å›æ»š")
                    return True
                
                if health_status['overall_status'] == 'critical':
                    print("ğŸš¨ ç³»ç»Ÿä¸¥é‡å¼‚å¸¸ï¼Œç«‹å³æ‰§è¡Œè‡ªåŠ¨å›æ»š")
                    await self.perform_emergency_rollback(current_version)
                    return False
                
                # ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥
                await asyncio.sleep(30)
                
            except Exception as e:
                print(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
                await asyncio.sleep(30)
        
        # è¶…æ—¶åæ‰§è¡Œå›æ»š
        print("â° å¥åº·æ£€æŸ¥è¶…æ—¶ï¼Œæ‰§è¡Œè‡ªåŠ¨å›æ»š")
        await self.perform_emergency_rollback(current_version)
        return False
    
    async def check_system_health(self):
        """æ£€æŸ¥ç³»ç»Ÿæ•´ä½“å¥åº·çŠ¶æ€"""
        # ç®€åŒ–çš„å¥åº·æ£€æŸ¥
        import httpx
        
        critical_services = [
            'http://localhost:8003/api/v1/health',
            'http://localhost:8000/health'
        ]
        
        healthy_count = 0
        total_count = len(critical_services)
        
        async with httpx.AsyncClient(timeout=10.0) as client:
            for service in critical_services:
                try:
                    response = await client.get(service)
                    if response.status_code == 200:
                        healthy_count += 1
                except:
                    pass
        
        health_ratio = healthy_count / total_count
        
        if health_ratio >= 0.8:
            overall_status = 'healthy'
        elif health_ratio >= 0.5:
            overall_status = 'warning'
        else:
            overall_status = 'critical'
        
        return {
            'overall_status': overall_status,
            'healthy_services': healthy_count,
            'total_services': total_count,
            'health_ratio': health_ratio
        }
    
    async def perform_emergency_rollback(self, current_version: str):
        """æ‰§è¡Œç´§æ€¥å›æ»š"""
        print("ğŸš¨ æ‰§è¡Œç´§æ€¥å›æ»š...")
        
        # æŸ¥æ‰¾æœ€è¿‘çš„å¯ç”¨ç‰ˆæœ¬
        checkpoints = list(self.backup_directory.glob("checkpoint_*.json"))
        checkpoints.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        
        for checkpoint_file in checkpoints:
            version = checkpoint_file.stem.replace("checkpoint_", "")
            if version != current_version:
                try:
                    await self.perform_rollback(version, "Emergency auto-rollback")
                    print(f"âœ… ç´§æ€¥å›æ»šåˆ°ç‰ˆæœ¬ {version} æˆåŠŸ")
                    return
                except Exception as e:
                    print(f"âŒ å›æ»šåˆ°ç‰ˆæœ¬ {version} å¤±è´¥: {e}")
                    continue
        
        print("âŒ æ‰€æœ‰å›æ»šå°è¯•éƒ½å¤±è´¥äº†")

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    rollback_manager = RollbackManager()
    
    # åˆ›å»ºæ£€æŸ¥ç‚¹
    await rollback_manager.create_deployment_checkpoint("v2.0.0")
    
    # æ¨¡æ‹Ÿéƒ¨ç½²å¤±è´¥åçš„å›æ»š
    # await rollback_manager.perform_rollback("v1.9.0", "Deployment validation failed")

if __name__ == "__main__":
    asyncio.run(main())
```

---

## æ€»ç»“

æœ¬ç³»ç»Ÿé›†æˆä¸å‡çº§ç­–ç•¥æ–‡æ¡£æä¾›äº†ï¼š

### ğŸš€ æ ¸å¿ƒç­–ç•¥

1. **æ¸è¿›å¼å‡çº§**: åˆ†4ä¸ªé˜¶æ®µå¹³æ»‘è¿‡æ¸¡ï¼Œé™ä½é£é™©
2. **é›¶åœæœºéƒ¨ç½²**: APIæ¡¥æ¥å™¨ç¡®ä¿æœåŠ¡è¿ç»­æ€§
3. **è‡ªåŠ¨å›æ»š**: å¥åº·ç›‘æ§ + è‡ªåŠ¨å›æ»šæœºåˆ¶
4. **å‘åå…¼å®¹**: V1 APIç»§ç»­å¯ç”¨ï¼Œç”¨æˆ·æ— æ„ŸçŸ¥
5. **é£é™©æ§åˆ¶**: æ¯ä¸ªé˜¶æ®µéƒ½æœ‰éªŒè¯å’Œå›æ»šé¢„æ¡ˆ

### ğŸ’¡ æŠ€æœ¯ä¼˜åŠ¿

- **æ™ºèƒ½è·¯ç”±**: V1/V2 APIæ™ºèƒ½åˆ‡æ¢å’Œé™çº§
- **æ•°æ®åŒæ­¥**: æ— æŸæ•°æ®è¿ç§»å’ŒéªŒè¯
- **å®æ—¶ç›‘æ§**: å…¨æ–¹ä½å¥åº·æ£€æŸ¥å’Œå‘Šè­¦
- **å¿«é€Ÿæ¢å¤**: è‡ªåŠ¨åŒ–å›æ»šæœºåˆ¶ï¼Œæ•…éšœå¿«é€Ÿæ¢å¤

### ğŸ›  å®æ–½ä¿éšœ

- **å®Œæ•´éªŒè¯**: æ¯ä¸ªé˜¶æ®µéƒ½æœ‰ä¸“é—¨çš„éªŒè¯å™¨
- **è¯¦ç»†æ—¥å¿—**: å®Œæ•´çš„æ“ä½œè®°å½•å’Œè¿½è¸ª
- **æ£€æŸ¥ç‚¹æœºåˆ¶**: å¯éšæ—¶å›æ»šåˆ°ä»»æ„ç¨³å®šç‰ˆæœ¬
- **æ–‡æ¡£å®Œå–„**: è¯¦ç»†çš„æ“ä½œæ‰‹å†Œå’Œæ•…éšœæ’é™¤æŒ‡å—

è¯¥é›†æˆç­–ç•¥ç¡®ä¿äº†ä»åŸå‹ç³»ç»Ÿåˆ°ç”Ÿäº§çº§ç³»ç»Ÿçš„å¹³æ»‘å‡çº§ï¼Œæœ€å¤§åŒ–é™ä½äº†é£é™©ï¼Œä¿è¯äº†ä¸šåŠ¡è¿ç»­æ€§ã€‚

<function_calls>
<invoke name="TodoWrite">
<parameter name="todos">[{"id": "analyze_current_system", "content": "\u5206\u6790\u73b0\u6709\u7cfb\u7edf\u67b6\u6784\uff08\u57fa\u4e8e\u5df2\u8bfb\u53d6\u7684HTML\u3001JS\u3001Python\u4ee3\u7801\uff09", "status": "completed"}, {"id": "design_system_architecture", "content": "\u8bbe\u8ba1\u5b8c\u6574\u7684\u7cfb\u7edf\u67b6\u6784\u56fe\u548c\u6280\u672f\u65b9\u6848", "status": "completed"}, {"id": "design_rust_engine", "content": "\u8bbe\u8ba1Rust\u6838\u5fc3\u8ba1\u7b97\u5f15\u64ce\u67b6\u6784", "status": "completed"}, {"id": "design_python_service", "content": "\u8bbe\u8ba1Python\u670d\u52a1\u5c42\u91cd\u6784\u65b9\u6848", "status": "completed"}, {"id": "design_data_architecture", "content": "\u8bbe\u8ba1\u6570\u636e\u5b58\u50a8\u548c\u5904\u7406\u67b6\u6784", "status": "completed"}, {"id": "create_api_specifications", "content": "\u5b9a\u4e49API\u63a5\u53e3\u89c4\u8303\u548c\u6570\u636e\u6d41\u8bbe\u8ba1", "status": "completed"}, {"id": "design_integration_strategy", "content": "\u5236\u5b9a\u73b0\u6709\u7cfb\u7edf\u5347\u7ea7\u548c\u96c6\u6210\u7b56\u7565", "status": "completed"}, {"id": "create_implementation_plan", "content": "\u5236\u5b9a\u5177\u4f53\u5b9e\u65bd\u6b65\u9aa4\u548c\u6280\u672f\u5efa\u8bae", "status": "in_progress"}]