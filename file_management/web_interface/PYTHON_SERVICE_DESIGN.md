# PythonæœåŠ¡å±‚é‡æ„è®¾è®¡æ–‡æ¡£

**é¡¹ç›®**: QuantAnalyzer Pro - Python APIæœåŠ¡å±‚  
**ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¥æœŸ**: 2025-08-10  

---

## 1. ç°æœ‰ç³»ç»Ÿåˆ†æ

### 1.1 å½“å‰PythonæœåŠ¡ç°çŠ¶

åŸºäºå¯¹ç°æœ‰ `data-analysis-api.py` çš„åˆ†æï¼Œå½“å‰ç³»ç»Ÿç‰¹ç‚¹ï¼š

**ç°æœ‰ä¼˜åŠ¿**ï¼š
- âœ… å®Œæ•´çš„APIç«¯ç‚¹è¦†ç›–ï¼ˆå› å­ã€å›æµ‹ã€æ•°æ®ç­‰ï¼‰
- âœ… è‰¯å¥½çš„è·¯ç”±ç»“æ„è®¾è®¡
- âœ… CORSè·¨åŸŸæ”¯æŒ
- âœ… ä¸°å¯Œçš„æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆ

**ä¸»è¦é™åˆ¶**ï¼š
- âŒ åŸºäºç®€å•HTTPæœåŠ¡å™¨ï¼Œç¼ºä¹å¼‚æ­¥å¤„ç†èƒ½åŠ›
- âŒ æ— æ•°æ®æŒä¹…åŒ–ï¼Œå…¨éƒ¨ä¸ºæ¨¡æ‹Ÿæ•°æ®
- âŒ ç¼ºä¹æ•°æ®éªŒè¯å’Œé”™è¯¯å¤„ç†
- âŒ æ— è®¤è¯å’Œæƒé™æ§åˆ¶
- âŒ æ€§èƒ½å’Œå¹¶å‘èƒ½åŠ›æœ‰é™

### 1.2 é‡æ„ç›®æ ‡

1. **æ¶æ„ç°ä»£åŒ–**: è¿ç§»åˆ°FastAPIå¼‚æ­¥æ¡†æ¶
2. **æ€§èƒ½æå‡**: é›†æˆRustå¼•æ“ï¼Œå®ç°é«˜æ€§èƒ½è®¡ç®—
3. **æ•°æ®æŒä¹…åŒ–**: é›†æˆClickHouseå’ŒPostgreSQL
4. **æœåŠ¡åŒ–**: å¾®æœåŠ¡æ¶æ„ï¼Œæ”¯æŒæ°´å¹³æ‰©å±•
5. **ç”Ÿäº§å°±ç»ª**: æ·»åŠ ç›‘æ§ã€æ—¥å¿—ã€å®‰å…¨ç­‰ç”Ÿäº§ç¯å¢ƒå¿…éœ€åŠŸèƒ½

---

## 2. FastAPIæœåŠ¡æ¶æ„è®¾è®¡

### 2.1 é¡¹ç›®ç»“æ„

```
python_api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                    # FastAPIåº”ç”¨å…¥å£
â”‚   â”œâ”€â”€ config.py                  # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ dependencies.py            # ä¾èµ–æ³¨å…¥
â”‚   â”œâ”€â”€ api/                       # APIè·¯ç”±å±‚
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ v1/                    # API v1ç‰ˆæœ¬ï¼ˆå‘åå…¼å®¹ï¼‰
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ legacy.py          # å…¼å®¹æ—§API
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ v2/                    # API v2ç‰ˆæœ¬ï¼ˆæ–°æ¶æ„ï¼‰
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ factors.py         # å› å­ç›¸å…³API
â”‚   â”‚       â”œâ”€â”€ backtest.py        # å›æµ‹ç›¸å…³API
â”‚   â”‚       â”œâ”€â”€ data.py            # æ•°æ®ç›¸å…³API
â”‚   â”‚       â”œâ”€â”€ portfolio.py       # ç»„åˆç›¸å…³API
â”‚   â”‚       â”œâ”€â”€ ai.py              # AIå¼•æ“ç›¸å…³API
â”‚   â”‚       â””â”€â”€ system.py          # ç³»ç»Ÿç›¸å…³API
â”‚   â”œâ”€â”€ core/                      # æ ¸å¿ƒæ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ database.py            # æ•°æ®åº“è¿æ¥
â”‚   â”‚   â”œâ”€â”€ cache.py               # ç¼“å­˜ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ rust_engine.py         # Rustå¼•æ“æ¥å£
â”‚   â”‚   â”œâ”€â”€ security.py            # å®‰å…¨è®¤è¯
â”‚   â”‚   â””â”€â”€ logging.py             # æ—¥å¿—é…ç½®
â”‚   â”œâ”€â”€ models/                    # æ•°æ®æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py                # åŸºç¡€æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ factor.py              # å› å­æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ backtest.py            # å›æµ‹æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ portfolio.py           # ç»„åˆæ¨¡å‹
â”‚   â”‚   â””â”€â”€ user.py                # ç”¨æˆ·æ¨¡å‹
â”‚   â”œâ”€â”€ services/                  # ä¸šåŠ¡é€»è¾‘å±‚
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ factor_service.py      # å› å­æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ backtest_service.py    # å›æµ‹æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ data_service.py        # æ•°æ®æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ portfolio_service.py   # ç»„åˆæœåŠ¡
â”‚   â”‚   â””â”€â”€ ai_service.py          # AIæœåŠ¡
â”‚   â”œâ”€â”€ workers/                   # åå°ä»»åŠ¡
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ factor_worker.py       # å› å­è®¡ç®—ä»»åŠ¡
â”‚   â”‚   â”œâ”€â”€ backtest_worker.py     # å›æµ‹ä»»åŠ¡
â”‚   â”‚   â””â”€â”€ data_worker.py         # æ•°æ®å¤„ç†ä»»åŠ¡
â”‚   â”œâ”€â”€ middleware/                # ä¸­é—´ä»¶
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ auth.py                # è®¤è¯ä¸­é—´ä»¶
â”‚   â”‚   â”œâ”€â”€ rate_limit.py          # é™æµä¸­é—´ä»¶
â”‚   â”‚   â””â”€â”€ monitoring.py          # ç›‘æ§ä¸­é—´ä»¶
â”‚   â””â”€â”€ utils/                     # å·¥å…·æ¨¡å—
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ datetime.py            # æ—¶é—´å¤„ç†
â”‚       â”œâ”€â”€ validation.py          # æ•°æ®éªŒè¯
â”‚       â””â”€â”€ serialization.py       # åºåˆ—åŒ–
â”œâ”€â”€ tests/                         # æµ‹è¯•ä»£ç 
â”œâ”€â”€ alembic/                       # æ•°æ®åº“è¿ç§»
â”œâ”€â”€ requirements.txt               # Pythonä¾èµ–
â”œâ”€â”€ pyproject.toml                # é¡¹ç›®é…ç½®
â””â”€â”€ Dockerfile                     # å®¹å™¨é…ç½®
```

### 2.2 æ ¸å¿ƒåº”ç”¨é…ç½®

```python
# app/main.py
import asyncio
from contextlib import asynccontextmanager
from fastapi import FastAPI, Depends, Request, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.responses import JSONResponse
import uvicorn
import logging

from .config import get_settings
from .core import database, cache, rust_engine
from .middleware import auth, rate_limit, monitoring
from .api.v1 import legacy_router
from .api.v2 import (
    factors_router, backtest_router, data_router, 
    portfolio_router, ai_router, system_router
)

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    logger.info("ğŸš€ QuantAnalyzer Pro API å¯åŠ¨ä¸­...")
    
    try:
        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        await database.init_database()
        logger.info("âœ… æ•°æ®åº“è¿æ¥å·²å»ºç«‹")
        
        # åˆå§‹åŒ–Redisç¼“å­˜
        await cache.init_cache()
        logger.info("âœ… ç¼“å­˜ç³»ç»Ÿå·²åˆå§‹åŒ–")
        
        # åˆå§‹åŒ–Rustå¼•æ“
        await rust_engine.init_engine()
        logger.info("âœ… Rustè®¡ç®—å¼•æ“å·²åŠ è½½")
        
        # å¯åŠ¨åå°ä»»åŠ¡
        await start_background_tasks()
        logger.info("âœ… åå°ä»»åŠ¡å·²å¯åŠ¨")
        
        logger.info("ğŸ‰ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        
    except Exception as e:
        logger.error(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        raise
    
    yield  # åº”ç”¨è¿è¡Œé˜¶æ®µ
    
    # æ¸…ç†èµ„æº
    logger.info("ğŸ§¹ ç³»ç»Ÿæ¸…ç†ä¸­...")
    await database.close_database()
    await cache.close_cache()
    await rust_engine.cleanup_engine()
    logger.info("âœ… ç³»ç»Ÿæ¸…ç†å®Œæˆ")

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="QuantAnalyzer Pro API",
    description="AI-driven quantitative analysis platform with high-performance computing",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_url="/openapi.json",
    lifespan=lifespan
)

# è·å–é…ç½®
settings = get_settings()

# æ·»åŠ ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.add_middleware(GZipMiddleware, minimum_size=1000)
app.add_middleware(monitoring.PrometheusMiddleware)
app.add_middleware(rate_limit.RateLimitMiddleware)

# å…¨å±€å¼‚å¸¸å¤„ç†
@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "success": False,
            "error": exc.detail,
            "timestamp": datetime.utcnow().isoformat(),
            "path": str(request.url.path)
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    logger.error(f"Unhandled exception: {exc}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content={
            "success": False,
            "error": "Internal server error",
            "timestamp": datetime.utcnow().isoformat(),
            "path": str(request.url.path)
        }
    )

# æ³¨å†Œè·¯ç”±
# V1 API (å‘åå…¼å®¹)
app.include_router(
    legacy_router,
    prefix="/api/v1",
    tags=["Legacy API v1"]
)

# V2 API (æ–°æ¶æ„)
app.include_router(
    factors_router,
    prefix="/api/v2/factors",
    tags=["Factors"],
    dependencies=[Depends(auth.get_current_user)]
)

app.include_router(
    backtest_router,
    prefix="/api/v2/backtest",
    tags=["Backtest"],
    dependencies=[Depends(auth.get_current_user)]
)

app.include_router(
    data_router,
    prefix="/api/v2/data",
    tags=["Data"],
    dependencies=[Depends(auth.get_current_user)]
)

app.include_router(
    portfolio_router,
    prefix="/api/v2/portfolio",
    tags=["Portfolio"],
    dependencies=[Depends(auth.get_current_user)]
)

app.include_router(
    ai_router,
    prefix="/api/v2/ai",
    tags=["AI Services"],
    dependencies=[Depends(auth.get_current_user)]
)

app.include_router(
    system_router,
    prefix="/api/v2/system",
    tags=["System"]
)

# å¥åº·æ£€æŸ¥ç«¯ç‚¹
@app.get("/health", tags=["Health"])
async def health_check():
    """ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
    try:
        # æ£€æŸ¥å„ä¸ªç»„ä»¶çŠ¶æ€
        db_status = await database.check_health()
        cache_status = await cache.check_health()
        rust_status = await rust_engine.check_health()
        
        overall_status = "healthy" if all([db_status, cache_status, rust_status]) else "unhealthy"
        
        return {
            "status": overall_status,
            "timestamp": datetime.utcnow().isoformat(),
            "version": "2.0.0",
            "components": {
                "database": "healthy" if db_status else "unhealthy",
                "cache": "healthy" if cache_status else "unhealthy",
                "rust_engine": "healthy" if rust_status else "unhealthy"
            }
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return JSONResponse(
            status_code=503,
            content={
                "status": "unhealthy",
                "error": str(e),
                "timestamp": datetime.utcnow().isoformat()
            }
        )

# æ ¹è·¯å¾„
@app.get("/", tags=["Root"])
async def root():
    """APIæ ¹è·¯å¾„"""
    return {
        "message": "QuantAnalyzer Pro API v2.0",
        "docs": "/docs",
        "health": "/health",
        "version": "2.0.0"
    }

async def start_background_tasks():
    """å¯åŠ¨åå°ä»»åŠ¡"""
    # è¿™é‡Œå¯ä»¥å¯åŠ¨å®šæ—¶ä»»åŠ¡ã€æ•°æ®åŒæ­¥ç­‰åå°ä»»åŠ¡
    pass

if __name__ == "__main__":
    uvicorn.run(
        "app.main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
```

### 2.3 é…ç½®ç®¡ç†

```python
# app/config.py
from functools import lru_cache
from pydantic_settings import BaseSettings
from typing import List, Optional
import os

class Settings(BaseSettings):
    # åº”ç”¨é…ç½®
    APP_NAME: str = "QuantAnalyzer Pro"
    APP_VERSION: str = "2.0.0"
    DEBUG: bool = False
    
    # æœåŠ¡å™¨é…ç½®
    HOST: str = "0.0.0.0"
    PORT: int = 8000
    WORKERS: int = 1
    
    # å®‰å…¨é…ç½®
    SECRET_KEY: str = "your-secret-key-here"
    JWT_ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30
    
    # CORSé…ç½®
    ALLOWED_ORIGINS: List[str] = ["http://localhost:3000", "http://localhost:8080"]
    
    # æ•°æ®åº“é…ç½®
    DATABASE_URL: str = "postgresql+asyncpg://user:pass@localhost:5432/quant_db"
    CLICKHOUSE_URL: str = "http://localhost:8123"
    CLICKHOUSE_DATABASE: str = "quant_data"
    
    # Redisé…ç½®
    REDIS_URL: str = "redis://localhost:6379"
    CACHE_TTL: int = 3600  # 1å°æ—¶
    
    # Rustå¼•æ“é…ç½®
    RUST_ENGINE_PATH: str = "./rust_engine/target/release"
    RUST_ENGINE_THREADS: int = 0  # 0è¡¨ç¤ºä½¿ç”¨CPUæ ¸å¿ƒæ•°
    RUST_ENGINE_MEMORY_LIMIT_GB: int = 8
    
    # æ•°æ®æºé…ç½®
    BINANCE_API_KEY: Optional[str] = None
    BINANCE_SECRET_KEY: Optional[str] = None
    OKX_API_KEY: Optional[str] = None
    OKX_SECRET_KEY: Optional[str] = None
    
    # AIæœåŠ¡é…ç½®
    OPENAI_API_KEY: Optional[str] = None
    DEEPSEEK_API_KEY: Optional[str] = None
    GEMINI_API_KEY: Optional[str] = None
    
    # ç›‘æ§é…ç½®
    ENABLE_PROMETHEUS: bool = True
    PROMETHEUS_PORT: int = 9090
    LOG_LEVEL: str = "INFO"
    
    # ä»»åŠ¡é˜Ÿåˆ—é…ç½®
    CELERY_BROKER_URL: str = "redis://localhost:6379/0"
    CELERY_RESULT_BACKEND: str = "redis://localhost:6379/0"
    
    # é™æµé…ç½®
    RATE_LIMIT_REQUESTS: int = 100
    RATE_LIMIT_PERIOD: int = 60  # ç§’
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"
        case_sensitive = True

@lru_cache()
def get_settings() -> Settings:
    """è·å–é…ç½®å®ä¾‹ï¼ˆç¼“å­˜ï¼‰"""
    return Settings()

# ç¯å¢ƒç‰¹å®šé…ç½®
class DevelopmentSettings(Settings):
    DEBUG: bool = True
    LOG_LEVEL: str = "DEBUG"
    WORKERS: int = 1

class ProductionSettings(Settings):
    DEBUG: bool = False
    LOG_LEVEL: str = "INFO"
    WORKERS: int = 4

class TestingSettings(Settings):
    DEBUG: bool = True
    DATABASE_URL: str = "sqlite+aiosqlite:///./test.db"
    REDIS_URL: str = "redis://localhost:6379/1"

def get_settings_for_env(env: str = None) -> Settings:
    """æ ¹æ®ç¯å¢ƒè·å–é…ç½®"""
    env = env or os.getenv("ENVIRONMENT", "development")
    
    if env == "production":
        return ProductionSettings()
    elif env == "testing":
        return TestingSettings()
    else:
        return DevelopmentSettings()
```

---

## 3. æ ¸å¿ƒæœåŠ¡æ¨¡å—è®¾è®¡

### 3.1 å› å­æœåŠ¡

```python
# app/services/factor_service.py
from typing import List, Dict, Any, Optional
import asyncio
from datetime import datetime, timedelta
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, and_, or_
import pandas as pd

from ..models.factor import FactorDefinition, FactorResult, FactorLibrary
from ..core.database import get_session
from ..core.rust_engine import get_rust_engine
from ..core.cache import get_cache
from ..utils.validation import validate_factor_definition

class FactorService:
    def __init__(self):
        self.cache = get_cache()
        self.rust_engine = get_rust_engine()
    
    async def calculate_factors(
        self,
        factors: List[FactorDefinition],
        symbols: List[str],
        start_date: datetime,
        end_date: datetime,
        session: AsyncSession = None
    ) -> Dict[str, FactorResult]:
        """æ‰¹é‡è®¡ç®—å› å­"""
        
        # è¾“å…¥éªŒè¯
        for factor in factors:
            validate_factor_definition(factor)
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = self._generate_cache_key(factors, symbols, start_date, end_date)
        cached_result = await self.cache.get(cache_key)
        if cached_result:
            return cached_result
        
        # è·å–å¸‚åœºæ•°æ®
        market_data = await self._get_market_data(symbols, start_date, end_date)
        
        # ä½¿ç”¨Rustå¼•æ“è®¡ç®—å› å­
        calculation_start = datetime.now()
        
        try:
            # å‡†å¤‡Rustå¼•æ“è¾“å…¥
            rust_factors = [self._convert_to_rust_factor(f) for f in factors]
            rust_market_data = self._convert_to_rust_data(market_data)
            
            # å¹¶è¡Œè®¡ç®—
            raw_results = await asyncio.to_thread(
                self.rust_engine.batch_calculate_factors,
                rust_factors,
                rust_market_data,
                symbols
            )
            
            calculation_time = (datetime.now() - calculation_start).total_seconds()
            
            # è½¬æ¢ç»“æœæ ¼å¼
            results = {}
            for factor in factors:
                if factor.name in raw_results:
                    results[factor.name] = FactorResult(
                        factor_id=factor.id,
                        factor_name=factor.name,
                        values=raw_results[factor.name],
                        timestamps=market_data.index.tolist(),
                        symbols=symbols,
                        calculation_time=calculation_time,
                        metadata={
                            "start_date": start_date.isoformat(),
                            "end_date": end_date.isoformat(),
                            "data_points": len(raw_results[factor.name])
                        }
                    )
            
            # ç¼“å­˜ç»“æœ
            await self.cache.set(cache_key, results, ttl=3600)
            
            # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆå¼‚æ­¥ï¼‰
            if session:
                asyncio.create_task(self._save_factor_results(results, session))
            
            return results
            
        except Exception as e:
            raise Exception(f"Factor calculation failed: {str(e)}")
    
    async def get_factor_library(
        self,
        category: Optional[str] = None,
        min_ic: Optional[float] = None,
        min_sharpe: Optional[float] = None,
        limit: int = 100,
        session: AsyncSession = None
    ) -> List[FactorLibrary]:
        """è·å–å› å­åº“"""
        
        if not session:
            async with get_session() as session:
                return await self._get_factor_library_impl(
                    session, category, min_ic, min_sharpe, limit
                )
        else:
            return await self._get_factor_library_impl(
                session, category, min_ic, min_sharpe, limit
            )
    
    async def _get_factor_library_impl(
        self,
        session: AsyncSession,
        category: Optional[str],
        min_ic: Optional[float],
        min_sharpe: Optional[float],
        limit: int
    ) -> List[FactorLibrary]:
        """å› å­åº“æŸ¥è¯¢å®ç°"""
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        conditions = [FactorLibrary.is_active == True]
        
        if category:
            conditions.append(FactorLibrary.category == category)
        
        if min_ic is not None:
            conditions.append(FactorLibrary.ic >= min_ic)
        
        if min_sharpe is not None:
            conditions.append(FactorLibrary.sharpe_ratio >= min_sharpe)
        
        # æ‰§è¡ŒæŸ¥è¯¢
        query = select(FactorLibrary).where(and_(*conditions)).limit(limit)
        result = await session.execute(query)
        
        return result.scalars().all()
    
    async def create_factor(
        self,
        factor_def: FactorDefinition,
        session: AsyncSession = None
    ) -> FactorLibrary:
        """åˆ›å»ºæ–°å› å­"""
        
        # éªŒè¯å› å­å®šä¹‰
        validate_factor_definition(factor_def)
        
        if not session:
            async with get_session() as session:
                return await self._create_factor_impl(session, factor_def)
        else:
            return await self._create_factor_impl(session, factor_def)
    
    async def _create_factor_impl(
        self,
        session: AsyncSession,
        factor_def: FactorDefinition
    ) -> FactorLibrary:
        """åˆ›å»ºå› å­å®ç°"""
        
        # æ£€æŸ¥å› å­æ˜¯å¦å·²å­˜åœ¨
        existing_query = select(FactorLibrary).where(
            FactorLibrary.name == factor_def.name
        )
        existing = await session.execute(existing_query)
        if existing.scalar_one_or_none():
            raise ValueError(f"Factor '{factor_def.name}' already exists")
        
        # åˆ›å»ºæ–°å› å­è®°å½•
        new_factor = FactorLibrary(
            name=factor_def.name,
            category=factor_def.category,
            formula=factor_def.formula,
            description=factor_def.description,
            parameters=factor_def.parameters,
            created_by=factor_def.created_by,
            is_active=True
        )
        
        session.add(new_factor)
        await session.commit()
        await session.refresh(new_factor)
        
        return new_factor
    
    async def evaluate_factor_performance(
        self,
        factor_id: str,
        symbols: List[str],
        start_date: datetime,
        end_date: datetime,
        session: AsyncSession = None
    ) -> Dict[str, float]:
        """è¯„ä¼°å› å­æ€§èƒ½"""
        
        # è·å–å› å­å®šä¹‰
        if not session:
            async with get_session() as session:
                factor_query = select(FactorLibrary).where(FactorLibrary.id == factor_id)
                result = await session.execute(factor_query)
                factor = result.scalar_one_or_none()
        
        if not factor:
            raise ValueError(f"Factor {factor_id} not found")
        
        # è®¡ç®—å› å­å€¼
        factor_def = FactorDefinition(
            id=factor.id,
            name=factor.name,
            category=factor.category,
            formula=factor.formula,
            parameters=factor.parameters
        )
        
        factor_results = await self.calculate_factors(
            [factor_def], symbols, start_date, end_date
        )
        
        if factor.name not in factor_results:
            raise ValueError("Factor calculation failed")
        
        # è·å–ä»·æ ¼æ•°æ®ç”¨äºè®¡ç®—IC
        price_data = await self._get_price_data(symbols, start_date, end_date)
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        performance = await self._calculate_performance_metrics(
            factor_results[factor.name],
            price_data
        )
        
        # æ›´æ–°å› å­æ€§èƒ½è®°å½•
        if session:
            await self._update_factor_performance(session, factor_id, performance)
        
        return performance
    
    async def search_factors(
        self,
        query: str,
        filters: Dict[str, Any] = None,
        limit: int = 50,
        session: AsyncSession = None
    ) -> List[FactorLibrary]:
        """æœç´¢å› å­"""
        
        if not session:
            async with get_session() as session:
                return await self._search_factors_impl(session, query, filters, limit)
        else:
            return await self._search_factors_impl(session, query, filters, limit)
    
    async def _search_factors_impl(
        self,
        session: AsyncSession,
        query: str,
        filters: Dict[str, Any],
        limit: int
    ) -> List[FactorLibrary]:
        """æœç´¢å› å­å®ç°"""
        
        conditions = [FactorLibrary.is_active == True]
        
        # æ–‡æœ¬æœç´¢
        if query:
            text_condition = or_(
                FactorLibrary.name.ilike(f"%{query}%"),
                FactorLibrary.description.ilike(f"%{query}%"),
                FactorLibrary.formula.ilike(f"%{query}%")
            )
            conditions.append(text_condition)
        
        # è¿‡æ»¤æ¡ä»¶
        if filters:
            if "category" in filters:
                conditions.append(FactorLibrary.category == filters["category"])
            
            if "min_ic" in filters:
                conditions.append(FactorLibrary.ic >= filters["min_ic"])
            
            if "created_after" in filters:
                conditions.append(FactorLibrary.created_at >= filters["created_after"])
        
        # æ‰§è¡ŒæŸ¥è¯¢
        search_query = select(FactorLibrary).where(and_(*conditions)).limit(limit)
        result = await session.execute(search_query)
        
        return result.scalars().all()
    
    # ç§æœ‰è¾…åŠ©æ–¹æ³•
    def _generate_cache_key(
        self, factors: List[FactorDefinition], symbols: List[str], 
        start_date: datetime, end_date: datetime
    ) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        factor_names = sorted([f.name for f in factors])
        symbols_str = sorted(symbols)
        return f"factors:{':'.join(factor_names)}:{':'.join(symbols_str)}:{start_date.date()}:{end_date.date()}"
    
    async def _get_market_data(
        self, symbols: List[str], start_date: datetime, end_date: datetime
    ) -> pd.DataFrame:
        """è·å–å¸‚åœºæ•°æ®"""
        # è¿™é‡Œåº”è¯¥ä»æ•°æ®æœåŠ¡è·å–çœŸå®å¸‚åœºæ•°æ®
        # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿæ•°æ®
        from ..services.data_service import DataService
        data_service = DataService()
        return await data_service.get_market_data(symbols, start_date, end_date)
    
    def _convert_to_rust_factor(self, factor: FactorDefinition) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºRustå¼•æ“æ ¼å¼"""
        return {
            "id": factor.id,
            "name": factor.name,
            "factor_type": factor.category.lower(),
            "formula": factor.formula,
            "parameters": factor.parameters or {}
        }
    
    def _convert_to_rust_data(self, df: pd.DataFrame) -> Dict[str, Any]:
        """è½¬æ¢å¸‚åœºæ•°æ®ä¸ºRustå¼•æ“æ ¼å¼"""
        return {
            "timestamps": df.index.tolist(),
            "data": df.to_dict('records')
        }
    
    async def _save_factor_results(
        self, results: Dict[str, FactorResult], session: AsyncSession
    ):
        """ä¿å­˜å› å­è®¡ç®—ç»“æœåˆ°æ•°æ®åº“"""
        # å®ç°æ‰¹é‡ä¿å­˜é€»è¾‘
        pass
    
    async def _get_price_data(
        self, symbols: List[str], start_date: datetime, end_date: datetime
    ) -> pd.DataFrame:
        """è·å–ä»·æ ¼æ•°æ®"""
        # å®ç°ä»·æ ¼æ•°æ®è·å–é€»è¾‘
        pass
    
    async def _calculate_performance_metrics(
        self, factor_result: FactorResult, price_data: pd.DataFrame
    ) -> Dict[str, float]:
        """è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""
        # å®ç°ICã€IRã€å¤æ™®æ¯”ç‡ç­‰æŒ‡æ ‡è®¡ç®—
        return {
            "ic": 0.15,  # ç¤ºä¾‹å€¼
            "ic_ir": 1.2,
            "sharpe_ratio": 1.8,
            "max_drawdown": -0.08,
            "win_rate": 0.65
        }
    
    async def _update_factor_performance(
        self, session: AsyncSession, factor_id: str, performance: Dict[str, float]
    ):
        """æ›´æ–°å› å­æ€§èƒ½è®°å½•"""
        # å®ç°æ€§èƒ½æŒ‡æ ‡æ›´æ–°é€»è¾‘
        pass
```

### 3.2 å›æµ‹æœåŠ¡

```python
# app/services/backtest_service.py
from typing import List, Dict, Any, Optional
import asyncio
import uuid
from datetime import datetime
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

from ..models.backtest import BacktestJob, BacktestResult, StrategyDefinition
from ..core.database import get_session
from ..core.rust_engine import get_rust_engine
from ..workers.backtest_worker import run_backtest_task

class BacktestService:
    def __init__(self):
        self.rust_engine = get_rust_engine()
    
    async def create_backtest_job(
        self,
        strategy: StrategyDefinition,
        start_date: datetime,
        end_date: datetime,
        initial_capital: float = 1000000.0,
        benchmark: Optional[str] = None,
        session: AsyncSession = None
    ) -> str:
        """åˆ›å»ºå›æµ‹ä»»åŠ¡"""
        
        job_id = str(uuid.uuid4())
        
        if not session:
            async with get_session() as session:
                return await self._create_backtest_job_impl(
                    session, job_id, strategy, start_date, end_date, 
                    initial_capital, benchmark
                )
        else:
            return await self._create_backtest_job_impl(
                session, job_id, strategy, start_date, end_date,
                initial_capital, benchmark
            )
    
    async def _create_backtest_job_impl(
        self,
        session: AsyncSession,
        job_id: str,
        strategy: StrategyDefinition,
        start_date: datetime,
        end_date: datetime,
        initial_capital: float,
        benchmark: Optional[str]
    ) -> str:
        """åˆ›å»ºå›æµ‹ä»»åŠ¡å®ç°"""
        
        # åˆ›å»ºä»»åŠ¡è®°å½•
        job = BacktestJob(
            id=job_id,
            strategy_id=strategy.id,
            name=f"Backtest {strategy.name} {start_date.date()}",
            status="pending",
            start_date=start_date,
            end_date=end_date,
            config={
                "initial_capital": initial_capital,
                "benchmark": benchmark,
                "commission_rate": 0.0025,
                "slippage_bps": 2.0
            }
        )
        
        session.add(job)
        await session.commit()
        
        # å¼‚æ­¥å¯åŠ¨å›æµ‹ä»»åŠ¡
        asyncio.create_task(
            run_backtest_task(job_id, strategy, start_date, end_date, initial_capital)
        )
        
        return job_id
    
    async def get_backtest_status(
        self, job_id: str, session: AsyncSession = None
    ) -> Dict[str, Any]:
        """è·å–å›æµ‹çŠ¶æ€"""
        
        if not session:
            async with get_session() as session:
                return await self._get_backtest_status_impl(session, job_id)
        else:
            return await self._get_backtest_status_impl(session, job_id)
    
    async def _get_backtest_status_impl(
        self, session: AsyncSession, job_id: str
    ) -> Dict[str, Any]:
        """è·å–å›æµ‹çŠ¶æ€å®ç°"""
        
        query = select(BacktestJob).where(BacktestJob.id == job_id)
        result = await session.execute(query)
        job = result.scalar_one_or_none()
        
        if not job:
            raise ValueError(f"Backtest job {job_id} not found")
        
        return {
            "job_id": job.id,
            "name": job.name,
            "status": job.status,
            "progress": job.progress or 0,
            "created_at": job.created_at.isoformat(),
            "started_at": job.started_at.isoformat() if job.started_at else None,
            "completed_at": job.completed_at.isoformat() if job.completed_at else None,
            "error_message": job.error_message,
            "estimated_duration": self._estimate_duration(job)
        }
    
    async def get_backtest_results(
        self, job_id: str, session: AsyncSession = None
    ) -> Optional[BacktestResult]:
        """è·å–å›æµ‹ç»“æœ"""
        
        if not session:
            async with get_session() as session:
                return await self._get_backtest_results_impl(session, job_id)
        else:
            return await self._get_backtest_results_impl(session, job_id)
    
    async def _get_backtest_results_impl(
        self, session: AsyncSession, job_id: str
    ) -> Optional[BacktestResult]:
        """è·å–å›æµ‹ç»“æœå®ç°"""
        
        # è·å–ä»»åŠ¡ä¿¡æ¯
        job_query = select(BacktestJob).where(BacktestJob.id == job_id)
        job_result = await session.execute(job_query)
        job = job_result.scalar_one_or_none()
        
        if not job or job.status != "completed":
            return None
        
        # è·å–ç»“æœæ•°æ®
        result_query = select(BacktestResult).where(BacktestResult.job_id == job_id)
        result_data = await session.execute(result_query)
        result = result_data.scalar_one_or_none()
        
        return result
    
    async def run_vectorized_backtest(
        self,
        strategy_config: Dict[str, Any],
        symbols: List[str],
        start_date: datetime,
        end_date: datetime,
        initial_capital: float = 1000000.0
    ) -> Dict[str, Any]:
        """è¿è¡Œå‘é‡åŒ–å›æµ‹ï¼ˆä½¿ç”¨Rustå¼•æ“ï¼‰"""
        
        try:
            # å‡†å¤‡å›æµ‹é…ç½®
            backtest_config = {
                "initial_capital": initial_capital,
                "commission_rate": 0.0025,
                "slippage_bps": 2.0,
                "start_date": start_date.isoformat(),
                "end_date": end_date.isoformat(),
                "symbols": symbols
            }
            
            # è°ƒç”¨Rustå›æµ‹å¼•æ“
            results = await asyncio.to_thread(
                self.rust_engine.run_vectorized_backtest,
                strategy_config,
                backtest_config
            )
            
            return {
                "success": True,
                "results": results,
                "computation_time": results.get("computation_time_ms", 0),
                "total_trades": results.get("total_trades", 0)
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "computation_time": 0
            }
    
    async def compare_strategies(
        self,
        strategies: List[Dict[str, Any]],
        symbols: List[str],
        start_date: datetime,
        end_date: datetime
    ) -> Dict[str, Any]:
        """ç­–ç•¥å¯¹æ¯”åˆ†æ"""
        
        results = {}
        
        # å¹¶è¡Œè¿è¡Œå¤šä¸ªç­–ç•¥å›æµ‹
        tasks = []
        for i, strategy in enumerate(strategies):
            task = self.run_vectorized_backtest(
                strategy, symbols, start_date, end_date
            )
            tasks.append(task)
        
        strategy_results = await asyncio.gather(*tasks)
        
        # æ•´åˆç»“æœ
        for i, result in enumerate(strategy_results):
            strategy_name = strategies[i].get("name", f"Strategy_{i+1}")
            results[strategy_name] = result
        
        # è®¡ç®—å¯¹æ¯”æŒ‡æ ‡
        comparison = self._calculate_comparison_metrics(results)
        
        return {
            "strategies": results,
            "comparison": comparison,
            "best_strategy": self._find_best_strategy(results)
        }
    
    async def get_backtest_history(
        self,
        user_id: Optional[str] = None,
        limit: int = 50,
        session: AsyncSession = None
    ) -> List[Dict[str, Any]]:
        """è·å–å›æµ‹å†å²"""
        
        if not session:
            async with get_session() as session:
                return await self._get_backtest_history_impl(session, user_id, limit)
        else:
            return await self._get_backtest_history_impl(session, user_id, limit)
    
    async def _get_backtest_history_impl(
        self,
        session: AsyncSession,
        user_id: Optional[str],
        limit: int
    ) -> List[Dict[str, Any]]:
        """è·å–å›æµ‹å†å²å®ç°"""
        
        conditions = []
        if user_id:
            conditions.append(BacktestJob.created_by == user_id)
        
        query = select(BacktestJob).order_by(BacktestJob.created_at.desc()).limit(limit)
        if conditions:
            from sqlalchemy import and_
            query = query.where(and_(*conditions))
        
        result = await session.execute(query)
        jobs = result.scalars().all()
        
        return [
            {
                "id": job.id,
                "name": job.name,
                "status": job.status,
                "created_at": job.created_at.isoformat(),
                "completed_at": job.completed_at.isoformat() if job.completed_at else None,
                "duration_minutes": self._calculate_duration(job),
                "summary": self._generate_summary(job)
            }
            for job in jobs
        ]
    
    # ç§æœ‰è¾…åŠ©æ–¹æ³•
    def _estimate_duration(self, job: BacktestJob) -> str:
        """ä¼°ç®—å›æµ‹æŒç»­æ—¶é—´"""
        # åŸºäºå†å²æ•°æ®å’Œç­–ç•¥å¤æ‚åº¦ä¼°ç®—
        return "5-10åˆ†é’Ÿ"
    
    def _calculate_comparison_metrics(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """è®¡ç®—ç­–ç•¥å¯¹æ¯”æŒ‡æ ‡"""
        if not results:
            return {}
        
        # æå–å„ç­–ç•¥çš„å…³é”®æŒ‡æ ‡
        metrics = {}
        for name, result in results.items():
            if result.get("success") and "results" in result:
                strategy_results = result["results"]
                metrics[name] = {
                    "total_return": strategy_results.get("total_return", 0),
                    "sharpe_ratio": strategy_results.get("sharpe_ratio", 0),
                    "max_drawdown": strategy_results.get("max_drawdown", 0),
                    "win_rate": strategy_results.get("win_rate", 0)
                }
        
        # è®¡ç®—æ’å
        rankings = {}
        for metric in ["total_return", "sharpe_ratio", "win_rate"]:
            sorted_strategies = sorted(
                metrics.items(),
                key=lambda x: x[1].get(metric, 0),
                reverse=True
            )
            rankings[metric] = [name for name, _ in sorted_strategies]
        
        # æœ€å¤§å›æ’¤æ’åï¼ˆè¶Šå°è¶Šå¥½ï¼‰
        sorted_by_drawdown = sorted(
            metrics.items(),
            key=lambda x: abs(x[1].get("max_drawdown", 0))
        )
        rankings["max_drawdown"] = [name for name, _ in sorted_by_drawdown]
        
        return {
            "metrics": metrics,
            "rankings": rankings,
            "best_performer": rankings["total_return"][0] if rankings["total_return"] else None
        }
    
    def _find_best_strategy(self, results: Dict[str, Any]) -> Optional[str]:
        """æ‰¾å‡ºæœ€ä½³ç­–ç•¥"""
        # ç»¼åˆè¯„åˆ†ç®—æ³•
        scores = {}
        
        for name, result in results.items():
            if result.get("success") and "results" in result:
                strategy_results = result["results"]
                
                # ç»¼åˆè¯„åˆ†ï¼ˆå¯è°ƒæ•´æƒé‡ï¼‰
                score = (
                    strategy_results.get("total_return", 0) * 0.3 +
                    strategy_results.get("sharpe_ratio", 0) * 0.3 +
                    strategy_results.get("win_rate", 0) * 0.2 +
                    (1 + strategy_results.get("max_drawdown", 0)) * 0.2  # å›æ’¤è¶Šå°å¾—åˆ†è¶Šé«˜
                )
                scores[name] = score
        
        return max(scores.items(), key=lambda x: x[1])[0] if scores else None
    
    def _calculate_duration(self, job: BacktestJob) -> Optional[float]:
        """è®¡ç®—å›æµ‹æŒç»­æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰"""
        if job.started_at and job.completed_at:
            duration = job.completed_at - job.started_at
            return duration.total_seconds() / 60
        return None
    
    def _generate_summary(self, job: BacktestJob) -> str:
        """ç”Ÿæˆå›æµ‹æ‘˜è¦"""
        if job.status == "completed" and job.results:
            total_return = job.results.get("total_return", 0)
            sharpe_ratio = job.results.get("sharpe_ratio", 0)
            return f"æ”¶ç›Šç‡: {total_return:.2%}, å¤æ™®æ¯”ç‡: {sharpe_ratio:.2f}"
        elif job.status == "failed":
            return "å›æµ‹å¤±è´¥"
        else:
            return f"çŠ¶æ€: {job.status}"
```

---

## 4. æ•°æ®æ¨¡å‹è®¾è®¡

### 4.1 Pydanticæ¨¡å‹

```python
# app/models/factor.py
from pydantic import BaseModel, Field, validator
from typing import List, Dict, Any, Optional
from datetime import datetime
from enum import Enum

class FactorCategory(str, Enum):
    TECHNICAL = "technical"
    STATISTICAL = "statistical" 
    FUNDAMENTAL = "fundamental"
    SENTIMENT = "sentiment"
    AI_GENERATED = "ai_generated"

class FactorDefinition(BaseModel):
    """å› å­å®šä¹‰æ¨¡å‹"""
    id: str = Field(..., description="å› å­å”¯ä¸€æ ‡è¯†")
    name: str = Field(..., min_length=1, max_length=100, description="å› å­åç§°")
    category: FactorCategory = Field(..., description="å› å­ç±»åˆ«")
    formula: str = Field(..., min_length=1, description="å› å­è®¡ç®—å…¬å¼")
    description: Optional[str] = Field(None, max_length=1000, description="å› å­æè¿°")
    parameters: Optional[Dict[str, Any]] = Field(None, description="è®¡ç®—å‚æ•°")
    created_by: Optional[str] = Field(None, description="åˆ›å»ºè€…")
    
    @validator('formula')
    def validate_formula(cls, v):
        """éªŒè¯å› å­å…¬å¼"""
        if not v or len(v.strip()) == 0:
            raise ValueError("Formula cannot be empty")
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šçš„å…¬å¼è¯­æ³•éªŒè¯
        return v.strip()
    
    class Config:
        use_enum_values = True
        schema_extra = {
            "example": {
                "id": "rsi_14",
                "name": "RSI_14",
                "category": "technical",
                "formula": "rsi(close, 14)",
                "description": "14æœŸç›¸å¯¹å¼ºå¼±æŒ‡æ•°",
                "parameters": {"period": 14},
                "created_by": "user_123"
            }
        }

class FactorResult(BaseModel):
    """å› å­è®¡ç®—ç»“æœæ¨¡å‹"""
    factor_id: str
    factor_name: str
    values: List[float]
    timestamps: List[datetime]
    symbols: List[str]
    calculation_time: float
    metadata: Optional[Dict[str, Any]] = None

class FactorCalculationRequest(BaseModel):
    """å› å­è®¡ç®—è¯·æ±‚æ¨¡å‹"""
    factors: List[FactorDefinition] = Field(..., min_items=1, max_items=50)
    symbols: List[str] = Field(..., min_items=1, max_items=1000)
    start_date: datetime
    end_date: datetime
    cache_enabled: bool = Field(True, description="æ˜¯å¦å¯ç”¨ç¼“å­˜")
    
    @validator('end_date')
    def validate_date_range(cls, v, values):
        if 'start_date' in values and v <= values['start_date']:
            raise ValueError('end_date must be after start_date')
        return v
    
    @validator('symbols')
    def validate_symbols(cls, v):
        if len(set(v)) != len(v):
            raise ValueError('Duplicate symbols not allowed')
        return v

class FactorCalculationResponse(BaseModel):
    """å› å­è®¡ç®—å“åº”æ¨¡å‹"""
    success: bool
    results: Optional[Dict[str, FactorResult]] = None
    error: Optional[str] = None
    computation_time: float
    cached: bool = False
    
class FactorLibraryQuery(BaseModel):
    """å› å­åº“æŸ¥è¯¢æ¨¡å‹"""
    category: Optional[FactorCategory] = None
    min_ic: Optional[float] = Field(None, ge=-1, le=1)
    min_sharpe: Optional[float] = Field(None, ge=0)
    search_text: Optional[str] = Field(None, max_length=100)
    limit: int = Field(50, ge=1, le=1000)
    offset: int = Field(0, ge=0)

# app/models/backtest.py
class BacktestConfig(BaseModel):
    """å›æµ‹é…ç½®æ¨¡å‹"""
    initial_capital: float = Field(1000000.0, gt=0, description="åˆå§‹èµ„é‡‘")
    commission_rate: float = Field(0.0025, ge=0, le=0.1, description="æ‰‹ç»­è´¹ç‡")
    slippage_bps: float = Field(2.0, ge=0, le=100, description="æ»‘ç‚¹(åŸºç‚¹)")
    max_position_size: float = Field(0.2, gt=0, le=1, description="æœ€å¤§ä»“ä½æ¯”ä¾‹")
    rebalance_frequency: str = Field("daily", regex="^(daily|weekly|monthly)$")
    benchmark: Optional[str] = Field(None, description="åŸºå‡†ä»£ç ")

class StrategyDefinition(BaseModel):
    """ç­–ç•¥å®šä¹‰æ¨¡å‹"""
    id: str
    name: str = Field(..., min_length=1, max_length=100)
    description: Optional[str] = Field(None, max_length=1000)
    factors: List[str] = Field(..., min_items=1, description="ä½¿ç”¨çš„å› å­IDåˆ—è¡¨")
    weights: Optional[Dict[str, float]] = Field(None, description="å› å­æƒé‡")
    rebalance_rule: str = Field("weekly", description="è°ƒä»“è§„åˆ™")
    risk_management: Optional[Dict[str, Any]] = Field(None, description="é£é™©æ§åˆ¶")

class BacktestRequest(BaseModel):
    """å›æµ‹è¯·æ±‚æ¨¡å‹"""
    strategy: StrategyDefinition
    symbols: List[str] = Field(..., min_items=1, max_items=500)
    start_date: datetime
    end_date: datetime
    config: BacktestConfig = BacktestConfig()
    
    @validator('end_date')
    def validate_backtest_period(cls, v, values):
        if 'start_date' in values:
            if v <= values['start_date']:
                raise ValueError('end_date must be after start_date')
            
            # æ£€æŸ¥å›æµ‹æœŸé—´é•¿åº¦
            period_days = (v - values['start_date']).days
            if period_days < 30:
                raise ValueError('Backtest period must be at least 30 days')
            if period_days > 3650:  # 10å¹´
                raise ValueError('Backtest period cannot exceed 10 years')
        return v

class BacktestMetrics(BaseModel):
    """å›æµ‹æŒ‡æ ‡æ¨¡å‹"""
    total_return: float
    annualized_return: float
    max_drawdown: float
    sharpe_ratio: float
    sortino_ratio: float
    calmar_ratio: float
    win_rate: float
    information_ratio: float
    total_trades: int
    avg_trade_return: float

class BacktestResult(BaseModel):
    """å›æµ‹ç»“æœæ¨¡å‹"""
    job_id: str
    status: str
    metrics: Optional[BacktestMetrics] = None
    daily_returns: Optional[List[float]] = None
    portfolio_values: Optional[List[float]] = None
    positions_history: Optional[Dict[str, List[float]]] = None
    trade_history: Optional[List[Dict[str, Any]]] = None
    error_message: Optional[str] = None
    computation_time: float = 0
    
class BacktestJobStatus(BaseModel):
    """å›æµ‹ä»»åŠ¡çŠ¶æ€æ¨¡å‹"""
    job_id: str
    name: str
    status: str  # pending, running, completed, failed
    progress: float = Field(0, ge=0, le=100)
    created_at: datetime
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    estimated_duration: Optional[str] = None
    error_message: Optional[str] = None
```

### 4.2 SQLAlchemyæ¨¡å‹

```python
# app/models/db_models.py
from sqlalchemy import Column, String, Float, Integer, DateTime, Boolean, Text, JSON
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.sql import func
import uuid

Base = declarative_base()

class FactorLibrary(Base):
    """å› å­åº“æ•°æ®è¡¨"""
    __tablename__ = "factor_library"
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    name = Column(String(100), nullable=False, unique=True, index=True)
    category = Column(String(50), nullable=False, index=True)
    formula = Column(Text, nullable=False)
    description = Column(Text)
    parameters = Column(JSON)
    
    # æ€§èƒ½æŒ‡æ ‡
    ic = Column(Float)
    ic_ir = Column(Float) 
    sharpe_ratio = Column(Float)
    max_drawdown = Column(Float)
    win_rate = Column(Float)
    
    # ä½¿ç”¨ç»Ÿè®¡
    usage_count = Column(Integer, default=0)
    last_used = Column(DateTime)
    
    # å…ƒæ•°æ®
    created_by = Column(String(100))
    created_at = Column(DateTime, server_default=func.now())
    updated_at = Column(DateTime, server_default=func.now(), onupdate=func.now())
    is_active = Column(Boolean, default=True, index=True)

class BacktestJob(Base):
    """å›æµ‹ä»»åŠ¡è¡¨"""
    __tablename__ = "backtest_jobs"
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    strategy_id = Column(String(100), nullable=False, index=True)
    name = Column(String(255), nullable=False)
    status = Column(String(50), default='pending', index=True)
    progress = Column(Float, default=0)
    
    # å›æµ‹é…ç½®
    start_date = Column(DateTime, nullable=False)
    end_date = Column(DateTime, nullable=False)
    config = Column(JSON, nullable=False)
    
    # ç»“æœ
    results = Column(JSON)
    metrics = Column(JSON)
    
    # æ—¶é—´æˆ³
    created_at = Column(DateTime, server_default=func.now(), index=True)
    started_at = Column(DateTime)
    completed_at = Column(DateTime)
    
    # é”™è¯¯ä¿¡æ¯
    error_message = Column(Text)
    
    # åˆ›å»ºè€…
    created_by = Column(String(100), index=True)

class FactorValue(Base):
    """å› å­å€¼æ•°æ®è¡¨ï¼ˆClickHouseä¼šæ˜¯ä¸»å­˜å‚¨ï¼‰"""
    __tablename__ = "factor_values"
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    factor_id = Column(String(100), nullable=False, index=True)
    symbol = Column(String(50), nullable=False, index=True)
    timestamp = Column(DateTime, nullable=False, index=True)
    value = Column(Float, nullable=False)
    rank = Column(Integer)
    quantile = Column(Integer)
    
    # å¤åˆç´¢å¼•
    __table_args__ = (
        Index('idx_factor_symbol_time', 'factor_id', 'symbol', 'timestamp'),
    )
```

---

## 5. APIè·¯ç”±è®¾è®¡

### 5.1 å› å­ç›¸å…³API

```python
# app/api/v2/factors.py
from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks, Query
from typing import List, Optional
from sqlalchemy.ext.asyncio import AsyncSession

from ...core.database import get_session
from ...core.security import get_current_user
from ...models.factor import (
    FactorDefinition, FactorCalculationRequest, FactorCalculationResponse,
    FactorLibraryQuery
)
from ...services.factor_service import FactorService

router = APIRouter()

@router.post("/calculate", response_model=FactorCalculationResponse)
async def calculate_factors(
    request: FactorCalculationRequest,
    background_tasks: BackgroundTasks,
    current_user: str = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """æ‰¹é‡è®¡ç®—å› å­"""
    try:
        factor_service = FactorService()
        
        results = await factor_service.calculate_factors(
            factors=request.factors,
            symbols=request.symbols,
            start_date=request.start_date,
            end_date=request.end_date,
            session=session
        )
        
        # è®°å½•ä½¿ç”¨ç»Ÿè®¡ï¼ˆåå°ä»»åŠ¡ï¼‰
        background_tasks.add_task(
            update_factor_usage_stats,
            [f.id for f in request.factors]
        )
        
        return FactorCalculationResponse(
            success=True,
            results=results,
            computation_time=sum(r.calculation_time for r in results.values()),
            cached=any(r.metadata and r.metadata.get("cached") for r in results.values())
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/library")
async def get_factor_library(
    category: Optional[str] = Query(None, description="å› å­ç±»åˆ«"),
    min_ic: Optional[float] = Query(None, ge=-1, le=1, description="æœ€å°ICå€¼"),
    min_sharpe: Optional[float] = Query(None, ge=0, description="æœ€å°å¤æ™®æ¯”ç‡"),
    search_text: Optional[str] = Query(None, max_length=100, description="æœç´¢å…³é”®è¯"),
    limit: int = Query(50, ge=1, le=1000, description="è¿”å›æ•°é‡é™åˆ¶"),
    offset: int = Query(0, ge=0, description="åç§»é‡"),
    session: AsyncSession = Depends(get_session)
):
    """è·å–å› å­åº“"""
    try:
        factor_service = FactorService()
        
        if search_text:
            # æœç´¢æ¨¡å¼
            factors = await factor_service.search_factors(
                query=search_text,
                filters={
                    "category": category,
                    "min_ic": min_ic,
                    "min_sharpe": min_sharpe
                },
                limit=limit,
                session=session
            )
        else:
            # åˆ—è¡¨æ¨¡å¼
            factors = await factor_service.get_factor_library(
                category=category,
                min_ic=min_ic,
                min_sharpe=min_sharpe,
                limit=limit,
                session=session
            )
        
        return {
            "success": True,
            "data": {
                "factors": factors,
                "total_count": len(factors),
                "limit": limit,
                "offset": offset
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/create")
async def create_factor(
    factor_def: FactorDefinition,
    current_user: str = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """åˆ›å»ºæ–°å› å­"""
    try:
        factor_def.created_by = current_user
        
        factor_service = FactorService()
        new_factor = await factor_service.create_factor(factor_def, session)
        
        return {
            "success": True,
            "data": {
                "factor_id": new_factor.id,
                "name": new_factor.name,
                "message": "å› å­åˆ›å»ºæˆåŠŸ"
            }
        }
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/evaluate/{factor_id}")
async def evaluate_factor(
    factor_id: str,
    symbols: List[str],
    start_date: datetime,
    end_date: datetime,
    background_tasks: BackgroundTasks,
    current_user: str = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """è¯„ä¼°å› å­æ€§èƒ½"""
    try:
        factor_service = FactorService()
        
        performance = await factor_service.evaluate_factor_performance(
            factor_id=factor_id,
            symbols=symbols,
            start_date=start_date,
            end_date=end_date,
            session=session
        )
        
        return {
            "success": True,
            "data": {
                "factor_id": factor_id,
                "performance": performance,
                "evaluation_date": datetime.utcnow().isoformat()
            }
        }
        
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/realtime/{factor_id}")
async def get_realtime_factor_value(
    factor_id: str,
    symbols: List[str] = Query(..., description="è‚¡ç¥¨ä»£ç åˆ—è¡¨"),
    session: AsyncSession = Depends(get_session)
):
    """è·å–å®æ—¶å› å­å€¼"""
    try:
        factor_service = FactorService()
        
        # è·å–å› å­å®šä¹‰
        factor = await factor_service.get_factor_by_id(factor_id, session)
        if not factor:
            raise HTTPException(status_code=404, detail="Factor not found")
        
        # è®¡ç®—å®æ—¶å› å­å€¼
        values = {}
        for symbol in symbols:
            value = await factor_service.calculate_realtime_factor(
                factor, symbol
            )
            values[symbol] = value
        
        return {
            "success": True,
            "data": {
                "factor_id": factor_id,
                "factor_name": factor.name,
                "values": values,
                "timestamp": datetime.utcnow().isoformat()
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

async def update_factor_usage_stats(factor_ids: List[str]):
    """æ›´æ–°å› å­ä½¿ç”¨ç»Ÿè®¡ï¼ˆåå°ä»»åŠ¡ï¼‰"""
    try:
        async with get_session() as session:
            # æ›´æ–°ä½¿ç”¨æ¬¡æ•°å’Œæœ€åä½¿ç”¨æ—¶é—´
            for factor_id in factor_ids:
                await session.execute(
                    "UPDATE factor_library SET usage_count = usage_count + 1, "
                    "last_used = :now WHERE id = :factor_id",
                    {"now": datetime.utcnow(), "factor_id": factor_id}
                )
            await session.commit()
    except Exception as e:
        logger.error(f"Failed to update factor usage stats: {e}")
```

---

## 6. ç›‘æ§å’Œè¿ç»´

### 6.1 ç›‘æ§ä¸­é—´ä»¶

```python
# app/middleware/monitoring.py
import time
import asyncio
from typing import Callable
from fastapi import Request, Response
from prometheus_client import Counter, Histogram, Gauge, generate_latest
from starlette.middleware.base import BaseHTTPMiddleware

# PrometheusæŒ‡æ ‡å®šä¹‰
REQUEST_COUNT = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

REQUEST_DURATION = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration',
    ['method', 'endpoint']
)

ACTIVE_REQUESTS = Gauge(
    'http_requests_active',
    'Active HTTP requests'
)

RUST_ENGINE_CALLS = Counter(
    'rust_engine_calls_total',
    'Total Rust engine calls',
    ['function']
)

FACTOR_CALCULATIONS = Histogram(
    'factor_calculation_duration_seconds',
    'Factor calculation duration',
    ['factor_type']
)

class PrometheusMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next: Callable) -> Response:
        start_time = time.time()
        
        # å¢åŠ æ´»è·ƒè¯·æ±‚è®¡æ•°
        ACTIVE_REQUESTS.inc()
        
        try:
            response = await call_next(request)
            
            # è®°å½•æŒ‡æ ‡
            REQUEST_COUNT.labels(
                method=request.method,
                endpoint=self._get_endpoint(request),
                status=response.status_code
            ).inc()
            
            REQUEST_DURATION.labels(
                method=request.method,
                endpoint=self._get_endpoint(request)
            ).observe(time.time() - start_time)
            
            return response
            
        finally:
            # å‡å°‘æ´»è·ƒè¯·æ±‚è®¡æ•°
            ACTIVE_REQUESTS.dec()
    
    def _get_endpoint(self, request: Request) -> str:
        """æå–APIç«¯ç‚¹"""
        path = request.url.path
        # ç®€åŒ–è·¯å¾„ï¼ˆå»æ‰IDç­‰åŠ¨æ€éƒ¨åˆ†ï¼‰
        if '/factors/' in path and path.split('/')[-1].isdigit():
            return '/factors/{id}'
        elif '/backtest/' in path and path.split('/')[-1].isdigit():
            return '/backtest/{id}'
        return path

@app.get("/metrics")
async def get_metrics():
    """PrometheusæŒ‡æ ‡ç«¯ç‚¹"""
    return Response(generate_latest(), media_type="text/plain")
```

### 6.2 æ—¥å¿—é…ç½®

```python
# app/core/logging.py
import logging
import sys
from loguru import logger
from pythonjsonlogger import jsonlogger

class StructuredLogger:
    def __init__(self, log_level: str = "INFO"):
        # ç§»é™¤é»˜è®¤å¤„ç†å™¨
        logger.remove()
        
        # æ§åˆ¶å°è¾“å‡ºï¼ˆå¼€å‘ç¯å¢ƒï¼‰
        logger.add(
            sys.stderr,
            format="<green>{time}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
            level=log_level,
            colorize=True
        )
        
        # ç»“æ„åŒ–æ—¥å¿—æ–‡ä»¶ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
        logger.add(
            "logs/app.log",
            rotation="100 MB",
            retention="30 days",
            level=log_level,
            format="{time} | {level} | {name}:{function}:{line} | {message}",
            serialize=True  # JSONæ ¼å¼
        )
        
        # é”™è¯¯æ—¥å¿—
        logger.add(
            "logs/errors.log",
            rotation="50 MB", 
            retention="90 days",
            level="ERROR",
            format="{time} | {level} | {name}:{function}:{line} | {message}",
            serialize=True,
            backtrace=True,
            diagnose=True
        )
        
        # æ€§èƒ½æ—¥å¿—
        logger.add(
            "logs/performance.log",
            rotation="50 MB",
            retention="7 days", 
            level="INFO",
            format="{time} | {level} | {message}",
            filter=lambda record: "performance" in record["extra"]
        )
    
    def log_api_call(self, endpoint: str, method: str, duration: float, status_code: int):
        """è®°å½•APIè°ƒç”¨"""
        logger.info(
            "API call completed",
            extra={
                "endpoint": endpoint,
                "method": method,
                "duration_ms": duration * 1000,
                "status_code": status_code,
                "event_type": "api_call"
            }
        )
    
    def log_factor_calculation(self, factor_names: list, duration: float, success: bool):
        """è®°å½•å› å­è®¡ç®—"""
        logger.info(
            "Factor calculation completed",
            extra={
                "factor_names": factor_names,
                "duration_ms": duration * 1000,
                "success": success,
                "event_type": "factor_calculation",
                "performance": True
            }
        )
    
    def log_backtest(self, job_id: str, status: str, duration: float = None):
        """è®°å½•å›æµ‹"""
        extra_data = {
            "job_id": job_id,
            "status": status,
            "event_type": "backtest"
        }
        
        if duration:
            extra_data["duration_ms"] = duration * 1000
            extra_data["performance"] = True
        
        logger.info("Backtest status update", extra=extra_data)
    
    def log_rust_engine_call(self, function: str, duration: float, success: bool):
        """è®°å½•Rustå¼•æ“è°ƒç”¨"""
        logger.info(
            "Rust engine call",
            extra={
                "function": function,
                "duration_ms": duration * 1000,
                "success": success,
                "event_type": "rust_engine",
                "performance": True
            }
        )
```

---

## æ€»ç»“

æœ¬PythonæœåŠ¡å±‚é‡æ„è®¾è®¡æä¾›äº†ï¼š

### ğŸš€ æ ¸å¿ƒæ”¹è¿›

1. **ç°ä»£åŒ–æ¶æ„**: FastAPI + å¼‚æ­¥å¤„ç† + å¾®æœåŠ¡è®¾è®¡
2. **æ€§èƒ½æå‡**: Rustå¼•æ“é›†æˆï¼Œå¼‚æ­¥æ•°æ®åº“æ“ä½œ
3. **ç”Ÿäº§å°±ç»ª**: ç›‘æ§ã€æ—¥å¿—ã€ç¼“å­˜ã€é™æµç­‰å®Œæ•´åŠŸèƒ½
4. **å‘åå…¼å®¹**: ä¿æŒç°æœ‰APIæ¥å£çš„å…¼å®¹æ€§
5. **æ‰©å±•æ€§**: æ¨¡å—åŒ–è®¾è®¡ï¼Œæ”¯æŒæ°´å¹³æ‰©å±•

### ğŸ’¡ æŠ€æœ¯ä¼˜åŠ¿

- **10å€å¹¶å‘èƒ½åŠ›**: å¼‚æ­¥å¤„ç† vs åŒæ­¥HTTPæœåŠ¡å™¨
- **ç±»å‹å®‰å…¨**: Pydanticæ•°æ®éªŒè¯å’ŒFastAPIè‡ªåŠ¨æ–‡æ¡£
- **ç¼“å­˜ä¼˜åŒ–**: Redisç¼“å­˜å‡å°‘é‡å¤è®¡ç®—
- **ç›‘æ§å®Œå–„**: PrometheusæŒ‡æ ‡ + ç»“æ„åŒ–æ—¥å¿—
- **å®‰å…¨è®¤è¯**: JWTä»¤ç‰Œ + æƒé™æ§åˆ¶

### ğŸ›  å®æ–½ç­–ç•¥

1. **æ¸è¿›å¼è¿ç§»**: å…ˆéƒ¨ç½²V2 APIï¼Œä¿æŒV1å…¼å®¹
2. **æ•°æ®åº“è¿ç§»**: ä½¿ç”¨Alembicç®¡ç†æ•°æ®åº“ç‰ˆæœ¬
3. **æ€§èƒ½æµ‹è¯•**: å‹åŠ›æµ‹è¯•éªŒè¯æ€§èƒ½æå‡
4. **ç›‘æ§éƒ¨ç½²**: å®æ—¶ç›‘æ§ç³»ç»Ÿå¥åº·çŠ¶æ€

è¯¥è®¾è®¡ä¸ºé‡åŒ–åˆ†æç³»ç»Ÿæä¾›äº†ç°ä»£åŒ–ã€é«˜æ€§èƒ½ã€ç”Ÿäº§å°±ç»ªçš„APIæœåŠ¡å±‚ï¼Œèƒ½å¤Ÿæ”¯æ’‘å¤§è§„æ¨¡ç”¨æˆ·å’Œè®¡ç®—éœ€æ±‚ã€‚